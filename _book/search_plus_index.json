{"./":{"url":"./","title":"Introduction","keywords":"","body":"Bota5ky's BlogBota5ky's Blog 日常学习做笔记使用，考证相关笔记有： AWS Certified Solutions Architect - Associate 学习笔记 AWS Certified Database - Specialty 学习笔记 Certified Kubernetes Administrator 学习笔记 其他还包括，但不限于： Java、C#、C、Golang Shell 命令及终端操作，git 命令和 JSON Path 的使用 Redis、Kafka 入门 MySQL、PostgreSQL、SQL Server、SQL CE 计算机网络、操作系统 ... Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/":{"url":"saa/","title":"SAA 学习笔记","keywords":"","body":"AWS 架构相关学习笔记AWS 架构相关学习笔记 根据 Udemy 上的课程 Ultimate AWS Certified Solutions Architect Associate SAA-C02 学习。 Full Practice Exam | Learn Cloud Computing | Pass the AWS Certified Solutions Architect Associate Certification SAA-C02! Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/1.基本概念.html":{"url":"saa/1.基本概念.html","title":"1. 基本概念","keywords":"","body":"1. Amazon Web Services2. Terminology3. AWS Regions4. How to choose an AWS Region?5. AWS Availability Zones1. Amazon Web Services IAM（Identity and Access Management）：身份识别与访问管理 EC2（Elastic Compute Cloud）：弹性计算云 ELB（Elastic Load Balance）：弹性负载均衡 S3（Simple Storage Service）：简单存储服务 EBS（Elastic Block Store）：弹性块存储 CloudFront：用户用于加速静态或动态内容发布的内容发布服务 RDS（Relational Database Service）：关系型数据库服务 ACM（AWS Certificate Manager）：AWS证书管理器 EMR（Elastic MapReduce) ：是一个托管集群平台，可简化在AWS上运行大数据框架 Redshift：是一种完全托管的 PB 级云中数据仓库服务 DynamoDB：完全托管的NoSQL数据库服务 ElastiCache：云缓存 2. Terminology VPC（Virtual Private Cloud）：私有云 TDE（Transparent Data Encryption）：透明数据加密 SLA (Service Level Agreements)：服务级协定 RPO（Recovery Point Objective）：数据恢复点目标，主要指的是业务系统所能容忍的数据丢失量 RTO（Recovery Time Objective）：恢复时间目标，主要指的是所能容忍的业务停止服务的最长时间，也就是从灾难发生到业务系统恢复服务功能所需要的最短时间周期 PITR（Point-In-Time Recovery）：时间点恢复 IOPS（Input/Output Operations Per Second）：每秒的输入输出量 3. AWS Regions https://infrastructure.aws/ AWS has Regions all around the world Names can be us-east-1, eu-west-3… A region is a cluster of data centers Most AWS services are region-scoped 4. How to choose an AWS Region? Compliance with data governance and legal requirements: data never leaves a region without your explicit permission Proximity to customers: reduced latency Available services within a Region: new services and new features aren’t available in every Region Pricing: pricing varies region to region and is transparent in the service pricing page 5. AWS Availability Zones Each region has many availability zones (usually 3, min is 2, max is 6) Names can be ap-southeast-2a, ap-southeast-2b, ap-southeast-2c... Each availability zone (AZ) is one or more discrete data centers with redundant power, networking, and connectivity They’re separate from each other, so that they’re isolated from disasters They’re connected with high bandwidth, ultra-low latency networking Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-12 12:03:18 "},"saa/2.考试概览.html":{"url":"saa/2.考试概览.html","title":"2. SAA-C02考试概览","keywords":"","body":"1. AWS 考试证书类型2. SAA-C02参加最新考试的最后日期是 2022 年 8 月 29 日3. 备考资料4. 公司内部政策1. AWS 考试证书类型 2. SAA-C02参加最新考试的最后日期是 2022 年 8 月 29 日 AWS 认证解决方案架构测试考试概览 AWS Certification 帐户的“Benefits”中的半价优惠券，可以用于再认证或用于您之后参加的任何认证考试 参加同等或更高级别的考试可以满足再认证的要求。如果您未通过考试，必须等待14天才能重考 重考次数没有限制，但每次重考都必须全额支付报名费（2022年9月30日之前，PSI考试不过免费补考） 一旦通过了考试，则在两年内不能重考同一门课程 费用 Foundational 100美元，Associate 150美元，Professional 和 Specialty 300美元 130分钟65道题，其中包括15道不计分（AWS收集评估以作为将来计分使用），及格分720分（可能会根据难易程度换算分数） 单选四选一，多选在五个或更多答案选项中具有两个或更多正确答案（会告诉你正确的个数） 3. 备考资料 AWS官方文档 AWS官方白皮书 在线题库 ExamTopics AWS认证模拟题 Free Briefing exams 博客 Jayendra's Cloud Certification Blog LiuYuchen Bing哥的博客 公司内部资源 Okta-Udemy视频课程，全英文带习题 Gmail、Google Drive等搜索关键字均可搜到相关资料，如博客大赛、AWS相关session等 4. 公司内部政策 详情见Google Groups - Quarterly Call for Cloud Certification Details查看报销code等 AWS全额报销，每个证给报销一次 GCP 200美元额度 个人层面：PDB报销（即每年2K经费） 社区层面：后续考虑给大家提供奖品（具体待定） 其它一些优惠政策： 一般每年黑五K8s报名有半价折扣 证书考取当年可在国家税务“个税App”申请“继续教育”3600元定额退税 国外三巨头都提供一些免费的试用计划 使用公司邮箱注册AWS Partner Central报名 使用 Quarterly Call for Cloud Certification Details 中提到的 code 发邮件给U Head审批后可以报销 考试通过后填写上述邮件里面的相关表格 美元信用卡（个人可以注册获得12个月免费套餐），公司层面Okta-AWS Beach AWS的绝大部分考试都支持考试中心和在线监考两种形式，可以选择 Pearson VUE 或 PSI（大陆目前只有 PSI 远程） 可以选中文考试，考试过程中可以切换中英文，成绩单为中文，证书无区别 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/3.IAM.html":{"url":"saa/3.IAM.html","title":"3. IAM","keywords":"","body":"1. IAM: Users & Groups2. IAM: Permissions3. IAM Policies Structure4. How can users access AWS ?5. IAM Security Tools6. IAM Guidelines & Best Practices7. Shared Responsibility Model for IAM1. IAM: Users & Groups Identity and Access Management Global service Root account created by default, shouldn’t be used or shared Users are people within your organization, and can be grouped Groups only contain users, not other groups Users don’t have to belong to a group, and user can belong to multiple groups 2. IAM: Permissions Users or Groups can be assigned JSON documents called policies These policies define the permissions of the users In AWS you apply the least privilege principle: don't give more permissions than a user needs 3. IAM Policies Structure Version: policy language version, always include \"2012-10-17\" Id: an identifier for the policy (optional) Statement: one or more individual statements (required) Sid: an identifier for the statement (optional) Effect: whether the statement allows or denies access (Allow, Deny) Principal: account/user/role to which this policy applied to Action: list of actions this policy allows or denies Resource: list of resources to which the actions applied to Condition: conditions for when this policy is in effect (optional) 使用标签控制对 IAM 用户和角色的访问以及他们进行的访问 4. How can users access AWS ? AWS Management Console (protected by password + MFA) AWS Command Line Interface (CLI): protected by access keys (is built on AWS SDK for Python) AWS Software Developer Kit (SDK) - for code: protected by access keys 5. IAM Security Tools IAM Credentials Report (account-level): a report that lists all your account's users and the status of their various credentials IAM Access Advisor (user-level): Access advisor shows the service permissions granted to a user and when those services were last accessed You can use this information to revise your policies 6. IAM Guidelines & Best Practices Don’t use the root account except for AWS account setup One physical user = One AWS user Assign users to groups and assign permissions to groups Create a strong password policy Use and enforce the use of Multi Factor Authentication (MFA) Create and use Roles for giving permissions to AWS services Use Access Keys for Programmatic Access (CLI / SDK) Audit permissions of your account with the IAM Credentials Report Never share IAM users & Access Keys 7. Shared Responsibility Model for IAM aws you - Infrastructure (global network security) - Configuration and vulnerability analysis - Compliance validation - Users, Groups, Roles, Policies management and monitoring - Enable MFA on all accounts - Rotate all your keys often - Use IAM tools to apply appropriate permissions - Analyze access patterns & review permissions Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/4.EC2.html":{"url":"saa/4.EC2.html","title":"4. EC2 & Security Groups","keywords":"","body":"1. Amazon EC2 (Elastic Compute Cloud)2. EC2 Instance Types - Overview3. Introduction to Security Groups4. Security Groups Good to know5. Classic Ports to know6. SSH Summary Table7. EC2 Instances Purchasing Options8. Differences between options9. How to terminate Spot Instances?10. Spot Fleets1. Amazon EC2 (Elastic Compute Cloud) It mainly consists in the capability of : Renting virtual machines (EC2) Storing data on virtual drives (EBS) Distributing load across machines (ELB) Scaling the services using an auto-scaling group (ASG) 2. EC2 Instance Types - Overview m5.2xlarge m: instance class 5: generation (AWS improves them over time) 2xlarge: size within the instance class 3. Introduction to Security Groups Security groups only contain allow rules Security groups rules can reference by IP or by security group 4. Security Groups Good to know Can be attached to multiple instances Locked down to a region / VPC combination Does live \"outside\" the EC2 – if traffic is blocked the EC2 instance won't see it It's good to maintain one separate security group for SSH access If your application is not accessible (time out), then it's a security group issue If your application gives a \"connection refused\" error, then it's an application error or it's not launched All inbound traffic is blocked by default All outbound traffic is authorised by default 5. Classic Ports to know 22 = SSH (Secure Shell) - log into a Linux instance 21 = FTP (File Transfer Protocol) – upload files into a file share 22 = SFTP (Secure File Transfer Protocol) – upload files using SSH 80 = HTTP – access unsecured websites 443 = HTTPS – access secured websites 3389 = RDP (Remote Desktop Protocol) – log into a Windows instance 6. SSH Summary Table SSH Putty EC2 Instance Connect Mac √ √ Linux √ √ Windows √ √ Windows > 10 √ √ √ 7. EC2 Instances Purchasing Options On-Demand Instances: short workload, predictable pricing Reserved: (MINIMUM 1 year) Reserved Instances: long workloads Convertible Reserved Instances: long workloads with flexible instances Scheduled Reserved Instances: example – every Thursday between 3 and 6 pm Spot Instances: short workloads, cheap, can lose instances (less reliable) Useful for workloads that are resilient to failure: Batch jobs, Data analysis, Image processing, Any distributed workloads, Workloads with a flexible start and end time 如果主动终止一个竞价实例，需要为当前这个完整小时付费 如果因为价格上涨，AWS终止了你的竞价实例，那么这个小时的费用会被免除 Dedicated Hosts: book an entire physical server, control instance placement Dedicated Hosts can help you address compliance requirements and reduce costs by allowing you to use your existing server-bound software licenses Dedicated Instances: no other customers will share your hardware May share hardware with other instances in same account No control over instance placement (can move hardware after Stop / Start) 8. Differences between options *note: the % discounts are different from the video as AWS change them over time – the exact numbers are not needed for the exam. This is just for illustrative purposes Spot Instances: Spot blocks during a specified time frame (1 to 6 hours) without interruptions (no longer available from 01/7/2021, support until 31/12/2022) Discount Reservation Period Upfront Payment On Demand / / No Reserved Up to 72% 1 year/ 3 years No / Partial / All Convertible Reserved Up to 66% Scheduled Reserved / 1 year only Spot Up to 90% Dedicated Hosts More expensive 3 years Dedicated Instances / / 9. How to terminate Spot Instances? You can only cancel Spot Instance requests that are open, active, or disabled. Cancelling a Spot Request does not terminate instances You must first cancel a Spot Request, and then terminate the associated Spot Instances 10. Spot Fleets Spot Fleets = set of Spot Instances + (optional) On-Demand Instances The Spot Fleet will try to meet the target capacity with price constraints Define possible launch pools: instance type (m5.large), OS, Availability Zone Can have multiple launch pools, so that the fleet can choose Spot Fleet stops launching instances when reaching capacity or max cost Strategies to allocate Spot Instances: lowestPrice: from the pool with the lowest price (cost optimization, short workload) diversified: distributed across all pools (great for availability, long workloads) capacityOptimized: pool with the optimal capacity for the number of instances Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/5.ElasticIPs.html":{"url":"saa/5.ElasticIPs.html","title":"5. Elastic IPs 及 EC2相关","keywords":"","body":"1. Elastic IPs - have a fixed public IP for your instance2. Placement Groups3. Elastic Network Interfaces (ENI)4. EC2 Hibernate5. EC2 Hibernate – Good to know6. EC2 Nitro7. EC2 – Capacity ReservationsIPv4 allows for 3.7 billion different addresses in the public space 1. Elastic IPs - have a fixed public IP for your instance With an Elastic IP address, you can mask the failure of an instance or software by rapidly remapping the address to another instance in your account. You can only have 5 Elastic IP in your account (you can ask AWS to increase that). Overall, try to avoid using Elastic IP: They often reflect poor architectural decisions Instead, use a random public IP and register a DNS name to it Or, as we'll see later, use a Load Balancer and don't use a public IP 2. Placement Groups Cluster - clusters instances into a low-latency group in a single Availability Zone Pros: Great network (10 Gbps bandwidth between instances with Enhanced Networking enabled - recommended) Cons: If the rack fails, all instances fails at the same time Use case: Big Data job that needs to complete fast Application that needs extremely low latency and high network throughput Spread - spreads instances across underlying hardware (max 7 instances per group per AZ) Pros: Can span across Availability Zones (AZ) Reduced risk is simultaneous failure EC2 Instances are on different physical hardware Cons: Limited to 7 instances per AZ per placement group Use case: Application that needs to maximize high availability Critical Applications where each instance must be isolated from failure from each other Partition - spreads instances across many different partitions (which rely on different sets of racks) within an AZ. Scales to 100s of EC2 instances per group (Hadoop, Cassandra, Kafka) Up to 7 partitions per AZ Can span across multiple AZs in the same region Up to 100s of EC2 instances The instances in a partition do not share racks with the instances in the other partitions A partition failure can affect many EC2 but won’t affect other partitions EC2 instances get access to the partition information as metadata Use cases: HDFS, HBase, Cassandra, Kafka 3. Elastic Network Interfaces (ENI) Logical component in a VPC that represents a virtual network card The ENI can have the following attributes: Primary private IPv4, one or more secondary IPv4 One Elastic IP (IPv4) per private IPv4 One Public IPv4 One or more security groups A MAC address You can create ENI independently and attach them on the fly (move them) on EC2 instances for failover Bound to a specific availability zone (AZ) 4. EC2 Hibernate Under the hood: the RAM state is written to a file in the root EBS volume which must be encrypted Use cases: long-running processing saving the RAM state services that take time to initialize 5. EC2 Hibernate – Good to know Supported instance families - C3, C4, C5, M3, M4, M5, R3, R4, and R5 Instance RAM size - must be less than 150 GB Instance size - not supported for bare metal instances AMI: Amazon Linux 2, Linux AMI, Ubuntu & Windows… Root Volume: must be EBS, encrypted, not instance store, and large Available for On-Demand and Reserved Instances An instance cannot be hibernated more than 60 days 6. EC2 Nitro Underlying Platform for the next generation of EC2 instances, Higher Speed EBS (Nitro is necessary for 64,000 EBS IOPS – max 32,000 on non-Nitro) 7. EC2 – Capacity Reservations Capacity Reservations ensure you have EC2 Capacity when needed Manual or planned end-date for the reservation No need for 1 or 3-year commitment Capacity access is immediate, you get billed as soon as it starts Specify: The Availability Zone in which to reserve the capacity (only one) The number of instances for which to reserve capacity The instance attributes, including the instance type, tenancy, and platform/OS Combine with Reserved Instances and Savings Plans to do cost saving Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/6.EBS.html":{"url":"saa/6.EBS.html","title":"6. EBS, AMI & EFS","keywords":"","body":"1. What's an EBS Volume?2. EBS – Delete on Termination attribute3. EBS Snapshots4. AMI (Amazon Machine Image)5. AMI Process (from an EC2 instance)6. EBS Volume Types7. EBS –Volume Types Summary8. EBS Multi-Attach – io1/io2 family9. EBS Encryption10. Encryption: encrypt an unencrypted EBS volume11. EFS – Elastic File System12. EFS – Performance & Storage Classes13. EBS vs EFS – Elastic Block Storage14. EBS vs EFS – Elastic File System1. What's an EBS Volume? They can only be mounted to one instance at a time (at the CCP level) They are bound to a specific availability zone 2. EBS – Delete on Termination attribute Controls the EBS behaviour when an EC2 instance terminates By default, the root EBS volume is deleted (attribute enabled) By default, any other attached EBS volume is not deleted (attribute disabled) This can be controlled by the AWS console / AWS CLI Use case: preserve root volume when instance is terminated 3. EBS Snapshots Make a backup (snapshot) of your EBS volume at a point in time Not necessary to detach volume to do snapshot, but recommended Can copy snapshots across AZ or Region 4. AMI (Amazon Machine Image) AMI are a customization of an EC2 instance You add your own software, configuration, operating system, monitoring… Faster boot / configuration time because all your software is pre-packaged AMI are built for a specific region (and can be copied across regions) You can launch EC2 instances from: A Public AMI: AWS provided Your own AMI: you make and maintain them yourself An AWS Marketplace AMI: an AMI someone else made (and potentially sells) 5. AMI Process (from an EC2 instance) Start an EC2 instance and customize it Stop the instance (for data integrity) Build an AMI – this will also create EBS snapshots Launch instances from other AMIs 6. EBS Volume Types EBS Volumes come in 6 types gp2 / gp3 (SSD): General purpose SSD volume that balances price and performance for a wide variety of workloads io1 / io2 (SSD): Highest-performance SSD volume for mission-critical low-latency or high-throughput workloads st1 (HDD): Low cost HDD volume designed for frequently accessed, throughputintensive workloads sc1 (HDD): Lowest cost HDD volume designed for less frequently accessed workloads EBS Volumes are characterized in Size | Throughput | IOPS (I/O Ops Per Sec) When in doubt always consult the AWS documentation – it's good! Only gp2/gp3 and io1/io2 can be used as boot volumes 7. EBS –Volume Types Summary Amazon EBS卷类型 8. EBS Multi-Attach – io1/io2 family Attach the same EBS volume to multiple EC2 instances in the same AZ Each instance has full read & write permissions to the volume Use case: Achieve higher application availability in clustered Linux applications (ex: Teradata) Applications must manage concurrent write operations Must use a file system that's cluster-aware (not XFS, EX4, etc…) 9. EBS Encryption When you create an encrypted EBS volume, you get the following: Data at rest is encrypted inside the volume All the data in flight moving between the instance and the volume is encrypted All snapshots are encrypted All volumes created from the snapshot Encryption and decryption are handled transparently (you have nothing to do) Encryption has a minimal impact on latency EBS Encryption leverages keys from KMS (AES-256) Copying an unencrypted snapshot allows encryption Snapshots of encrypted volumes are encrypted 10. Encryption: encrypt an unencrypted EBS volume Create an EBS snapshot of the volume Encrypt the EBS snapshot (using copy) Create new ebs volume from the snapshot (the volume will also be encrypted) Now you can attach the encrypted volume to the original instance 11. EFS – Elastic File System Managed NFS (network file system) that can be mounted on many EC2 EFS works with EC2 instances in multi-AZ Highly available, scalable, expensive (3x gp2), pay per use Use cases: content management, web serving, data sharing,Wordpress Uses NFSv4.1 protocol Uses security group to control access to EFS Compatible with Linux based AMI (not Windows) Encryption at rest using KMS POSIX (Portable Operating System Interface 可移植操作系统接口) file system (~Linux) that has a standard file API File system scales automatically, pay-per-use, no capacity planning! 12. EFS – Performance & Storage Classes EFS Scale 1000s of concurrent NFS clients, 10 GB+ /s throughput Grow to Petabyte-scale network file system, automatically Performance mode (set at EFS creation time) General purpose (default): latency-sensitive use cases (web server, CMS, etc…) Max I/O – higher latency, throughput, highly parallel (big data, media processing) Throughput mode Bursting (1 TB = 50MiB/s + burst of up to 100MiB/s) Provisioned: set your throughput regardless of storage size, ex: 1 GiB/s for 1 TB storage Storage Tiers (lifecycle management feature – move file after N days) Standard: for frequently accessed files Infrequent access (EFS-IA): cost to retrieve files, lower price to store 13. EBS vs EFS – Elastic Block Storage EBS volumes… can be attached to only one instance at a time are locked at the Availability Zone (AZ) level gp2: IO increases if the disk size increases io1: can increase IO independently To migrate an EBS volume across AZ Take a snapshot Restore the snapshot to another AZ EBS backups use IO and you shouldn’t run them while your application is handling a lot of traffic Root EBS Volumes of instances get terminated by default if the EC2 instance gets terminated (you can disable that) 14. EBS vs EFS – Elastic File System Mounting 100s of instances across AZ EFS share website files (WordPress) Only for Linux Instances (POSIX) EFS has a higher price point than EBS Can leverage EFS-IA for cost savings Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-12 12:19:34 "},"saa/7.LB&ASG.html":{"url":"saa/7.LB&ASG.html","title":"7. LB & ASG","keywords":"","body":"1. Why use a load balancer?2. Types of load balancer on AWS3. Sticky Sessions (Session Affinity)4. Sticky Sessions – Cookie Names5. Cross-Zone Load Balancing6. SSL – Server Name Indication (SNI)7. Elastic Load Balancers – SSL Certificates8. ASG Brain Dump9. Auto Scaling Groups - Scaling Cooldowns10. ASG for Solutions Architects11. ASG for Solutions Architects - Lifecycle Hooks1. Why use a load balancer? Spread load across multiple downstream instances Expose a single point of access (DNS) to your application Seamlessly handle failures of downstream instances Do regular health checks to your instances Provide SSL termination (HTTPS) for your websites Enforce stickiness with cookies High availability across zones Separate public traffic from private traffic 2. Types of load balancer on AWS AWS has 4 kinds of managed Load Balancers Classic Load Balancer (v1 - old generation) – 2009 – CLB HTTP, HTTPS, TCP, SSL (secure TCP) Supports TCP (Layer 4), HTTP & HTTPS (Layer 7) Health checks are TCP or HTTP based Fixed hostname : xxx.region.elb.amazonaws.com Application Load Balancer (v2 - new generation) – 2016 – ALB HTTP, HTTPS, WebSocket Application load balancers is Layer 7 (HTTP) Load balancing to multiple HTTP applications across machines (target groups) Load balancing to multiple applications on the same machine (ex: containers) Support for HTTP/2 and WebSocket Support redirects (from HTTP to HTTPS for example) Routing tables to different target groups: Routing based on path in URL (example.com/users & example.com/posts) Routing based on hostname in URL (one.example.com & other.example.com) Routing based on Query String, Headers (example.com/users?id=123&order=false) ALB are a great fit for micro services & container-based application (example: Docker & Amazon ECS) Has a port mapping feature to redirect to a dynamic port in ECS In comparison, we'd need multiple Classic Load Balancer per application Target Groups: EC2 instances (can be managed by an Auto Scaling Group) – HTTP ECS tasks (managed by ECS itself) – HTTP Lambda functions – HTTP request is translated into a JSON event IP Addresses – must be private IPs ALB can route to multiple target groups Health checks are at the target group level Fixed hostname (xxx.region.elb.amazonaws.com) The application servers don’t see the IP of the client directly The true IP of the client is inserted in the header X-Forwarded-For 请求标头可自动添加并帮助您识别客户端的 IP 地址 We can also get Port (X-Forwarded-Port 请求标头可帮助您识别客户端与您的负载均衡器连接时所用的目标端口) and proto (X-Forwarded-Proto 请求标头可帮助您识别客户端与您的负载均衡器连接时所用的协议 (HTTP 或 HTTPS)) Network Load Balancer (v2 - new generation) – 2017 – NLB TCP, TLS (secure TCP), UDP Network load balancers (Layer 4) allow to: Forward TCP & UDP traffic to your instances Handle millions of request per seconds Less latency ~100 ms (vs 400 ms for ALB) NLB has one static IP per AZ, and supports assigning Elastic IP (helpful for whitelisting specific IP) NLB are used for extreme performance, TCP or UDP traffic Target Groups: EC2 instances IP Addresses – must be private IPs Application Load Balancer Gateway Load Balancer – 2020 – GWLB Operates at layer 3 (Network layer) – IP Protocol Deploy, scale, and manage a fleet of 3rd party network virtual appliances in AWS Example: Firewalls, Intrusion Detection and Prevention Systems, Deep Packet Inspection Systems, payload manipulation, … Operates at Layer 3 (Network Layer) – IP Packets Combines the following functions: Transparent Network Gateway – single entry/exit for all traffic Load Balancer – distributes traffic to your virtual appliances Uses the GENEVE protocol on port 6081 Target Groups: EC2 instances IP Addresses – must be private IPs 3. Sticky Sessions (Session Affinity) It is possible to implement stickiness so that the same client is always redirected to the same instance behind a load balancer This works for Classic Load Balancers & Application Load Balancers The \"cookie\" used for stickiness has an expiration date you control Use case: make sure the user doesn’t lose his session data Enabling stickiness may bring imbalance to the load over the backend EC2 instances 4. Sticky Sessions – Cookie Names Application-based Cookies Custom cookie Generated by the target Can include any custom attributes required by the application Cookie name must be specified individually for each target group Don’t use AWSALB, AWSALBAPP, or AWSALBTG (reserved for use by the ELB) Application cookie Generated by the load balancer Cookie name is AWSALBAPP Duration-based Cookies Cookie generated by the load balancer Cookie name is AWSALB for ALB, AWSELB for CLB 5. Cross-Zone Load Balancing Application Load Balancer Always on (can't be disabled) No charges for inter AZ data Network Load Balancer Disabled by default You pay charges ($) for inter AZ data if enabled Classic Load Balancer Disabled by default No charges for inter AZ data if enabled 6. SSL – Server Name Indication (SNI) SSL refers to Secure Sockets Layer, used to encrypt connections TLS refers to Transport Layer Security, which is a newer version SNI solves the problem of loading multiple SSL certificates onto one web server (to serve multiple websites) It's a \"newer\" protocol, and requires the client to indicate the hostname of the target server in the initial SSL handshake The server will then find the correct certificate, or return the default one *Note: Only works for ALB & NLB (newer generation), CloudFront Does not work for CLB (older gen) 7. Elastic Load Balancers – SSL Certificates Classic Load Balancer (v1) Support only one SSL certificate Must use multiple CLB for multiple hostname with multiple SSL certificates Application Load Balancer (v2) & Network Load Balancer (v2) Supports multiple listeners with multiple SSL certificates Uses Server Name Indication (SNI) to make it work 8. ASG Brain Dump Scaling policies can be on CPU, Network… and can even be on custom metrics or based on a schedule (if you know your visitors patterns) ASGs use Launch configurations or Launch Templates (newer) To update an ASG, you must provide a new launch configuration / launch template IAM roles attached to an ASG will get assigned to EC2 instances ASG are free. You pay for the underlying resources being launched Having instances under an ASG means that if they get terminated for whatever reason, the ASG will automatically create new ones as a replacement. Extra safety! ASG can terminate instances marked as unhealthy by an LB (and hence replace them) 9. Auto Scaling Groups - Scaling Cooldowns After a scaling activity happens, you are in the cooldown period (default 300 seconds) During the cooldown period, the ASG will not launch or terminate additional instances (to allow for metrics to stabilize) Advice: Use a ready-to-use AMI to reduce configuration time in order to be serving request fasters and reduce the cooldown period 10. ASG for Solutions Architects ASG Default Termination Policy (simplified version): Find the AZ which has the most number of instances If there are multiple instances in the AZ to choose from, delete the one with the oldest launch configuration ASG tries the balance the number of instances across AZ by default 11. ASG for Solutions Architects - Lifecycle Hooks By default as soon as an instance is launched in an ASG it’s in service. You have the ability to perform extra steps before the instance goes in service (Pending state) You have the ability to perform some actions before the instance is terminated (Terminating state) Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/8.RDS, Aurora & ElastiCache.html":{"url":"saa/8.RDS, Aurora & ElastiCache.html","title":"8. RDS, Aurora & ElastiCache","keywords":"","body":"1. RDS Backups2. RDS – Storage Auto Scaling3. RDS Read Replicas for read scalability4. RDS Read Replicas – Network Cost5. RDS Multi AZ (Disaster Recovery)6. RDS – From Single-AZ to Multi-AZ7. RDS Security - Encryption8. RDS Security – IAM9. RDS - IAM Authentication10. Amazon Aurora11. Aurora High Availability and Read Scaling12. Aurora – Custom Endpoints13. Global Aurora14. ElastiCache – Redis vs Memcached15. ElastiCache – Cache Security16. Patterns for ElastiCache17. ElastiCache – Redis Use Case1. RDS Backups Backups are automatically enabled in RDS Automated backups: Daily full backup of the database (during the maintenance window) Transaction logs are backed-up by RDS every 5 minutes => ability to restore to any point in time (from oldest backup to 5 minutes ago) 7 days retention (can be increased to 35 days) DB Snapshots: Manually triggered by the user Retention of backup for as long as you want 2. RDS – Storage Auto Scaling Helps you increase storage on your RDS DB instance dynamically When RDS detects you are running out of free database storage, it scales automatically Avoid manually scaling your database storage You have to set Maximum Storage Threshold (maximum limit for DB storage) Automatically modify storage if: Free storage is less than 10% of allocated storage Low-storage lasts at least 5 minutes 6 hours have passed since last modification Useful for applications with unpredictable workloads Supports all RDS database engines (MariaDB, MySQL, PostgreSQL, SQL Server, Oracle) 3. RDS Read Replicas for read scalability Up to 5 Read Replicas Within AZ, Cross AZ or Cross Region Replication is ASYNC, so reads are eventually consistent Replicas can be promoted to their own DB Applications must update the connection string to leverage read replicas 4. RDS Read Replicas – Network Cost In AWS there's a network cost when data goes from one AZ to another For RDS Read Replicas within the same region, you don't pay that fee 5. RDS Multi AZ (Disaster Recovery) SYNC replication, Increase availability 6. RDS – From Single-AZ to Multi-AZ Zero downtime operation (no need to stop the DB) Just click on \"modify\" for the database The following happens internally: A snapshot is taken A new DB is restored from the snapshot in a new AZ Synchronization is established between the two databases 7. RDS Security - Encryption At rest encryption Possibility to encrypt the master & read replicas with AWS KMS - AES-256 encryption Encryption has to be defined at launch time If the master is not encrypted, the read replicas cannot be encrypted Transparent Data Encryption (TDE) available for Oracle and SQL Server In-flight encryption SSL certificates to encrypt data to RDS in flight Provide SSL options with trust certificate when connecting to database To enforce SSL: PostgreSQL: rds.force_ssl=1 in the AWS RDS Console (Parameter Groups) MySQL: Within the DB: GRANT USAGE ON . TO 'mysqluser'@'%' REQUIRE SSL; 8. RDS Security – IAM Access Management IAM policies help control who can manage AWS RDS (through the RDS API) Traditional Username and Password can be used to login into the database IAM-based authentication can be used to login into RDS MySQL & PostgreSQL 9. RDS - IAM Authentication IAM database authentication works with MySQL and PostgreSQL You don’t need a password, just an authentication token obtained through IAM & RDS API calls Auth token has a lifetime of 15 minutes Benefits: Network in/out must be encrypted using SSL IAM to centrally manage users instead of DB Can leverage IAM Roles and EC2 Instance profiles for easy integration 10. Amazon Aurora Aurora is a proprietary technology from AWS (not open sourced) Postgres and MySQL are both supported as Aurora DB (that means your drivers will work as if Aurora was a Postgres or MySQL database) Aurora is “AWS cloud optimized” and claims 5x performance improvement over MySQL on RDS, over 3x the performance of Postgres on RDS Aurora storage automatically grows in increments of 10GB, up to 128 TB. Aurora can have 15 replicas while MySQL has 5, and the replication process is faster (sub 10 ms replica lag) Failover in Aurora is instantaneous. It’s HA (High Availability) native. Aurora costs more than RDS (20% more) – but is more efficient 11. Aurora High Availability and Read Scaling 6 copies of your data across 3 AZ: 4 copies out of 6 needed for writes 3 copies out of 6 need for reads Self healing with peer-to-peer replication Storage is striped across 100s of volumes One Aurora Instance takes writes (master) Automated failover for master in less than 30 seconds Master + up to 15 Aurora Read Replicas serve reads Support for Cross Region Replication 12. Aurora – Custom Endpoints Define a subset of Aurora Instances as a Custom Endpoint Example: Run analytical queries on specific replicas The Reader Endpoint is generally not used after defining Custom Endpoints 13. Global Aurora Aurora Cross Region Read Replicas: Useful for disaster recovery Simple to put in place Aurora Global Database (recommended): 1 Primary Region (read / write) Up to 5 secondary (read-only) regions, replication lag is less than 1 second Up to 16 Read Replicas per secondary region Helps for decreasing latency Promoting another region (for disaster recovery) has an RTO of 14. ElastiCache – Redis vs Memcached Redis： Multi AZ with Auto-Failover Read Replicas to scale reads and have high availability Data Durability using AOF persistence Backup and restore features Memcached： Multi-node for partitioning of data (sharding) No high availability (replication) Non persistent No backup and restore Multi-threaded architecture 15. ElastiCache – Cache Security All caches in ElastiCache: Do not support IAM authentication IAM policies on ElastiCache are only used for AWS API-level security Redis AUTH You can set a \"password/token\" when you create a Redis cluster This is an extra level of security for your cache (on top of security groups) Support SSL in flight encryption Memcached Supports SASL-based authentication (advanced) 16. Patterns for ElastiCache Lazy Loading: all the read data is cached, data can become stale in cache Write Through: Adds or update data in the cache when written to a DB (no stale data) Session Store: store temporary session data in a cache (using TTL features) Quote: There are only two hard things in Computer Science: cache invalidation 缓存失效 and naming things 17. ElastiCache – Redis Use Case 游戏排行榜的复杂计算 Redis排序集保证了唯一性和元素顺序 每次添加新元素时，都会对其进行实时排名，然后添加到正确的顺序 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/9.路由.html":{"url":"saa/9.路由.html","title":"9. 路由","keywords":"","body":"1. DNS Terminologies2. Amazon Route 533. Route 53 – Records4. Route 53 – Record Types5. Route 53 – Records TTL (Time To Live)6. CNAME vs Alias7. Routing Policies - Simple8. Routing Policies – Weighted9. Route 53 – Health Checks10. Health Checks – Monitor an Endpoint11. Routing Policies – Multi-Value12. Instantiating Applications quickly13. Elastic Beanstalk – Overview14. Elastic Beanstalk – Components1. DNS Terminologies Domain Registrar: Amazon Route 53, GoDaddy, … DNS Records: A, AAAA, CNAME, NS, … Zone File: contains DNS records Name Server: resolves DNS queries (Authoritative or Non-Authoritative) Top Level Domain (TLD): .com, .us, .in, .gov, .org, … Second Level Domain (SLD): amazon.com, google.com, … 2. Amazon Route 53 A highly available, scalable, fully managed and Authoritative DNS Authoritative = the customer (you) can update the DNS records Route 53 is also a Domain Registrar Ability to check the health of your resources The only AWS service which provides 100% availability SLA (Service Level Agreements 服务级协定) Why Route 53? 53 is a reference to the traditional DNS port $0.50 per month per hosted zone 3. Route 53 – Records Domain/subdomain Name – e.g., example.com Record Type – e.g., A or AAAA Value – e.g., 12.34.56.78 Routing Policy – how Route 53 responds to queries TTL – amount of time the record cached at DNS Resolvers 4. Route 53 – Record Types A – maps a hostname to IPv4 AAAA – maps a hostname to IPv6 CNAME – maps a hostname to another hostname The target is a domain name which must have an A or AAAA record Can't create a CNAME record for the top node of a DNS namespace (Zone Apex) Example: you can't create for example.com, but you can create for www.example.com NS – Name Servers for the Hosted Zone Control how traffic is routed for a domain 5. Route 53 – Records TTL (Time To Live) Except for Alias records, TTL is mandatory for each DNS record 6. CNAME vs Alias AWS Resources (Load Balancer, CloudFront...) expose an AWS hostname: lb1-1234.us-east-2.elb.amazonaws.com and you want myapp.mydomain.com CNAME: Points a hostname to any other hostname (app.mydomain.com => blabla.anything.com) ONLY FOR NON ROOT DOMAIN (aka something.mydomain.com) Alias: Points a hostname to an AWS Resource (app.mydomain.com => blabla.amazonaws.com) Works for ROOT DOMAIN and NON ROOT DOMAIN (aka mydomain.com) Free of charge Native health check Alias Record is always of type A/AAAA for AWS resources (IPv4 / IPv6) You can't set the TTL You cannot set an ALIAS record for an EC2 DNS name 7. Routing Policies - Simple If multiple values are returned, a random one is chosen by the client When Alias enabled, specify only one AWS resource Can't be associated with Health Checks 8. Routing Policies – Weighted Control the % of the requests that go to each specific resource Assign each record a relative weight, Weights don't need to sum up to 100 DNS records must have the same name and type Can be associated with Health Checks Use cases: load balancing between regions, testing new application versions… Assign a weight of 0 to a record to stop sending traffic to a resource If all records have weight of 0, then all records will be returned equally 9. Route 53 – Health Checks HTTP Health Checks are only for public resources Health Check => Automated DNS Failover: Health checks that monitor an endpoint (application, server, other AWS resource) Health checks that monitor other health checks (Calculated Health Checks) Health checks that monitor CloudWatch Alarms (full control !!) – e.g., throttles of DynamoDB, alarms on RDS, custom metrics, … (helpful for private resources) Health Checks are integrated with CW metrics 10. Health Checks – Monitor an Endpoint About 15 global health checkers will check the endpoint health Healthy/Unhealthy Threshold – 3 (default) Interval – 30 sec (can set to 10 sec – higher cost) Supported protocol: HTTP, HTTPS and TCP If > 18% of health checkers report the endpoint is healthy, Route 53 considers it Healthy. Otherwise, it’s Unhealthy Ability to choose which locations you want Route 53 to use Health Checks pass only when the endpoint responds with the 2xx and 3xx status codes Health Checks can be setup to pass / fail based on the text in the first 5120 bytes of the response Configure you router/firewall to allow incoming requests from Route 53 Health Checkers 11. Routing Policies – Multi-Value Use when routing traffic to multiple resources Route 53 return multiple values/resources Can be associated with Health Checks (return only values for healthy resources) Up to 8 healthy records are returned for each Multi-Value query Multi-Value is not a substitute for having an ELB 12. Instantiating Applications quickly EC2 Instances: Use a Golden AMI: Install your applications, OS dependencies etc.. beforehand and launch your EC2 instance from the Golden AMI Bootstrap using User Data: For dynamic configuration, use User Data scripts Hybrid: mix Golden AMI and User Data (Elastic Beanstalk) RDS Databases: Restore from a snapshot: the database will have schemas and data ready! EBS Volumes: Restore from a snapshot: the disk will already be formatted and have data! 13. Elastic Beanstalk – Overview Elastic Beanstalk is a developer centric view of deploying an application on AWS It uses all the component's we've seen before: EC2, ASG, ELB, RDS, … Managed service Automatically handles capacity provisioning, load balancing, scaling, application health monitoring, instance configuration, … Just the application code is the responsibility of the developer We still have full control over the configuration Beanstalk is free but you pay for the underlying instances 14. Elastic Beanstalk – Components Application: collection of Elastic Beanstalk components (environments, versions, configurations, …) Application Version: an iteration of your application code Environment Collection of AWS resources running an application version (only one application version at a time) Tiers: Web Server Environment Tier & Worker Environment Tier You can create multiple environments (dev, test, prod, …) Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/10.S3, FSx & Storage Gateway.html":{"url":"saa/10.S3, FSx & Storage Gateway.html","title":"10. S3, FSx & Storage Gateway","keywords":"","body":"1. Amazon S3 Overview - Buckets2. Amazon S3 Overview – Objects3. S3 Encryption for Objects4. S3 Security5. CORS (Cross-Origin Resource Sharing)6. AWS EC2 Instance Metadata7. Amazon FSx8. Amazon FSx for Windows (File Server)9. Amazon FSx for Lustre10. AWS Storage Gateway11. File Gateway12. Volume Gateway13. Tape Gateway14. Storage Comparison1. Amazon S3 Overview - Buckets Amazon S3 allows people to store objects (files) in \"buckets\" (directories) Buckets must have a globally unique name Buckets are defined at the region level Naming convention No uppercase No underscore 3-63 characters long Not an IP Must start with lowercase letter or number 2. Amazon S3 Overview – Objects Object values are the content of the body: Max Object Size is 5TB (5000GB) If uploading more than 5GB, must use \"multi-part upload\" Metadata (list of text key / value pairs – system or user metadata) Tags (Unicode key / value pair – up to 10) – useful for security / lifecycle Version ID (if versioning is enabled) 3. S3 Encryption for Objects SSE-S3: encrypts S3 objects using keys handled & managed by AWS Object is encrypted server side AES-256 encryption type Must set header: \"x-amz-server-side-encryption\": \"AES256\" SSE-KMS: leverage AWS Key Management Service to manage encryption keys SSE-KMS: encryption using keys handled & managed by KMS KMS Advantages: user control + audit trail Object is encrypted server side Must set header: \"x-amz-server-side-encryption\": \"aws:kms\" SSE-C: when you want to manage your own encryption keys server-side encryption using data keys fully managed by the customer outside of AWS Amazon S3 does not store the encryption key you provide HTTPS must be used Encryption key must provided in HTTP headers, for every HTTP request made Client Side Encryption Client library such as the Amazon S3 Encryption Client Clients must encrypt data themselves before sending to S3 Clients must decrypt data themselves when retrieving from S3 Customer fully manages the keys and encryption cycle 4. S3 Security User based IAM policies - which API calls should be allowed for a specific user from IAM console Resource Based Bucket Policies - bucket wide rules from the S3 console - allows cross account Object Access Control List (ACL) – finer grain Bucket Access Control List (ACL) – less common Note: an IAM principal can access an S3 object if the user IAM permissions allow it OR the resource policy ALLOWS it AND there's no explicit DENY 5. CORS (Cross-Origin Resource Sharing) using CORS Headers (ex: Access-Control-Allow-Origin) 6. AWS EC2 Instance Metadata AWS EC2 Instance Metadata is powerful but one of the least known features to developers It allows AWS EC2 instances to \"learn about themselves\" without using an IAM Role for that purpose. The URL is http://169.254.169.254/latest/meta-data You can retrieve the IAM Role name from the metadata, but you CANNOT retrieve the IAM Policy 7. Amazon FSx Launch 3rd party high-performance file systems on AWS Fully managed service 8. Amazon FSx for Windows (File Server) EFS is a shared POSIX system for Linux systems. FSx for Windows is a fully managed Windows file system share drive Supports SMB protocol & Windows NTFS Microsoft Active Directory integration, ACLs, user quotas Built on SSD, scale up to 10s of GB/s, millions of IOPS, 100s PB of data Can be accessed from your on-premise infrastructure Can be configured to be Multi-AZ (high availability) Data is backed-up daily to S3 9. Amazon FSx for Lustre Lustre is a type of parallel distributed file system, for large-scale computing The name Lustre is derived from \"Linux\" and \"cluster\" Machine Learning, High Performance Computing (HPC) Video Processing, Financial Modeling, Electronic Design Automation Scales up to 100s GB/s, millions of IOPS, sub-ms latencies Seamless integration with S3 Can \"read S3\" as a file system (through FSx) Can write the output of the computations back to S3 (through FSx) Can be used from on-premise servers 10. AWS Storage Gateway Bridge between on-premises data and cloud data in S3 Use cases: disaster recovery, backup & restore, tiered storage 11. File Gateway Configured S3 buckets are accessible using the NFS and SMB protocol Supports S3 standard, S3 IA, S3 One Zone IA Bucket access using IAM roles for each File Gateway Most recently used data is cached in the file gateway Can be mounted on many servers Integrated with Active Directory (AD) for user authentication 12. Volume Gateway Block storage using iSCSI protocol backed by S3 Backed by EBS snapshots which can help restore on-premises volumes! Cached volumes: low latency access to most recent data Stored volumes: entire dataset is on premise, scheduled backups to S3 13. Tape Gateway Some companies have backup processes using physical tapes (!) With Tape Gateway, companies use the same processes but, in the cloud Virtual Tape Library (VTL) backed by Amazon S3 and Glacier Back up data using existing tape-based processes (and iSCSI interface) Works with leading backup software vendors 14. Storage Comparison S3: Object Storage Glacier: Object Archival EFS: Network File System for Linux instances, POSIX filesystem FSx for Windows: Network File System for Windows servers FSx for Lustre: High Performance Computing Linux file system EBS volumes: Network storage for one EC2 instance at a time Instance Storage: Physical storage for your EC2 instance (high IOPS) Storage Gateway: File Gateway, Volume Gateway (cache & stored), Tape Gateway Snowball / Snowmobile: to move large amount of data to the cloud, physically Database: for specific workloads, usually with indexing and querying Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/11.S3, Glacier & Athena.html":{"url":"saa/11.S3, Glacier & Athena.html","title":"11. S3, Glacier & Athena","keywords":"","body":"1. S3 MFA-Delete2. S3 Replication (CRR & SRR)3. S3 Replication – Notes4. S3 Pre-Signed URLs5. Amazon S3存储类别6. S3 – Moving between storage classes7. S3 Lifecycle Rules8. S3 Analytics – Storage Class Analysis9. S3 – Baseline Performance10. S3 Performance11. Athena1. S3 MFA-Delete MFA (multi factor authentication) forces user to generate a code on a device (usually a mobile phone or hardware) before doing important operations on S3 To use MFA-Delete, enable Versioning on the S3 bucket You will need MFA to permanently delete an object version suspend versioning on the bucket You won’t need MFA for enabling versioning listing deleted versions Only the bucket owner (root account) can enable/disable MFA-Delete MFA-Delete currently can only be enabled using the CLI *Note: Bucket Policies are evaluated before \"default encryption\" 2. S3 Replication (CRR & SRR) Must enable versioning in source and destination Cross Region Replication (CRR) Same Region Replication (SRR) Buckets can be in different accounts Copying is asynchronous Must give proper IAM permissions to S3 CRR - Use cases: compliance, lower latency access, replication across accounts SRR – Use cases: log aggregation, live replication between production and test accounts 3. S3 Replication – Notes After activating, only new objects are replicated (not retroactive) For DELETE operations: Can replicate delete markers from source to target (optional setting) Deletions with a version ID are not replicated (to avoid malicious deletes) There is no \"chaining\" of replication If bucket 1 has replication into bucket 2, which has replication into bucket 3 Then objects created in bucket 1 are not replicated to bucket 3 4. S3 Pre-Signed URLs Can generate pre-signed URLs using SDK or CLI For downloads (easy, can use the CLI) For uploads (harder, must use the SDK) Valid for a default of 3600 seconds, can change timeout with --expires-in [TIME_BY_SECONDS] argument Users given a pre-signed URL inherit the permissions of the person who generated the URL for GET / PUT 5. Amazon S3存储类别 S3 Storage Classes Comparison 6. S3 – Moving between storage classes 7. S3 Lifecycle Rules Transition actions: It defines when objects are transitioned to another storage class. Move objects to Standard IA class 60 days after creation Move to Glacier for archiving after 6 months Expiration actions: configure objects to expire (delete) after some time Access log files can be set to delete after a 365 days Can be used to delete old versions of files (if versioning is enabled) Can be used to delete incomplete multi-part uploads Rules can be created for a certain prefix (ex - s3://mybucket/mp3/*) Rules can be created for certain objects tags (ex - Department: Finance) 8. S3 Analytics – Storage Class Analysis You can setup S3 Analytics to help determine when to transition objects from Standard to Standard_IA Does not work for ONEZONE_IA or GLACIER Report is updated daily Takes about 24h to 48h hours to first start Good first step to put together Lifecycle Rules (or improve them)! 9. S3 – Baseline Performance Amazon S3 automatically scales to high request rates, latency 100-200 ms Your application can achieve at least 3,500 PUT/COPY/POST/DELETE and 5,500 GET/HEAD requests per second per prefix in a bucket 10. S3 Performance Multi-Part upload: recommended for files > 100MB, must use for files > 5GB Can help parallelize uploads (speed up transfers) S3 Transfer Acceleration Increase transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region Compatible with multi-part upload 11. Athena one time SQL queries, serverless queries on S3, log analytics Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/12.CloudFront, SQS, SNS & Kinesis.html":{"url":"saa/12.CloudFront, SQS, SNS & Kinesis.html","title":"12. CloudFront, SQS, SNS & Kinesis","keywords":"","body":"1. CloudFront vs S3 Cross Region Replication2. CloudFront Signed URL Diagram3. CloudFront Signed URL vs S3 Pre-Signed URL4. Unicast IP vs Anycast IP5. AWS Global Accelerator vs CloudFront6. Amazon SQS – Standard Queue7. Kinesis1. CloudFront vs S3 Cross Region Replication CloudFront: Global Edge network Files are cached for a TTL (maybe a day) Great for static content that must be available everywhere S3 Cross Region Replication: Must be setup for each region you want replication to happen Files are updated in near real-time Read only Great for dynamic content that needs to be available at low-latency in few regions 2. CloudFront Signed URL Diagram 3. CloudFront Signed URL vs S3 Pre-Signed URL CloudFront Signed URL: Allow access to a path, no matter the origin Account wide key-pair, only the root can manage it Can filter by IP, path, date, expiration Can leverage caching features S3 Pre-Signed URL: Issue a request as the person who pre-signed the URL Uses the IAM key of the signing IAM principal Limited lifetime 4. Unicast IP vs Anycast IP Unicast IP: one server holds one IP address Anycast IP: all servers hold the same IP address and the client is routed to the nearest one 5. AWS Global Accelerator vs CloudFront They both use the AWS global network and its edge locations around the world Both services integrate with AWS Shield for DDoS protection. CloudFront Improves performance for both cacheable content (such as images and videos) Dynamic content (such as API acceleration and dynamic site delivery) Content is served at the edge Global Accelerator Improves performance for a wide range of applications over TCP or UDP Proxying packets at the edge to applications running in one or more AWS Regions. Good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP Good for HTTP use cases that require static IP addresses Good for HTTP use cases that required deterministic, fast regional failover using SQS: queue model using SNS: pub/sub model using Kinesis: real-time streaming model 6. Amazon SQS – Standard Queue Oldest offering (over 10 years old) Fully managed service, used to decouple applications Attributes: Unlimited throughput, unlimited number of messages in queue Default retention of messages: 4 days, maximum of 14 days Low latency ( Limitation of 256KB per message sent Can have duplicate messages (at least once delivery, occasionally) Can have out of order messages (best effort ordering) 7. Kinesis Kinesis Data Streams: capture, process, and store data streams Kinesis Data Firehose: load data streams into AWS data stores 以可靠方式将实时数据串流加载到数据湖、数据库和分析服务中 Kinesis Data Analytics: analyze data streams with SQL or Apache Flink Kinesis Video Streams: capture, process, and store video streams Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/13.DynamoDB, QuickSight, Redshift及安全相关.html":{"url":"saa/13.DynamoDB, QuickSight, Redshift及安全相关.html","title":"13. DynamoDB, QuickSight, Redshift及安全相关","keywords":"","body":"1. DynamoDB2. QuickSight3. Redshift4. WAF, Shield Advanced5. CloudHSM6. Secrets Manager1. DynamoDB 读取容量单位Readcapacityunit(RCU)：从表中读取数据的每个API调用都是一个读取请求。读取请求可以是强一致性、最终一致性或事务性读取请求。对最大4KB的项目，一个RCU每秒可以执行一个强一致性读取请求。大于4KB的项目需要额外的RCU。对最大4KB的项目，一个RCU每秒可以执行两个最终一致性读取请求。对最大4KB的项目，事务性读取请求需要两个RCU才能每秒执行一个读取请求。例如，对8KB项目的强一致性读取需要两个RCU，对8KB项目的最终一致性读取需要一个RCU，而对8KB项目的事务性读取需要四个RCU。有关详细信息，请参阅读取一致性。 写入容量单位Writecapacityunit(WCU)：将数据写入表的每个API调用都是一个写入请求。对最大1KB的项目，一个WCU每秒可以执行一个标准写入请求。大于1KB的项目需要额外的WCU。对最大1KB的项目，事务性写入请求需要两个WCU才能每秒执行一个写入请求。例如，对1KB项目的标准写入请求需要一个WCU，对3KB项目的标准写入请求需要三个WCU，而对3KB项目的事务性写入请求需要六个RCU。 2. QuickSight Amazon QuickSight 允许您的企业中的所有人通过使用自然语言提问以了解您的数据，通过交互式控制面板探索，或自动查找由机器学习支持的模式和异常值。 3. Redshift Redshift is based on PostgreSQL, but it’s not used for OLTP It's OLAP – online analytical processing (analytics and data warehousing) 10x better performance than other data warehouses, scale to PBs of data Columnar storage of data (instead of row based) Massively Parallel Query Execution (MPP) Pay as you go based on the instances provisioned Has a SQL interface for performing the queries BI tools such as AWS Quicksight or Tableau integrate with it 4. WAF, Shield Advanced 什么是AWS WAF、AWS和 ShieldAWS Firewall Manager? 5. CloudHSM AWS CloudHSM 是基于云的硬件安全模块 (HSM)，让您能够在 AWS 云上轻松生成和使用自己的加密密钥。借助 CloudHSM，您可以使用经过 FIPS 140-2 第 3 级验证的 HSM 管理自己的加密密钥。CloudHSM 让您可以灵活选择使用行业标准的 API 与应用程序集成，这些 API 包括 PKCS#11、Java 加密扩展 (JCE) 和 Microsoft CryptoNG (CNG) 库等。 此外，CloudHSM 符合标准，让您可以将所有密钥导出到大多数其他商用 HSM，具体取决于您的配置。它是一项完全托管的服务，可为您自动执行耗时的管理任务，例如硬件预置、软件修补、高可用性和备份。借助 CloudHSM，您还能够通过按需添加和删除 HSM 容量进行快速扩展和收缩，无任何预付费用。 6. Secrets Manager AWS Secrets Manager 可帮助您保护访问应用程序、服务和 IT 资源所需的密钥。该服务使您能够轻松地跨整个生命周期轮换、管理和检索数据库凭证、API 密钥和其他密钥。用户和应用程序通过调用 Secrets Manager API 来检索密钥，无需对纯文本的敏感信息进行硬编码。Secrets Manager 通过适用于 Amazon RDS、Amazon Redshift 和 Amazon DocumentDB 的内置集成实现密钥轮换。此外，该服务还可以扩展到其他类型的密钥，包括 API 密钥和 OAuth 令牌。此外，Secrets Manager 使您能够使用精细权限来访问机密信息，并集中审核对 AWS 云、第三方服务和本地资源的密钥轮换。 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/14.ECS.html":{"url":"saa/14.ECS.html","title":"14. ECS","keywords":"","body":"1. 集群 Cluster2. 容器和镜像3. 任务定义4. 任务5. 服务6. 容器代理1. 集群 Cluster Amazon ECS 集群是任务或服务的逻辑分组。您可以使用集群隔离应用程序。这样，他们就不会使用相同的底层基础设施。当您的任务在 Fargate 上运行时，您的集群资源也由 Fargate 托管。 2. 容器和镜像 要在 Amazon ECS 上部署应用程序，必须配置应用程序组件以在容器中运行。容器是软件开发的标准化单位，它包含软件应用程序运行需要的所有内容。这包括相关代码、运行时、系统工具和系统库。从称为映像的只读模板中创建容器。 通常通过 Dockerfile 进行构建镜像。Dockerfile 是一个纯文本文件，指定了容器中包含的所有组件。构建完成后，这些映像将存储在可从中下载它们的注册表。然后，下载后，您可以使用它们在集群上运行。有关容器技术的更多信息，请参阅 Amazon ECS 的 Docker 基本信息。 3. 任务定义 任务定义是描述构成应用程序的一个或多个容器的文本文件，该文件以 JSON 格式。您可以使用它来描述最多 10 个容器。任务定义可以用作应用程序的蓝图。它为您的应用程序指定各种参数。例如，您可以使用它指定操作系统的参数、要使用哪些容器、要为应用程序打开哪些端口以及任务中的容器应使用哪些数据卷。可用于任务定义的特定参数取决于您的特定应用程序需求。 您的整个应用程序堆栈不需要存在于单个任务定义上。实际上，我们建议您的应用程序跨越多个任务定义。您的应用程序可通过将相关容器组合到其自己的任务定义（每个任务定义表示一个组件）中来操作。 4. 任务 任务 是集群内的任务定义的实例化。在为 Amazon ECS 中的应用程序创建任务定义后，您可以指定将在集群上运行的任务的数量。您可以运行独立任务，也可以将任务作为服务的一部分运行。 5. 服务 您可以使用 Amazon ECS 服务在 Amazon ECS 集群中同时运行和维护所需数量的任务。它的工作原理是，如果您的任何任务出于任何原因失败或停止，Amazon ECS 服务调度器将根据您的任务定义启动另一个实例。这样做是为了替换它，从而保持服务中所需的任务数量。 6. 容器代理 容器代理 在 Amazon ECS 群集内的每个实例上运行。代理向 Amazon ECS 发送有关容器当前正在运行的任务和资源使用率的信息。在接收来自 Amazon ECS 的请求时启动和停止任务。有关更多信息，请参阅 Amazon ECS 容器代理。 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"saa/15.考前速记.html":{"url":"saa/15.考前速记.html","title":"15. 考前速记（已通过 SAA）","keywords":"","body":"已通过 2022.07.01 记考前速记已通过 2022.07.01 记 推荐资料： Console AWS文档 AWS白皮书 ExamTopics Jayendra LiuYuchen Bing哥的博客 Partner Central 考前速记 Inspector 漏洞修复 GuardDuty 威胁检测 WAF(Web Application Firewall) 跨站脚本、SQL注入、定义IP规则 ALB Sheild DDos NLB CloudHSM(Hardware Security Module) 生成和使用密钥 Secrets Manager 保护、轮换密钥、凭证 Parameter Store 不支持密码轮换 KMS(Key Management Service) 创建和管理加密密钥，并控制其在各种 AWS 服务和应用程序中的使用，支持轮换在HSM中生成的密钥 Secrets Manager是管理/储存secret的地方；KMS是管理加密金钥(key)的地方。而Secrets Manager新增secrets时需要将secret加密(encrypt)，后续要使用secret时需要解密(decrypt)，而加解密secrets使用的key则是由KMS来管理。所以Secrets Manager与KMS经常搭配使用。 DataSync 本地 → AWS，不应该长时间持续使用 Direct Connect 建立需要约几个月 支持REST API：S3、API Gateway 支持VPC Gateway：S3、DynamoDB CloudTrail 默认开启管理事件 DynamoDB DAX 内存缓存，微秒级 → Redis 亚毫秒级 Fsx 支持SMB(Server Message Block)、ACL、DFSR(Distributed File System Replication 分布式文件系统复制) FSx for Lustre 亚毫秒级延迟、HPC(FSx for Windows 不支持) CloudFront 不在子网内，不适用ACL Auto Scaling在最后一个启动的实例完成冷却期后才会接受扩展活动请求 Redshift 随着数据和查询复杂度的增长，保持高性能；防止报告和分析处理干扰OLTP(Online Transaction Processing)工作负载的性能；使用标准SQL和现有BI工具保存和查询大量结构化数据；自动运行自己的数据仓库和处理设置、持久性、监控、扩展和修补 Redshift 使用列式数据存储 Gateway-cached 将数据存储在Amazon Simple Storage Service (Amazon S3) 并在本地保留经常访问的数据子集的副本 Gateway-stored 可以将所有数据储存在本地存储，然后异步备份将此数据传输到 Amazon S3 Memcached不支持数据复制或高可用性，Redis支持 EBS snapshot 最大1TB 一个 VPC 可以跨越多个可用区，子网必须驻留在单个可用区内 SES(Simple Email Service) Oracle Data Pump导入大量数据；Oracle SQL Developer 导入20MB数据库 EBS optimimzed instance 平均IOPS 90% AWS 导入/导出支持：导入导出S3；导入EBS；导入Glacier。不支持：导出EBS；导出Glacier Route 53原生支持带有内部健康检查的ELB，开启评估目标健康，关闭关联Health Check 每个Region限制5个弹性IP EC2-Classic须使用专门的安全组，不能用EIP LB使用HTTP检查实例的运行状况 Amazon EMR(Elastic MapReduce) 使用 Apache Hadoop 作为其分布式数据处理引擎。Hadoop 是一个开源的 Java 软件框架，支持在大型商品硬件集群上运行的数据密集型分布式应用程序。Hadoop 实现了一个名为“MapReduce”的编程模型，其中数据被分成许多小的工作片段，每个片段都可以在集群中的任何节点上执行。该框架已被开发人员、企业和初创公司广泛使用，并被证明是处理高达 PB 级数据的可靠软件平台，数千台商品机器集群的数据。 ECS目前仅支持Docker容器类型 EBS gp2 16000 IOPS ACL按编号从低到高的顺序处理 ALB不支持静态IP地址，而NLB支持静态IP地址。要将静态IP分配给ALB，有两种解决方案。1. 在 ALB 前面使用NLB和lambda 2.使用全球加速器 Storage Gateway支持NFS、SMB、Active Directory S3根据文件在S3中的天数移动，EFS根据文件闲置的天数移动 Parameter Store 是 AWS Systems Manager 的一项功能，可为配置数据管理和机密管理提供安全的分层存储。您可以将密码、数据库字符串、Amazon 系统映像 (AMI) ID 和许可证代码等数据存储为参数值。您可以将值存储为纯文本或加密数据。您可以使用创建参数时指定的唯一名称在脚本、命令、SSM 文档以及配置和自动化工作流中引用 Systems Manager 参数。 无法禁用VPC和子网的IPv4支持 在ACM（AWS Certificate Manager）导入SSL证书 Kinesis Data Streams只保留7天数据 Brusting EFS随着标准存储类中文件系统大小的增长而扩展 仅出口IPv6 流量请使用Internet 网关，要通过IPv4出站请改用 NAT 网关 在ALB上安装了SSL证书，是免费的。ALB从网上获取https，转换为http，然后发送到EC2 Lambda只能使用基于轮询的调用而不是通过异步调用来调用SQS ES（Elasticearch Service）做数据可视化，不是查询数据 Lamdba最大内存10GB Alias根域名，CNAME不行 Fargate不支持Fsx 只有IAM角色可用于访问跨账户资源 DAX -> DynamoDB的缓存，即使在每秒数百万个请求的情况下，也可将性能提高多达 10 倍（从毫秒到微秒） AWS KMS删除强制执行等待期7-30天 SSE-S3、SSE-C不提供审计跟踪加密密钥使用的能力 FIFO 队列支持每秒最多300个操作（每个操作最多批处理 10 条消息） GuardDuty 支持的数据源：VPC 流日志、DNS 日志、CloudTrail 事件 API Gateway可以使用令牌桶算法限制对您的 API 的请求 AWS Managed Microsoft AD 不支持 Microsoft 的分布式文件系统 (DFS) S3 Standard 上的测试文件存储成本 Firehose 无法直接写入 DynamoDB 表 Lambda支持C#/.NET、Go、Java、Node.js、Python、Ruby Lambda目前支持每个区域每个 AWS 账户1000 次并发执行 Neptune图形数据库服务 Global Accelerator 无助于加快文件传输到 S3 的速度 Global Accelerator 是一项服务，可提高本地或全球用户的应用程序的可用性和性能。它提供静态 IP 地址，充当单个或多个 AWS 区域中的应用程序终端节点的固定入口点，例如您的应用程序负载均衡器、网络负载均衡器或 Amazon EC2 实例 RDS多可用区遵循同步复制，Auroa遵循异步复制 GuardDuty禁用服务将删除所有剩余数据，包括您的发现和配置，然后再放弃服务权限并重置服务 S3 Glacier Instant Retrieval 提供对归档存储的最快访问，具有与 S3 Standard 和 S3 Standard-IA 存储类相同的吞吐量和毫秒访问。S3 Glacier Instant Retrieval 非常适合需要立即访问的存档数据，例如医学图像、新闻媒体资产或用户生成的内容存档，最低存储期限费用为 90 天 S3 Standard-IA 和 S3 One Zone-IA 的最低存储期限费用为 30 天 S3 Standard 没有最低存储持续时间费用和检索费用，S3 Standard-IA 和 S3 One Zone-IA 有检索费用 专用主机与专用实例的区别：可见性、放置位置、自带许可，在性能、安全性或物理特性方面没有区别 AWS Resource Access Manager (RAM) 是一项服务，可让您轻松安全地与任何 AWS 账户或在您的 AWS 组织内共享 AWS 资源。您可以与 RAM 共享 AWS Transit Gateways、子网、AWS License Manager 配置和 Amazon Route 53 Resolver 规则资源。RAM 消除了在多个账户中创建重复资源的需要，从而减少了在您拥有的每个账户中管理这些资源的运营开销。您可以在多账户环境中集中创建资源，并通过三个简单的步骤使用 RAM 跨账户共享这些资源：创建资源共享、指定资源和指定账户。RAM 可供您免费使用。 正确的解决方案是使用 RAM 在 VPC 内共享子网。这将允许所有 EC2 实例部署在同一个 VPC 中（尽管来自不同的账户）并轻松地相互通信。 AWS PrivateLink 通过消除数据暴露于公共 Internet 来简化与基于云的应用程序共享的数据的安全性。AWS PrivateLink 在 Amazon 网络上安全地提供 VPC、AWS 服务和本地应用程序之间的私有连接。私人链接是这个问题的干扰因素。Private Link 用于在一个账户中的 NLB 前端的应用程序和另一个账户中的弹性网络接口 (ENI) 之间创建私有连接，无需 VPC 对等互连并允许两者之间的连接保留在内部AWS 网络。 Amazon Cognito 的两个主要组件是用户池和身份池。身份池提供 AWS 凭证以授予您的用户访问其他 AWS 服务的权限。要使您的用户池中的用户能够访问 AWS 资源，您可以配置一个身份池以将用户池令牌交换为 AWS 凭证。因此，身份池本身并不是一种身份验证机制，因此不是此用例的选择。 使用存储在 AWS Key Management Service (SSE-KMS)中的客户主密钥 (CMK) 进行服务器端加密 - 使用存储在 AWS Key Management Service (SSE-KMS) 中的客户主密钥 (CMK) 进行服务器端加密类似于 SSE- S3。SSE-KMS 为您提供审计跟踪，显示您的 CMK 的使用时间和用户。此外，您可以创建和管理客户托管的 CMK 或使用您、您的服务和您所在区域独有的 AWS 托管 CMK。 使用 Amazon S3 托管密钥 (SSE-S3)进行服务器端加密 - 当您使用 Amazon S3 托管密钥 (SSE-S3) 进行服务器端加密时，每个对象都使用唯一密钥进行加密。作为额外的保护措施，它使用定期轮换的主密钥对密钥本身进行加密。所以这个选项是不正确的。 为私有托管区域启用 DNS 主机名和 DNS 解析- DNS 主机名和 DNS 解析是私有托管区域的必需设置。私有托管区域的 DNS 查询只能由 Amazon 提供的 VPC DNS 服务器解析。因此，必须启用这些选项才能使您的私有托管区域正常工作 DNS 主机名和 DNS 解析是私有托管区域的必需设置 SNS FIFO由SQS FIFO订阅，标准SNS由标准SQS订阅 Kinesis Agent 是一个独立的 Java 软件应用程序，它提供了一种简单的方法来收集数据并将其发送到 Kinesis Data Streams 或 Kinesis Firehose Kinesis Agent 只能写入 Kinesis Data Streams，而不能写入 Kinesis Firehose - Kinesis Agent 是一个独立的 Java 软件应用程序，它提供了一种简单的方法来收集数据并将其发送到 Kinesis Data Streams 或 Kinesis Firehose Amazon Kinesis Data Firehose 是将流数据可靠地加载到数据湖、数据存储和分析工具中的最简单方法。它是一项完全托管的服务，可自动扩展以匹配您的数据吞吐量，并且无需持续管理。它还可以在加载数据之前对数据进行批处理、压缩、转换和加密，从而最大限度地减少目的地使用的存储量并提高安全性。 Amazon Redshift 是一种完全托管的 PB 级基于云的数据仓库产品，专为大规模数据集存储和分析而设计。您不能使用 Redshift 从 IoT 源中捕获键值对中的数据 在多主集群中，所有数据库实例都可以执行写入操作。当写入器数据库实例不可用时，不会进行任何故障转移，因为另一个写入器数据库实例可立即接管故障实例的工作。AWS 将这种可用性称为连续可用性，以区别于单主集群提供的高可用性（故障转移期间有短暂的停机时间）。 启动模板类似于启动配置，因为它指定实例配置信息，例如 Amazon 系统映像 (AMI) 的 ID、实例类型、密钥对、安全组以及您用于启动的其他参数EC2 实例。此外，定义启动模板而不是启动配置允许您拥有多个版本的模板。多类型 启动配置是 Auto Scaling 组用来启动 EC2 实例的实例配置模板。创建启动配置时，您需要为实例指定信息，例如 Amazon 系统映像 (AMI) 的 ID、实例类型、密钥对、一个或多个安全组以及块储存设备映射。单类型 ASG未终止运行状况不佳的 Amazon EC2 实例：实例的运行状况检查宽限期尚未到期、实例可能处于受损状态、实例未通过 ELB 运行状况检查 AWS 支持 IAM 实体（用户或角色）的权限边界。权限边界是一项高级功能，用于使用托管策略设置基于身份的策略可以授予 IAM 实体的最大权限。实体的权限边界允许它仅执行其基于身份的策略及其权限边界所允许的操作。在这里，我们必须使用 IAM 权限边界。它们只能应用于角色或用户，而不是 IAM 组 服务控制策略 (SCP) 是一种可用于管理组织的策略。SCP 提供对组织中所有帐户的最大可用权限的集中控制，使您能够确保您的帐户符合组织的访问控制准则。SCP 仅在启用了所有功能的组织中可用。如果您的组织仅启用了整合计费功能，则 SCP 不可用。将 SCP 附加到 AWS Organizations 实体（根、OU 或账户）定义了委托人可以执行的操作的防护机制。如果您考虑此选项，由于此问题中未提及 AWS Organizations，因此我们无法应用 SCP AWS OpsWorks 是一项配置管理服务，可提供 Chef 和 Puppet 的托管实例。Chef 和 Puppet 是自动化平台，允许您使用代码来自动化服务器的配置。OpsWorks 允许您使用 Chef 和 Puppet 来自动化跨 Amazon EC2 实例或本地计算环境配置、部署和管理服务器的方式 Type of Access Control AWS Account Level Control User Level Control IAM Policies No Yes ACLs Yes No Bucket Policies Yes Yes 支持的S3生命周期转换 默认终止策略：按需与 Spot 任何分配策略的实例 -> 最旧启动配置的实例 -> 最旧启动模板的实例 -> 最接近下一个计费小时 通过 Cognito 用户池为您的应用程序负载均衡器使用 Cognito 身份验证 EFS Bursting Throughput mode 吞吐量会随着标准存储类中文件系统大小的增长而扩展；预置吞吐量模式，您可以立即预置文件系统的吞吐量（以 MiB/s 为单位），而与存储的数据量无关 如果您为 Lambda 函数创建的 IAM 角色与存储桶位于同一 AWS 账户中，则您无需同时授予 Amazon S3 对 IAM 角色和存储桶策略的权限。需要授予 IAM 角色的权限，然后验证存储桶策略没有明确拒绝对 Lambda 函数角色的访问。如果 IAM 角色和存储桶位于不同的账户中，则您需要授予 Amazon S3 对 IAM 角色和存储桶策略的权限。 \"KMS\" - AWS 密钥管理服务 (AWS KMS) 是一项服务，它结合了安全、高度可用的硬件和软件，以提供针对云扩展的密钥管理系统。当您将服务器端加密与 AWS KMS (SSE-KMS) 一起使用时，您可以指定您已创建的客户托管 CMK。SSE-KMS 为您提供审计跟踪，显示您的 CMK 的使用时间和用户。KMS 是一种加密服务，它不是秘密存储。所以这个选项是不正确的。 \"CloudHSM\"- AWS CloudHSM 是一个基于云的硬件安全模块 (HSM)，使您能够轻松地在 AWS 云上生成和使用您的加密密钥。借助 CloudHSM，您可以使用经过 FIPS 140-2 3 级验证的 HSM 管理您的加密密钥。CloudHSM 符合标准，使您能够将所有密钥导出到大多数其他市售 HSM，具体取决于您的配置。它是一项完全托管的服务，可为您自动执行耗时的管理任务，例如硬件配置、软件修补、高可用性和备份。CloudHSM 也是一种加密服务，而不是秘密存储。所以这个选项是不正确的。 AWS Systems Manager Parameter Store（又名 SSM Parameter Store）为配置数据管理和机密管理提供安全的分层存储。您可以将密码、数据库字符串、EC2 实例 ID、Amazon 系统映像 (AMI) ID 和许可证代码等数据存储为参数值。您可以将值存储为纯文本或加密数据。您可以使用创建参数时指定的唯一名称在脚本、命令、SSM 文档以及配置和自动化工作流中引用 Systems Manager 参数。SSM Parameter Store 可以用作秘密存储，但您必须自己轮换秘密，它没有自动执行此操作的功能。所以这个选项是不正确的。 Amazon Kinesis Data Firehose 是将流数据加载到数据存储和分析工具中的最简单方法。它可以捕获、转换流数据并将其加载到 Amazon S3、Amazon Redshift、Amazon Elasticsearch Service 和 Splunk 中，使用您现在已经在使用的现有商业智能工具和仪表板实现近乎实时的分析。 Amazon Kinesis Data Analytics 是实时分析流数据的最简单方法。您可以使用内置模板和运算符快速构建 SQL 查询和复杂的 Java 应用程序，以实现通用处理功能，以组织、转换、聚合和分析任何规模的数据。Kinesis Data Analytics 使您能够通过三个简单的步骤轻松快速地构建查询和复杂的流式处理应用程序：设置流式处理数据源、编写查询或流式处理应用程序以及设置处理数据的目的地。 Alias 和 CNAME 的比较 ALB不能分配弹性IP，NLB可以 如果您的实例未能通过系统状态检查，您可以使用 CloudWatch 警报操作来自动恢复它。恢复选项适用于超过 90% 的已部署客户 EC2 实例。CloudWatch 恢复选项仅适用于系统检查失败，不适用于实例状态检查失败。此外，如果您终止您的实例，则它无法恢复。不能使用 CloudWatch 事件直接触发 EC2 实例的恢复。仅在配置了 EBS 卷的实例上支持恢复操作，CloudWatch 警报不支持实例存储卷进行自动恢复。 恢复的实例与原始实例相同，包括实例 ID、私有 IP 地址、弹性 IP 地址和所有实例元数据，如果您的实例有公有 IPv4 地址，它会在恢复后保留公有 IPv4 地址 对于大型对象的长距离传输，Amazon S3 Transfer Acceleration 可以将进出 Amazon S3 的内容传输速度提高 50-500%。拥有广泛用户的 Web 或移动应用程序或托管在远离其 S3 存储桶的应用程序的客户可以通过 Internet 体验长时间且可变的上传和下载速度。S3 传输加速 (S3TA) 减少了 Internet 路由、拥塞和可能影响传输的速度的可变性，并从逻辑上缩短了远程应用程序到 S3 的距离。小于 1GB 的对象或数据集的大小小于 1GB，则考虑使用CloudFront。 您可以使用网络地址转换 (NAT) 网关使私有子网中的实例能够连接到 Internet 或其他 AWS 服务，但阻止 Internet 启动与这些服务的连接实例。要创建 NAT 网关，您必须指定 NAT 网关应驻留的公共子网。您还必须在创建 NAT 网关时指定一个弹性 IP 地址以与它关联。与 NAT 网关关联后，弹性 IP 地址无法更改。创建 NAT 网关后，您必须更新与一个或多个私有子网关联的路由表，以将 Internet 绑定流量指向 NAT 网关。这使您的私有子网中的实例能够与 Internet 通信。如果您不再需要 NAT 网关，可以将其删除。删除 NAT 网关会解除其弹性 IP 地址的关联，但不会从您的账户中释放该地址。仅出口互联网网关是支持 IPv6 流量的互联网网关，Internet 网关不能直接与私有子网一起使用。如果公有子网中没有 NAT 实例或 NAT 网关，则无法设置此配置。 AWS DataSync 是一种在线数据传输服务，可简化、自动化和加速通过 Internet 或 AWS Direct Connect 与 AWS 存储服务之间的大量数据复制。 FIFO 队列支持每秒最多 3,000 条消息；FIFO 队列的名称必须以 .fifo 后缀结尾 EFS、EBS、S3不支持 SMB 协议。AWS Storage Gateway和Fsx支持。 Amazon VPC 控制台向导提供以下四种配置：具有单个公有子网的 VPC、具有公有和私有子网 (NAT) 的 VPC、具有公有和私有子网以及 AWS Site-to-Site VPN 访问的 VPC SCP 权限的影响：如果用户或角色的 IAM 权限策略授予对适用 SCP 不允许或明确拒绝的操作的访问权限，则用户或角色无法执行该操作。SCP 会影响附加账户中的所有用户和角色，包括 root 用户。SCP 不影响任何服务相关角色。 使用 AWS Systems Manager，您可以按应用程序对资源（如 Amazon EC2 实例、Amazon S3 存储桶或 Amazon RDS 实例）进行分组，查看操作用于监控和故障排除的数据，并对您的资源组采取行动。您不能使用 Systems Manager 来维护资源配置更改的历史记录。 创建启动配置时，实例放置租期的默认值为 null，并且实例租期由 VPC 的租期属性控制。如果您将 Launch Configuration Tenancy 设置为默认值并且 VPC Tenancy 设置为 dedicated，则实例具有专用租赁。如果您将 Launch Configuration Tenancy 设置为 dedicated 并且 VPC Tenancy 设置为默认值，则实例再次具有专用租赁。 Elastic Fabric Adapter (EFA) 是一种网络设备，您可以将其连接到您的 Amazon EC2 实例以加速高性能计算 (HPC) 和机器学习应用程序。它增强了实例间通信的性能，这对于扩展 HPC 和机器学习应用程序至关重要。EFA 设备提供所有 Elastic Network Adapter (ENA) 设备功能以及新的操作系统旁路硬件接口，允许用户空间应用程序直接与硬件提供的可靠传输功能进行通信。 Elastic Network Adapter (ENA) 设备通过单根 I/O 虚拟化 (SR-IOV) 支持增强网络，以提供高性能网络功能。尽管增强型网络提供了更高的带宽、更高的每秒数据包 (PPS) 性能和持续更低的实例间延迟，但 EFA 仍然更适合给定的用例，因为 EFA 设备提供了 ENA 设备的所有功能，此外硬件支持应用程序直接与 EFA 设备通信，而不涉及使用扩展编程接口的实例内核（OS 旁路通信）。 要创建 NAT 网关，您必须指定 NAT 网关应驻留的公共子网。您还必须在创建 NAT 网关时指定一个弹性 IP 地址以与它关联。与 NAT 网关关联后，弹性 IP 地址无法更改。创建 NAT 网关后，您必须更新与一个或多个私有子网关联的路由表，以将 Internet 绑定流量指向 NAT 网关。这使您的私有子网中的实例能够与 Internet 通信。 NAT 实例可用作堡垒服务器、安全组可以与 NAT 实例关联、NAT实例支持端口转发 您只能在启动实例后将实例的租期从专用更改为主机，或从主机更改为专用。 AWS OpsWorks - AWS OpsWorks 是一种配置管理服务，提供 Chef 和 Puppet 的托管实例。Chef 和 Puppet 是自动化平台，允许您使用代码来自动化服务器的配置。OpsWorks 允许您使用 Chef 和 Puppet 来自动化跨 Amazon EC2 实例或本地计算环境配置、部署和管理服务器的方式。 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"dbs/":{"url":"dbs/","title":"DBS 学习笔记","keywords":"","body":"AWS 数据库相关学习笔记AWS 数据库相关学习笔记 根据 Udemy 上的课程 [NEW] Ultimate AWS Certified Database Specialty 2023 学习 Pass the AWS Certified Database Specialty Certification DBS-C01. Learn RDS, Aurora, DynamoDB, DMS, ElastiCache in depth Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"dbs/1.基本概念及Security.html":{"url":"dbs/1.基本概念及Security.html","title":"1. 基本概念及 Security","keywords":"","body":"1. OLTP（Online Transaction Processing）和 OLAP（Online Analytical Processing）2. BASE（Basically Available, Soft state, Eventually consistent）3. 关系型数据库和非关系型数据库的对比4. 概述5. 参数组（Parameter groups）6. 选项组（Option groups）7. Security - Network8. Security - IAM 身份验证9. 如何使用 IAM DB 身份认证？10. 轮换 RDS DB 证书11. RDS SQL Server 的 Windows 身份认证12. 强制使用 SSL13. SSL连接选项14. RDS 数据加密15. 复制和分享加密的 snapshots1. OLTP（Online Transaction Processing）和 OLAP（Online Analytical Processing） OLTP 和 OLAP 是两种常见的数据处理技术，用于处理不同类型的数据和满足不同的业务需求。 OLTP 是一种用于处理事务性数据的技术。它主要用于日常的业务操作，例如订单处理、交易记录、库存管理等。OLTP系统通常针对大量的短期事务，需要高并发性和快速的数据插入、更新和查询能力。这些系统通常强调数据的一致性和准确性，并追求低延迟的响应时间。OLTP 数据库通常采用关系型数据库管理系统（RDBMS），如 Oracle、MySQL、Microsoft SQL Server 等。 OLAP 则是一种用于处理分析性数据的技术。它主要用于数据分析、决策支持和业务智能等领域。OLAP系统通常面对复杂的查询和多维数据分析，需要支持大规模数据的聚合、切片、切块和透视等操作。这些系统通常强调数据的可读性和多维度的分析能力，并追求高性能的数据查询和计算。OLAP 数据库通常采用特定的数据存储和处理技术，如多维数据库（例如 OLAP 立方体）或列式数据库。 2. BASE（Basically Available, Soft state, Eventually consistent） BASE 是非关系型数据库系统设计的一种原则，与ACID（原子性、一致性、隔离性、持久性）相对应。它强调在大规模分布式系统中的可用性和性能，而放松了强一致性的要求。 下面是BASE原则的解释： Basically Available（基本可用）：系统保持基本的可用性，即使在面临部分故障或分区的情况下也能继续提供服务。它意味着系统可以接受部分故障，但仍然能够返回响应或执行部分功能。 Soft state（软状态）：系统在没有输入时可以处于不确定的状态，这是允许的。与ACID中的强一致性要求不同，软状态允许系统的状态在时间上存在一定的延迟和不一致性，而这些不一致性可以通过后续的操作或时间来纠正。 Eventually consistent（最终一致性）：系统的状态最终将达到一致状态，尽管在分布式环境中不同节点之间的状态可能存在一段时间的不一致。最终一致性并不要求实时或即时的一致性，而是通过后续的同步和协调机制使系统最终达到一致状态。 BASE原则在分布式系统和大规模数据处理中更为适用，特别是在面对高可用性、可扩展性和性能需求的场景下。相对于强一致性的ACID，BASE提供了更灵活的数据一致性模型，可以在牺牲一部分一致性的前提下获得更高的可用性和性能。 需要注意的是，BASE原则并非一种具体的技术实现或标准，而是一种设计思想和原则的概念。具体的非关系型数据库系统可以根据BASE原则进行设计和实现，以满足不同的可用性、一致性和性能需求。常见的非关系型数据库系统包括MongoDB、Cassandra、Redis等。 3. 关系型数据库和非关系型数据库的对比 关系型数据库 非关系型数据库 数据存储在表中，通过外键建立关系 数据用集合或键值对存储 严格的ACID原则 BASE原则 结构化数据 半结构化或非结构化数据 垂直扩展（换成更大的instance） 水平扩展（添加新node） 使用SQL 使用基于对象的APIs 适配OLTP和OLAP 适配OLTP（网页、移动应用） 4. 概述 支持的引擎：PostgreSQL，MySQL，MariaDB，Oracle，Microsoft SQL Server，Aurora 在一个VPC内启动：常使用私有子网，用 security groups 控制权限（如使用 Lambda 时） 使用 EBS 储存：gp2 或 io1，可自动扩展容量 备份：自动根据时间点恢复，备份过期 监控：使用 CloudWatch RDS Events：SNS 事件提醒 1 credit = CPU 核心利用率100%一分钟 5. 参数组（Parameter groups） 动态参数（修改立即生效，可能会导致停机）和静态参数（需要手动重启，状态从 in-sync -> pending-reboot -> in-sync） 6. 选项组（Option groups） 数据库引擎功能选项（默认为空），修改则需要创建新的选项组 7. Security - Network 数据库创建（通常是在子网中 ）后 VPC 就无法修改了 8. Security - IAM 身份验证 您不需要密码，只需通过 IAM 和 RDS API 调用获得身份验证令牌 身份验证令牌的生存期为15分钟 优点： 进出流量必须使用SSL 取代数据库，IAM 集中化管理用户 9. 如何使用 IAM DB 身份认证？ 在数据库群集上启用 IAM 数据库身份验证 创建数据库用户（不带密码） 附加 IAM 策略以将 DB 用户映射到 IAM 角色 将 IAM 角色附加到 IAM 用户（或 EC2 实例） 现在您可以通过 SSL 使用 IAM 令牌连接到 DB MySQL 实现方式： -- 创建用户 CREATE USER {db_username} IDENTIFIED WITH AWSAuthenticationPlugin as 'RDS'; -- 授予SSL权限 GRANT USAGE ON *.* TO '{db_username}'@'REQUIRE SSL; -- 下载SSL密钥 wget \"https://s3.amazonaws.com/rds-downloads/rds-ca-2019-root.pem\" -- 使用CLI生成token TOKEN=\"$(aws rds generate-db-auth-token --hostname {db_or_cluster_endpoint} --port 3306 --username {db_username})\" -- 连接数据库 mysql --host={db_or_cluster_endpoint} --port=3306 --ssl-ca=/home/ec2-user/rds-combined-ca-bundle.pem --enable-cleartext-plugin --user={db_username} --password=$TOKEN PostgreSQL 实现方式： 不需要修改配置文件pg_hba.conf CREATE USER {db_username}; GRANT rds_iam to {db_username}; wget \"https://s3.amazonaws.com/rds-downloads/rds-ca-2019-root.pem\" export PGPASSWORD=\"$(aws rds generate-db-auth-token --hostname={db_endpoint} --port=5432 --username={db_username} --region us-west-2)\" psql -h {db_endpoint} -p 5432 \"dbname={db_name} user={db_username} password=$PGPASSWORD sslrootcert=/home/ec2-user/rds-combined-ca-bundle.pem sslmode=verify-ca\" 10. 轮换 RDS DB 证书 使用 AWS Security Manager 集中、安全地存储凭证，支持审计 支持 secrets 的自动轮换 Secrets Manager 提供了一个 Lambda 轮换函数，并自动用 ARN（Amazon Resource Name）填充 secret 与 RDS 中的 MySQL、PostgreSQL 和 Aurora 集成 11. RDS SQL Server 的 Windows 身份认证 创建 AWS 托管的 Microsoft AD 目录，并在您的公司 AD 和 AWS 托管的AD之间建立信任关系（称为 forest trust 域信任） 如果您有超过5000个用户，并且需要与您的前置目录建立信任关系，则 AWS 托管 AD 是最佳选择 或者，您也可以使用 AD 连接器（用于现有的本地目录）或简单 AD（如果您的用户少于5000） 在 AD 中设置用户和组 在 RDS 实例中启用 SQL Server Windows 身份验证以将目录映射到 DB 实例（自动创建适当的lAM角色） 使用主用户凭据登录到数据库，并为 AD 用户创建 SQL Server Windows 登录 12. 强制使用 SSL SQL Server 或 PostgreSQL：在参数组中设置参数rds.force ssl=1（静态参数，需要手动重新启动） MySQL 或 MariaDB：ALTER USER 'mysqluser'@'%' REQUIRE SSL Oracle：将 SSL 选项添加到 DB 实例选项组 13. SSL连接选项 # PostgreSQL sslrootcert=rds-cert.pem sslmode=[verify-ca | verify-full] # MySQL --ssl-ca=rds-cert.pem --ssl-mode=VERIFY_IDENTITY (MySQL 5.7+) # MariaDB --ss1-ca=rds-cert.pem --ssl-mode=REQUIRED (MaraDB 10.2+) # MySOL/MariaDB (older versions) --ss1-ca=rds-cert.pem --ssl-verify-server-cert 14. RDS 数据加密 RDS 支持 AES-256 加密算法 通过 KMS 管理的密钥 可以同时加密主副本和读取副本必须在启动时定义加密 RDS 还支持 TDE（透明数据加密） For SQL Server（仅限 Enterprise Edition）和 Oracle DB 实例 通过设置选项组启用 对 Oracle 启用 TDE 选项 对 SQL Server 启用 TRANSPARENT_DATA_ENCRYPTION 选项 如果同时使用 TDE 和 静态加密，可能会略微影响数据库性能 15. 复制和分享加密的 snapshots 使用默认RDSencryption密钥加密的快照不能直接共享 使用自定义加密密钥复制快照，然后共享[密钥+快照] 无法共享具有某些自定义选项组的快照（例如TDE） Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-19 10:48:47 "},"dbs/2.databases.html":{"url":"dbs/2.databases.html","title":"2. 数据库","keywords":"","body":"1. RDS 备份2. 从快照还原3. 导出快照到 S34. 比较 RDS DR 策略5. 如何解决复制错误的建议6. Aurora Replicas vs MySQL Replicas7. Comparison of RDS Deployments8. DynamoDB Terminology Compared to SQL9. AWS 数据库之间的比较1. RDS 备份 RDS 支持自动备份 实时捕获事务日志 默认情况下启用，保留期为7天（0-35天保留期，0=禁用自动备份） 您可以提供备份窗口时间和备份保留天数 第一个备份是完整备份，后续备份是增量备份 数据存储在 S3 存储桶中（由 RDS 服务拥有和管理，您不会在 S3 控制台中看到它们） 建议使用 Multi-AZ 选项来避免备份运行时的性能问题 与 AWS Backup 服务集成以实现集中管理 支持 PITR，而快照则不支持 复制备份会变为快照，可以跨越账号、region Point-In-Time Recovery 时间间隔为 5 分钟 2. 从快照还原 只能恢复到新实例 一个实例可以有一个或多个数据库，所有这些数据库都将被恢复 要保留相同的名称，请先删除或重命名现有实例 无法直接从共享和加密的快照中恢复（先复制，然后从副本中恢复） 无法直接从另一个区域恢复（先复制，然后从副本恢复） 可以从 VPC 外的数据库实例快照恢复到 VPC 内（但相反则不行） 默认情况下，还原的集群使用： 新建安全组 默认参数组 与快照关联的选项组 从快照恢复时，请确保 选择正确的安全组以确保恢复的数据库的连接 为还原的数据库选择正确的参数组 建议保留快照的参数组，以帮助使用正确的参数组进行恢复 3. 导出快照到 S3 可以导出所有类型的备份（自动/手动或使用 AWS 备份服务创建的备份） 如何出口？ 设置具有适当 IAM 权限的 S3 存储桶，并为 SSE 创建KMS密钥 使用控制台（Actions -> Export to Amazon S3）或使用 start Export task CLI 命令导出快照 导出在后台运行 不会影响数据库性能 以 Apache Parquet 格式导出的数据（压缩、一致） 允许您使用 Athena 或 Redshift Spectrum 分析数据库数据 4. 比较 RDS DR 策略 RTORecovery Time Objective RPORecovery Point Object Cost Scope Automated backups Good Better Low Single Region Manual snapshots Better Good Medium Cross-Region Read replicas Best Best High Cross-Region 5. 如何解决复制错误的建议 调整副本的大小以匹配源数据库（存储大小和数据库实例类） 对源数据库和副本使用兼容的数据库参数组设置 例如，读取副本允许的最大数据包必须与源数据库实例的数据包相同 监视副本实例的 Replication State 字段 如果 Replication State = Error，然后查看 Replication Error 字段中的错误详细信息 使用 RDS 事件通知获取有关此类副本问题的警报 写入读取复制副本上的表 将只读设置为0以使读取副本可写 仅用于维护任务（如仅在复制副本上创建索引） 如果您在读取副本上写入表，可能会使其与源数据库不兼容并破坏复制 因此，在完成维护任务后立即设置read-only=1 只有像lnnoDB这样的事务存储引擎才支持复制，使用MylSAM这样的引擎会导致复制错误 使用不安全的非确定性查询（如SYSDATE）（可能会破坏复制） 您可以跳过复制错误（如果不是主要错误），也可以删除并重新创建复制副本 对于MySQL： 错误或数据不一致b/w源实例和replica 可能是由于 binlog 事件或 lnnoDB 重做日志在 replica 或源实例失败期间未刷新而发生的 必须手动删除并重新创建复制 预防性建议： sync_binlog=1 innodb_flush_log_at_trx_commit=1 innodb_support_xa=1 这些设置可能会降低性能（因此在转到生产前进行测试） 6. Aurora Replicas vs MySQL Replicas Feature Amazon Aurora Replicas MySQL Replicas Number of replicas Up to 15 Up to 5 Replication type Asynchronous (milliseconds) Asynchronous (seconds) Performance impact on primary Low High Replica location In-region Cross-region Act as failover target Yes (no data loss) Yes (potentially minutes of data loss) Automated failover Yes No Support for user-defined replication delay No Yes Support for different data or schema vs. primary No Yes 7. Comparison of RDS Deployments Read replicas Multi-AZ deployments (Single-Region) Multi-Region deployments Main purpose Scalability HA DR and performance Replication method Asynchronous (eventual consistency) Synchronous Asynchronous (eventual consistency) Asynchronous (Aurora) Accessibility All replicas can be used for read scaling Active-Passive (standby not accessible) All regions can be used for reads Automated backups No backups configured by default Taken from standby Can be taken in each region Taken from shared storage layer (Aurora) Instance placement Within-AZ, Cross-AZ, or Cross-Region At least two AZs within region Each region can have a Multi-AZ deployment Upgrades Independent from source instance On primary Independent in each region All instances together (Aurora) DR (Disaster Recovery) Can be manually promoted to a standalone instance Automatic failover to standby Aurora allows promotion of a secondary region to be the master Can be promoted to primary (Aurora) Automatic failover to read replica (Aurora) 8. DynamoDB Terminology Compared to SQL SQL / RDBMS DynamoDB Tables Tables Rows Items Columns Attributes Primary Keys - Multicolumn Primary Keys - Mandatory, minimum one and maximum two attributes Indexes Local Secondary Indexes Views Global Secondary Indexes 9. AWS 数据库之间的比较 Database Type of data Workload Size Performance Operational overhead RDS DBs Structured Relational / OLTP / simple OLAP Low TB range Mid-to-high throughtput, low latency Moderate Aurora Mysql Structured Relational / OLTP / simple OLAP Mid TB range High throughtput, low latency Low-to-moderate Aurora PostgrSQL Structured Relational / OLTP / simple OLAP Mid TB range High throughtput, low latency Low-to-moderate Redshift Structured / Semi-structured Relational / OLAP / DW PB range Mid-to-high latency Moderate DynamoDB Semi-structured Non-relational / Key-Value / OLTP / Document store High TB range Ultra-high throughtput, low latency, ultra-low latency with DAX Low ElastiCache Semi-structured / Unstructured Non-relational / In-memory caching / Key-Value Low TB range High throughtput, ultra-low latency Low Neptune Graph data Highly connected graph datasets Mid TB range High throughtput, ultra-low latency Low Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-24 13:45:51 "},"dbs/3.network.html":{"url":"dbs/3.network.html","title":"3. 网络","keywords":"","body":"1. VPC 和子网2. Internet Gateway & NAT Gateways3. Network ACL & Security Groups4. 网络访问控制列表和安全组对比5. VPC Flow Logs6. VPC Peering7. VPC Endpoints8. 堡垒机1. VPC 和子网 VPC：部署资源的专用网络（region 层面） 子网：允许您在VPC内分区网络（AZ 层面） 公共子网：是可从互联网访问的子网 专用子网：是不能从互联网访问的子网 为了定义对互联网和子网之间的访问，我们使用路由表 2. Internet Gateway & NAT Gateways 互联网网关帮助我们的 VPC 实例与互联网连接 公共子网有通往互联网网关的路由 NAT 网关（AWS管理）和 NAT 实例（自我管理）允许您的私有子网中的实例在保持私有状态的同时访问互联网 3. Network ACL & Security Groups 网络访问控制列表 控制子网和子网之间流量的防火墙 可以具有 ALLOW 和 DENY 规则 附加在子网级别 规则仅包括 IP 地址 安全组 控制往返 ENl / EC2 实例的流量的防火墙 只能有 ALLOW 规则 规则包括 IP 地址和其他安全组 4. 网络访问控制列表和安全组对比 Security Group Network ACL 运行在实例层面 运行在子网层面 只支持allow规则 支持allow和deny规则 无状态：返回的流量自动允许 有状态：返回的流量必须经规则允许 比对所有规则 按顺序比对规则 仅在启动实例时指定了安全组，或在之后与实例关联时，才适用于实例 自动应用于与之关联的子网中的所有实例（因此，您不必依赖用户来指定安全组） 5. VPC Flow Logs 捕获有关进入接口的 IP 流量的信息 VPC 流日志 子网流日志 弹性网络接口流日志 帮助监控和定位连接问题。比如： 子网到互联网 子网到子网 因特网到子网 还从 AWS 托管接口捕获网络信息：弹性负载均衡器，ElastiCache，RDS，Aurora等... VPC Flow日志数据可以转到 S3、CloudWatch Logs 和 Kinesis Data Firehose 6. VPC Peering 连接两个VPC，单独使用AWS的网络 使它们的行为就像在同一个网终中一样 不能有重叠的CIDR（IP地址范围） VPC 对等连接不具有可传递性（必须为需要彼此通信的每个 VPC 建立对等连接） 7. VPC Endpoints 端点允许您使用专用网络而不是公共万维网网络连接到AWS服务 这增强了安全性并降低了访问AWS服务的延迟 VPC端点网关：S3和DynamoDB VPC端点接口：其余部分 只在你的VPC中使用 8. 堡垒机 我们可以使用 Bastion 主机访问我们的私人 RDS 数据库，ElastiCache 集群，等等... 堡垒在公共子网中，然后连接到所有其他私有子网 必须加强堡垒主机安全组 确保数据库安全组允许 bastion 安全组 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-24 11:02:35 "},"cli/":{"url":"cli/","title":"CLI 学习笔记","keywords":"","body":"命令行相关工具笔记命令行相关工具笔记 包括 git、ssh、终端、JSON Path、Powershell、正则等常用操作，另外推荐阅读简明 VIM 练级攻略 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"cli/1.git常用命令.html":{"url":"cli/1.git常用命令.html","title":"1. git 常用命令","keywords":"","body":"1. 原理2. 常用命令3. 常用设置4. 参考资料1. 原理 git 工作区（workspace）、暂存区（index/staging）、版本库（local repository） 2. 常用命令 git init # 初始化本地git仓库（创建新仓库） git config --global user.name \"xxx\" # 配置用户名 git config --global user.email \"xxx@xxx.com\" # 配置邮件 git config --global color.ui true # git status等命令自动着色 git config --global color.status auto git config --global color.diff auto git config --global color.branch auto git config --global color.interactive auto git clone git+ssh://git@192.168.53.168/VT.git # clone远程仓库 git status # 查看当前版本状态（是否修改） git add xyz # 添加xyz文件至index git add . # 增加当前子目录下所有更改过的文件至index，包括untrack的文件，会根据.gitignore过滤 git add * # 会忽略.gitignore过滤 git add -p # 交互式选择代码片段，辅助整理出所需的patch git commit -m 'xxx' # 提交 git commit --amend -m 'xxx' # 合并上一次提交（用于反复修改） git commit -am 'xxx' # 将add和commit合为一步，一般不用，不包含untrack的文件 git rm xxx # 删除index中的文件 git rm -r * # 递归删除 git log # 显示提交日志 git log -1 # 显示1行日志 -n为n行 git log -5 git log --stat # 显示提交日志及相关变动文件 git log -p -m git show # 默认显示HEAD日志的相关信息 git show dfb02e6e4f2f7b573337763e5c0013802e392818 # 显示某个提交的详细内容 git show dfb02 # 可只用commitid的前几位 git show HEAD # 显示HEAD提交日志 git show HEAD^ # 显示HEAD上一个版本的提交日志^^为上两个版本^5为上5个版本 git tag # 显示已存在的tag git tag -a v2.0 -m 'xxx' # 增加v2.0的tag git show v2.0 # 显示v2.0的日志及详细内容 git log v2.0 # 显示v2.0的日志 git log --oneline # 一行显示日志 git diff # 显示所有未添加至index的变更 git diff --cached # 显示所有已添加index但还未commit的变更，和--staged相同 git diff HEAD^ # 比较与上一个版本的差异 git diff HEAD -- ./lib # 比较与HEAD版本lib目录的差异 git diff origin/master..master # 比较远程分支master上有本地分支master上没有的 git diff origin/master..master --stat # 只显示差异的文件，不显示具体内容 git remote # 列出它存储的远端仓库别名 git remote -v # 还可以看到每个别名的实际链接地址 git remote add origin git+ssh://git@192.168.53.168/VT.git # 增加远程定义（用于push/pull/fetch） git branch # 显示本地分支 git branch --contains 50089 # 显示包含提交50089的分支 git branch -a # 显示所有分支 git branch -r # 显示所有原创分支 git branch --merged # 显示所有已合并到当前分支的分支 git branch --no-merged # 显示所有未合并到当前分支的分支 git branch -m master master_copy # 本地分支改名 git checkout -b master_copy # 从当前分支创建新分支master_copy并检出 git checkout -b master master_copy # 上面的完整版 git checkout features/performance # 检出已存在的features/performance分支 git checkout --track hotfixes/BJVEP933 # 检出远程分支hotfixes/BJVEP933并创建本地跟踪分支 git checkout v2.0 # 检出版本v2.0 git checkout -b devel origin/develop # 从远程分支develop创建新本地分支devel并检出 git checkout -- README # 检出head版本的README文件（可用于修改错误回退） git merge origin/master # 合并远程master分支至当前分支 git cherry-pick ff44785404a8e # 合并提交ff44785404a8e的修改 git push origin master # 将当前分支push到远程master分支 git push origin :hotfixes/BJVEP933 # 删除远程仓库的hotfixes/BJVEP933分支 git push --tags # 把所有tag推送到远程仓库 git push -f # 暴力覆盖 git fetch # 获取所有远程分支（不更新本地分支，另需merge） git fetch --prune # 获取所有原创分支并清除服务器上已删掉的分支 git pull --rebase git pull origin master # 获取远程分支master并merge到当前分支 git mv README README2 # 重命名文件README为README2 git reset --soft HEAD # 重置位置的同时，保留working Tree工作目录和index暂存区的内容，只让repository中的内容和 reset 目标节点保持一致，因此原节点和reset节点之间的「差异变更集」会放入index暂存区中(Staged files)。所以效果看起来就是工作目录的内容不变，暂存区原有的内容也不变，只是原节点和Reset节点之间的所有差异都会放到暂存区中 git reset (--mixed) HEAD # 重置位置的同时，只保留Working Tree工作目录的內容，但会将 Index暂存区 和 Repository 中的內容更改和reset目标节点一致，因此原节点和Reset节点之间的「差异变更集」会放入Working Tree工作目录中。所以效果看起来就是原节点和Reset节点之间的所有差异都会放到工作目录中 git reset --hard HEAD # 重置位置的同时，直接将 working Tree工作目录、 index 暂存区及 repository 都重置成目标Reset节点的內容,所以效果看起来等同于清空暂存区和工作区 git rebase git rebase -i head~4 # 查看当前后面的4个提交 git branch -d hotfixes/BJVEP933 # 删除分支hotfixes/BJVEP933（本分支修改已合并到其他分支） git branch -D hotfixes/BJVEP933 # 强制删除分支hotfixes/BJVEP933 git ls-files # 列出git index包含的文件 git show-branch # 图示当前分支历史 git show-branch --all # 图示所有分支历史 git whatchanged # 显示提交历史对应的文件修改 git revert dfb02e6e4f2f7b573337763e5c0013802e392818 # 撤销提交dfb02e6e4f2f7b573337763e5c0013802e392818 git ls-tree HEAD # 内部命令：显示某个git对象 git rev-parse v2.0 # 内部命令：显示某个ref对于的SHA1 HASH git reflog # 显示所有提交，包括孤立节点 git show HEAD@{5} git show master@{yesterday} # 显示master分支昨天的状态 git log --pretty=format:'%h %s' --graph # 图示提交日志 git show HEAD~3 git show -s --pretty=raw 2be7fcb476 git stash # 暂存所有未提交修改（包括暂存的和非暂存的） git stash list # 查看所有暂存 git stash save \"test-cmd-stash\" # 暂存时添加message git stash show -p stash@{0} # 参考第一次暂存 git stash apply stash@{0} # 应用第一次暂存但不删除 git stash pop # 应用堆栈中第一个暂存并删除 git stash drop stash@{0} # 删除暂存 git stash clear # 删除所有缓存的stash git grep \"delete from\" # 文件中搜索文本“delete from” git grep -e '#define' --and -e SORT_DIRENT git gc git fsck 3. 常用设置 Q: git pull 出错 fatal: Could not read from remote repository.Please make sure you ha... A: 出现这个问题是因为，没有在github账号添加SSH key git config --global user.name \"yourName\" git config --global user.email \"yourEmail\" SSO 需要在 GitHub 授权 ssh-keygen ls -al ~/.ssh less ~/.ssh/id_rsa cat ~/.ssh/id_rsa.pub git 如何设置使用代理 git config --global https.proxy http://127.0.0.1:80809 git config --global https.proxy https://127.0.0.1:80809 git config -l --global # 查看设置，SSH访问不通过SOCK5或HTTP，所以以上设置其实无效，需要进行以下设置 git 设置 SSH 代理 ssh 配置文件地址为：~/.ssh/config windows 中就是：C:\\Users\\你的用户名\\.ssh\\config (若不存在自行创建) 配置文件中增加以下内容： Host github.com *.github.com User git # SSH默认端口22， HTTPS默认端口443 Port 22 Hostname %h # 这里放你的SSH私钥 IdentityFile ~\\.ssh\\id_rsa # 设置代理, 127.0.0.1:10808 换成你自己代理软件监听的本地地址 # HTTPS使用-H，SOCKS使用-S ProxyCommand connect -S 127.0.0.1:10808 %h %p CTRL+R 自动查找命令历史，CTRL+E 使用历史命令 4. 参考资料 Git新命令switch和restore git docs Beginner’s Guide to using Git git - 简明指南 Git 取消commit Git rebase 用法小结 Git Reset 三种模式 Git Reset 三种模式 详细 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"cli/2.ssh配置及连接.html":{"url":"cli/2.ssh配置及连接.html","title":"2. ssh 配置及连接","keywords":"","body":"1. 常用命令2. /etc/ssh/sshd_config 配置文件详细说明3. ssh隧道1. 常用命令 # 1.使用ssh连接远程主机 # 最简单的用法只需要指定用户名和主机名参数即可，主机名可以是 IP 地址或者域名。 ssh user@hostname # 2.ssh连接到其他端口 # SSH 默认连接到目标主机的 22 端口上，可以使用-p选项指定端口号 ssh -p 10022 user@hostname # 3.使用ssh在远程主机执行一条命令并显示到本地, 然后继续本地工作 # 直接连接并在后面加上要执行的命令就可以了 ssh pi@10.42.0.47 ls -l # 4.在远程主机运行一个图形界面的程序 # 使用ssh的-X选项，然后主机就会开启 X11 转发功能 ssh -X feiyu@222.24.51.147 # 5.构建 ssh 密钥对 # 使用 ssh-keygen -t ，现在大多数都使用rsa或者dsa算法。 ssh-keygen -t rsa # 6.使用-F选项查看是否已经添加了对应主机的密钥 ssh-keygen -F 222.24.51.147 # 7，使用-R选项删除主机密钥，也可以在~/.ssh/known_hosts文件中手动删除 ssh-keygen -R 222.24.51.147 # 8.绑定源地址 # 如果你的客户端有多于两个以上的 IP 地址，你就不可能分得清楚在使用哪一个 IP 连接到 SSH 服务器。为了解决这种情况，我们可以使用 -b 选项来指定一个IP 地址。这个 IP 将会被使用做建立连接的源地址。 ssh -b 192.168.0.200 root@192.168.0.103 # 9.对所有数据请求压缩 # 使用 -C 选项，所有通过 SSH 发送或接收的数据将会被压缩，并且仍然是加密的。 ssh -C root@192.168.0.103 # 10.打开调试模式 # 因为某些原因，我们想要追踪调试我们建立的 SSH 连接情况。SSH 提供的 -v 选项参数正是为此而设的。其可以看到在哪个环节出了问题。 ssh -v root@192.168.0.103 # 11.上传公钥到服务器，之后就可以免密登录 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.235.22 2. /etc/ssh/sshd_config 配置文件详细说明 # 设置sshd监听的端口号 Port 2 # 设置sshd服务器绑定的IP地址 ListenAddress 192.168.1.1 # 设置包含计算机私人密匙的文件 HostKey /etc/ssh/ssh_host_key # 定义服务器密匙的位数 ServerKeyBits 1024 # 设置如果用户不能成功登录，在切断连接之前服务器需要等待的时间（以秒为单位） LoginGraceTime 600 # 这个参数的是意思是每5分钟，服务器向客户端发一个消息，用于保持连接 ClientAliveInterval 300（默认为0） # 设置在多少秒之后自动重新生成服务器的密匙（如果使用密匙）。重新生成密匙是为了防止用盗用的密匙解密被截获的信息 KeyRegenerationInterval 3600 # 设置root能不能用ssh登录。这个选项一定不要设成\"yes\" PermitRootLogin no # 设置验证的时候是否使用\"rhosts\"和\"shosts\"文件 IgnoreRhosts yes # 设置ssh daemon是否在进行RhostsRSAAuthentication安全验证的时候忽略用户的\"$HOME/.ssh/known_hosts IgnoreUserKnownHosts yes # 设置ssh在接收登录请求之前是否检查用户家目录和rhosts文件的权限和所有权。这通常是必要的，因为新手经常会把自己的目录和文件设成任何人都有写权限 StrictModes yes # 设置是否允许X11转发 X11Forwarding no # 设置sshd是否在用户登录的时候显示\"/etc/motd\"中的信息 PrintMotd yes # 设置在记录来自sshd的消息的时候，是否给出\"facility pre\" SyslogFacility AUTH # 设置记录sshd日志消息的层次 LogLevel INFO # 设置只用rhosts或\"/etc/hosts.equiv\"进行安全验证是否已经足够了 RhostsAuthentication no # 设置是否允许用rhosts或\"/etc/hosts.equiv\"加上RSA进行安全验证 RhostsRSAAuthentication no # 设置是否允许只有RSA安全验证 RSAAuthentication yes # 设置是否允许口令验证 PasswordAuthentication yes # 设置是否允许用口令为空的帐号登录 PermitEmptyPasswords no 3. ssh隧道 3.1 机器IP: 10.211.55.3 10.211.55.7 装有nginx 3.2 本地转发，将远程机器的指定端口，通过本地的一个端口转发，适用于本地仅能连接远程机器的ssh端口 “-L选项”：表示使用本地端口转发创建ssh隧道 “-R选项”：表示使用远程端口转发创建ssh隧道 “-N选项”：表示创建隧道以后不连接到sshServer端，通常与”-f”选项连用 \"-f选项\"：表示在后台运行ssh隧道，通常与”-N”选项连用 ssh -fNL 12345:10.211.55.7:80 root@10.211.55.7 访问地址：http://localhost:12345/ 3.3 同上，区别：适用于远程机器仅能通过中间跳板机连接，本地无法直接访问 ssh -fNL 12345:10.211.55.7:80 root@10.211.55.7 -J root@10.211.55.3 访问地址：http://localhost:12345/ 3.4 远程转发，适用于自己有公网IP的虚机，且开放了对应端口的防火墙，并且远程虚机修改过对应配置 /etc/ssh/sshd_config GatewayPorts yes ssh -fNTR 71.132.36.61:10035:0.0.0.0:80 ec2-user@71.132.36.61 -i ./.ssh/temp.pem 访问地址：http://71.132.36.61:12345/ Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-14 13:56:50 "},"cli/3.terminal常用快捷键.html":{"url":"cli/3.terminal常用快捷键.html","title":"3. terminal 常用快捷键","keywords":"","body":"常用历史命令命令行编辑控制快捷键!号开头的快捷命令Esc相关常用 Ctrl+L ：清屏 Ctrl+M ：等效于回车 Ctrl+C : 中断正在当前正在执行的程序 历史命令 Ctrl+P : 上一条命令，可以一直按表示一直往前翻 Ctrl+N : 下一条命令 Ctrl+R : 再按历史命令中出现过的字符串：按字符串寻找历史命令（重度推荐） Ctrl+G : 从执行 Ctrl+R 的搜索历史命令模式退出 命令行编辑 Tab : 自动补齐（重度推荐） Ctrl+A ： 移动光标到命令行首 Ctrl+E : 移动光标到命令行尾 Ctrl+F : 光标前进 Ctrl+B : 光标后退 Alt+F : 光标前进一个单词 Alt+B : 光标后退一格单词 Ctrl+] : 从当前光标往后搜索字符串，用于快速移动到该字符串 Ctrl+Alt+] : 从当前光标往前搜索字符串，用于快速移动到该字符串 Ctrl+H : 删除光标的前一个字符（相当于退格键） Ctrl+D : 删除当前光标所在字符 Ctrl+K ：删除光标之后所有字符 Ctrl+U : 清空当前键入的命令 Ctrl+W : 删除光标前的单词(Word, 不包含空格的字符串) Ctrl+Y : 粘贴Ctrl+W或Ctrl+K删除的内容 Ctrl+\\ : 删除光标前的所有空白字符 Alt+. : 粘贴上一条命令的最后一个参数（很有用） Alt+[0-9],Alt+. 粘贴上一条命令的第[0-9]个参数 Alt+[0-9],Alt+.,Alt+. 粘贴上上一条命令的第[0-9]个参数 Ctrl+X,Ctrl+E : 调出系统默认编辑器编辑当前输入的命令，退出编辑器时，命令执行 控制快捷键 Ctrl+Z : 把当前进程放到后台（之后可用fg命令回到前台） Ctrl+S : 锁定终端，使之无法输入内容 Ctrl+Q : 解锁执行Ctrl+S的锁定状态 Ctrl+Insert : 复制 Shift+Insert : 粘贴（相当于 Windows 的 Ctrl+V） 在命令行窗口选中即复制 在命令行窗口中键即粘贴，可用 Shift+Insert 代替 Ctrl+PageUp : 屏幕输出向上翻页 Ctrl+PageDown : 屏幕输出向下翻页 !号开头的快捷命令 !! : 执行上一条命令 !pw : 执行最近以pw开头的命令 !pw:p : 仅打印最近pw开头的命令，但不执行 !num : 执行历史命令列表的第num(数字)条命令 !$ : 上一条命令的最后一个参数，相当于Esc+. Esc相关 Esc+. : 获取上一条命令的最后的部分（空格分隔） Esc+B : 移动到当前单词的开头 Esc+F : 移动到当前单词的结尾 Esc+T : 颠倒光标所在处及其相邻单词的位置 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-14 13:56:56 "},"cli/4.JSON Path.html":{"url":"cli/4.JSON Path.html","title":"4. JSON Path","keywords":"","body":"参考资料list操作符逻辑表达式函数kubectl参考资料 课程：https://kodekloud.com/courses/json-path-quiz/ 注意点： json query 得到的都是数组形式的 result list list 有序（序号从0开始），而 dictionary 无序 取第0个和第3个：$[0,3] 取第0个到第3（不包含）个：$[0:3] 每隔2个取第0个到第8（不包含）个：$[0:8:2] 取最后1个：在某些实现下不起作用$[-1]，需要写成$[-1:0]，$[-1:] 操作符 操作符 描述 $ root根元素 @ 表示list中的每一个元素 * 匹配所有 ?() if过滤匹配 ['' (, '')] 用方括号和单引号取值 逻辑表达式 逻辑表达式 描述 ==, !=, , >= 等于，不等于... =~ 右边匹配正则表达式 in, nin 匹配是否存在数组中 subsetof, anyof, noneof 子集匹配 size, empty 数组大小匹配 函数 函数 描述 输出类型 min, max, avg 最小最大平均值 Double stddev 标准偏差值 Double sum 求和 Double length 长度 Integer keys 提供属性键（终端波浪号~的替代项） Set concat, append 拼接，加入 like input first, last, index 数组元素 由数组决定 kubectl $非强制需要写上，kubectl会帮助添加 拼接内容：kubectl get nodes -o=jsonpath='{.items[*].metadata.name}{\"\\n\"}{.items[*].status.capacity.cpu}' Loop： '{range .items[*]} {.metadata.name}{\"\\t\"}{.status.capacity.cpu}{\"\\n\"} {end}' custom-columns： kubectl get nodes -o=custom-columns=: Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"cli/5.常用PowerShell命令.html":{"url":"cli/5.常用PowerShell命令.html","title":"5. 常用 PowerShell 命令","keywords":"","body":"How do you set PowerShell's default directory? 删除文件Remove-Item -Path \"*\" -Include \"*.txt\" -Recurse -Force 获取文件个数Get-ChildItem -Include *.dump -Recurse | select Name | Measure-Object 删除Sample开头的sqlserver数据库$Databases = Invoke-SQLcmd -ServerInstance $ServerInstance -Query (\"SELECT * FROM sys.databases WHERE NAME LIKE 'Sample%'\") ForEach ($Database in $Databases){Invoke-SQLcmd -ServerInstance $ServerInstance -Query (\"DROP DATABASE [\" + $Database.Name + \"]\") \"$($Database.Name) is deleted.\"} dump文件转postgrespsql -U postgres -d -f 'C:\\xxxxxx.dump' 删除Sample开头的postgres数据库psql -U postgres -t -A -c \"select datname from pg_database where datname ~ 'Sample\\w*'\" | ForEach-Object { dropdb --force --echo --username postgres \"$_\" } Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-14 13:57:14 "},"cli/6.正则表达式.html":{"url":"cli/6.正则表达式.html","title":"6. 正则表达式","keywords":"","body":"匹配模式分组断言C# 特供匹配模式 讲道理的正则表达式对于 *+? 的匹配模式是贪心匹配 用a*a*b匹配aab时，a*吃掉了两个a，而a*没得a吃 在 *+? 后面加上一个 ? 可以把匹配模式变为惰性匹配 用a*?a*?b 匹配aab时，a*?一个a都不吃，而a*?被迫吃掉了两个a 在 *+? 后面加上一个+可以把匹配模式变为侵占匹配 用a*+a无法匹配aaa，因为a*+抢走了所有的a，导致a匹配失败 分组 \\ 如\\1，引用前面的第1个分组var match = Regex.Match(\"abcabc\", @\"(.+)\\1\"); // match.Groups[1] = \"abc\" var result = Regex.Replace(\" 358 * (126 + 282)\", @\"(\\d+) \\* \\((\\d+) \\+ (\\d+)\\)\", \"$1 * $2 + $1 * $3\"); // result = \"358 * 126 + 358 * 282\" 对于不想要的分组，开头加上 ?:var match = Regex.Match(\"abcabc\", @\"(?:.+)\\1\"); // Reference to undefined group number 1 注意只要有一对单独的圆括号就存在一个组，顺序为开括号出现的顺序var match = Regex.Match(\"abcdef\", @\"(?:a(bc)(d(ef)))\"); // match.Groups[1] = bc // match.Groups[2] = def // match.Groups[3] = ef 分组时用 ? 指定名字，即可用 \\k 的方式引用var match = Regex.Match(\"abcabc\", @\"(?.+)\\k\") // match.Groups[\"x\"] = abc 正则替换的引用方式: var result = Regex.Replace(\" 358 + 126\", @\"(?\\d+) \\+ (?\\d+)\", \"${B} + ${A}\") // result = \"126 + 358\" 断言 (? 匹配前面匹配 x 的 y x(?=y) 匹配后面匹配 y 的 x (? 匹配前面不匹配 x 的 y x(?!y) 匹配后面不匹配 y 的 x ^ 断言当前位置为字符串开头 $ 断言当前位置为字符串末尾 \\b 断言当前位置为单词(包括数字下划线)的边界 C# 特供 C# 对于正则的分组行为强于其它语言 组以堆栈的形式存在而非单个元素 对于同组匹配多个的正则，能同时存储被匹配的内容 对于带名称的分组效果相同 除了放入元素还可以取出元素，遵循堆栈的后入先出原则Pattern p = Pattern.compile(\"(.)+\") Matcher m = p.matcher(\"abc\"); if (m.matches()) System.out.println(m.group(1)); // 输出:c var groups = Regex.Match(\"abc\", \"(.)+\").Groups; var captures = groups[1].Captures.ToArray(); var output = string.Join(\",\"), captures); Console.WriteLine(output); // 输出:a,b,c Multiple outputs from T4 made easy – revisited Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/":{"url":"k8s/","title":"Kubernetes 学习笔记","keywords":"","body":"Kubernetes 相关学习笔记Kubernetes 相关学习笔记 根据 Udemy 上的课程 Certified Kubernetes Administrator (CKA) with Practice Tests 学习。 Prepare for the Certified Kubernetes Administrators Certification with live practice tests right in your browser - CKA Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/1.常用名词及ETCD等组件.html":{"url":"k8s/1.常用名词及ETCD等组件.html","title":"1. 常用名词及 ETCD 等组件","keywords":"","body":"1. 常用名词2. ETCD等组件3. PODs4. ReplicaSets5. Service6. Namespace1. 常用名词 词汇表 考试报名链接CN 考试报名链接EN Master：manage, plan, schedule, monitor nodes（主节点上也可以安装容器引擎） worker nodes：host application containers etcd cluster：存储所有集群数据的数据库 kube-scheduler：调度程序，确定要放置容器的正确节点 controller-manager： node-controller：加载新节点，替换不可用节点 replication-controller：保证一定数量的容器运行 kube-api：协调集群中的所有操作（api是公开的），定期从kubelet获取状态报告 kubelet：集群中在每个节点上运行的代理 kube-proxy：负责节点间通信 2. ETCD等组件 kubectl命令看到的所有信息都来自ETCD k8s部署的2种方式：kubeadm工具和scratch ETCD监听地址：--advertise-client-urls https://${INTERNAL_IP}:2379，kube-api访问etcd时，应配置这个。ETCD之间连接用2380接口，与其他控制面板组件连接用2379。 kubeadm设置集群，则会将ETCD服务器部署为kube-system名称空间中的PODkubectl get pods -n kube-system etcdctl get / --prefix -keys-only列出k8s存储的所有密钥 k8s存储目录registry：下面有minions、pods、replicasets、deployments、roles、secrets kubectl命令运行实际是在访问kube-apiserver kube-apiserver负责认证和验证请求，检索和更新ETCD数据存储中的数据 node-controller：每5s访问一次，等待40s然后标记为不可访问（通过kube-apiserver），会给节点5min时间恢复，如果node-controller没有恢复节点，则会删除分配给该节点的pod。 scheduler：只负责决定哪个pod在哪个node上运行，不执行放置（kubelet干这个） kubelet：kubeadm不会自动部署kubelet，必须手动在node上安装 service：没有任何接口或主动监听进程，存在于k8s内存中 kube-proxy：在每个node上运行的进程，作为守护者进程部署，它的工作是寻找新的service。 IPTABLES规则：将流量从节点的10.32.0.x发送到service的10.96.0.12 3. PODs kubectl run xxx --image=xxx这类命令首先自动创建一个pod，并部署容器引擎如docker img的实例 查看cluster中pod列表：kubectl get pods -o wide pod-definition.yml apiVersion: v1|apps/v1 kind: Pod|Service|ReplicaSet|Deployment metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx kubectl create -f pod-definition.yml kubectl describe pod nginx：查看pod详细信息 kubectl delete pod nginx：删除pod kubectl edit pod redis：修改pod配置，或者修改yml文件后kubectl apply -f redis-definition.yaml kubectl run --help：查看帮助 kubectl run redis --image=redis123 --dry-run=client -o yaml > redis.yaml：模拟运行输出到yaml文件 4. ReplicaSets Replication Controller：管理跨越集群中多个node rc-definition.yml apiVersion: v1 kind: ReplicationController metadata: name: myapp-rc labels: app: myapp type: front-end spec: template: metadata: labels: app: type: spec: containers: - name: image: replicas: 3 kubectl get replicationcontroller：查看复制控制器 replicaset-definition.yml apiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp-replicaset labels: app: myapp type: front-end spec: template: metadata: labels: app: type: spec: containers: - name: image: replicas: 3 selector: matchLabels: type: front-end Scale： 修改replicas，然后kubectl replace -f replicaset-definition.yml kubectl scale --replicas=6 -f replicaset-definition.yml kubectl scale --replicas=6 replicaset myapp-replicaset type + name 不会更改yaml文件中的replicas kubectl delete replicaset myapp-replicaset：也会删除所有依赖的PODs replicaset 可以缩写为 rs deployment-definition.yml kind: Deployment kubectl create deployment my-dep-name --image==busybox --replicas=3 5. Service NodePorts范围：30000 - 32767 service-definition.yml apiVersion: V1 kind: Service metadata: name: myapp-service spec: type: NodePort ##LoadBalancer ports: - targetPort: 80 ##pod端口 不填则默认和port相同 port: 80 ##Servoce端口 必填 nodePort: 30008 ##对外端口 不填自动分配30000-32767 selector: ##选择pods的label内容 app: myapp type: front-end kubectl create -f service-definition.yml 192.168.1.2:30008 6. Namespace mysql.connect(\"db-service\") mysql.connect(\"db-service.dev.svc.cluster.local\") cluster.local : domain svc : sub domain for service dev : Namespace db-service : Service Name kubectl get pods --namespace=kube-system 确保在dev Namespace中创建的pod kubectl create -f pod-definition.yml --namespace=dev 在yaml文件中，指定metadata.namespace=dev namespace-dev.yml apiVersion: v1 kind: Namespace metadata: name: dev 设置永久切换Namespace kubectl config set-context $(kubectl config current-context) --namespace=dev 查看所有Namespace中的pods：kubectl get pods --all-namespaces，-Ashort for --all-namespaces 设置Resource Quota，Compute-quota.yaml： apiVersion: v1 kind: ResourceQuota metadata: name: compute-quota namespace: dev spec: hard: pods: \"10\" requests.cpu: \"4\" requests.memory: 5Gi limits.cpu: \"10\" limits.memory: 10Gi kubectl run redis --image=redis -n=finance其中-nshort for --namespace Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/2.命令式和声明式.html":{"url":"k8s/2.命令式和声明式.html","title":"2. 命令式和声明式","keywords":"","body":"1. 命令式和声明式2. kubectl apply 原理1. 命令式和声明式 命令式 Imperative： kubectl run nginx --image=nginx --port=80 --labels=\"tier=db,env=prod\" --expose=true ##container的port kubectl create deployment --image=nginx nginx kubectl expose deployment nginx --port 80 ## cluster的port kubectl edit deployment nginx ##仅修改活动对象配置文件 kubectl scale deployment nginx --replicas=5 kubectl set image deployment nginx nginx=nginx:1.18 kubectl create -f nginx.yaml kubectl replace -f nginx.yaml ##更新本地配置文件后运行 kubectl replace --force -f nginx.yaml ##删除后再创建 kubectl delete -f nginx.yaml 声明式 Declarative： kubectl apply -f nginx.yaml kubectl apply -f /path ##根据路径创建多个对象 创建 NGINX Pod kubectl run nginx --image=nginx 生成 POD 清单 YAML 文件-o yaml，如果不想实际创建则用--dry-run kubectl run nginx --image=nginx --dry-run=client -o yaml 创建部署 kubectl create deployment --image=nginx nginx 生成部署 YAML 文件-o yaml，如果不想实际创建则用--dry-run kubectl create deployment --image=nginx nginx --dry-run=client -o yaml 使用 4 个副本生成部署 kubectl create deployment nginx --image=nginx --replicas=4 您还可以使用该kubectl scale命令扩展部署。 kubectl scale deployment nginx --replicas=4 另一种方法是将 YAML 定义保存到文件并修改 kubectl create deployment nginx --image=nginx --dry-run=client -o yaml > nginx-deployment.yaml 然后，您可以在创建部署之前使用副本或任何其他字段更新 YAML 文件。 创建一个名为 redis-service 的 ClusterIP 类型的 Service 以在端口 6379 上公开 pod redis kubectl expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml （这将自动使用 pod 的标签作为选择器） 或者 kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml （这不会将 pods 标签用作选择器，而是将选择器假定为app=redis。您不能将选择器作为选项传递。因此，如果您的 pod 具有不同的标签集，它就不能很好地工作。所以生成文件并在创建服务之前修改选择器） 创建一个名为 nginx 的 NodePort 类型的 Service 以在节点上的 30080 端口上公开 pod nginx 的 80 端口： kubectl expose pod nginx --type=NodePort --port=80 --name=nginx-service --dry-run=client -o yaml （这将自动使用 pod 的标签作为选择器，但您不能指定节点端口。您必须生成定义文件，然后手动添加节点端口，然后再使用 pod 创建服务。） 或者 kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml （这不会使用 pods 标签作为选择器） 上述两个命令都有自己的挑战。虽然其中一个不能接受选择器，但另一个不能接受节点端口。我建议使用kubectl expose命令。如果需要指定节点端口，请使用相同的命令生成定义文件，并在创建服务之前手动输入节点端口。 参考： https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands https://kubernetes.io/docs/reference/kubectl/conventions/ 2. kubectl apply 原理 本地的yaml配置文件会转换成 json 格式的文件 kubectl apply 会对本地配置文件、最后一次 apply 的配置文件（Json）和实时对象配置文件进行对比，当本地配置文件更新后也会同时更新其他2个配置文件 合并更改：https://kubernetes.io/docs/tasks/manage-kubernetes-objects/declarative-config/#merging-changes-to-primitive-fields Json 内容实际保存在实时对象配置文件中的 metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: {Json Content} 实际请不要这样配置 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/3.调度.html":{"url":"k8s/3.调度.html","title":"3. 调度","keywords":"","body":"1. 绑定 Pod2. Labels3. Taints - Node4. Tolerations - Pods5. Node Selectors6. Node Affinity1. 绑定 Pod 未命名隐藏字段nodeName的 pod 将作为候选进行调度 spec: nodeName: node02 但对于已创建的 pod，pod-definition.yaml中的nodeName字段不允许修改，因此将Node分配给 pod 的另一种方法是创建一个绑定对象，并向 pod 绑定 API 发送 post 请求： Pod-bind-definition.yaml apiVersion: v1 kind: Binding metadata: name: nginx target: apiVersion: v1 kind: Node name: node02 把 yaml 文件转换成 Json 格式 curl --header \"Content-Type:application/json\" --request POST --data '{\"apiVersion\":\"v1\", \"kind\": \"Binding\", ...}' http://$SERVER/api/v1/namespaces/default/pods/$PODNAME/binding 2. Labels kubectl get all kubectl get pods -l env=dev | wc -l : 列出env=dev的pod个数（包含header），-l short for --selector kubectl get pods -l env=dev --no-headers | wc -l : 列出env=dev的pod个数（不包含header） kubectl label node node01 color=blue : 添加Label 3. Taints - Node kubectl taint nodes node-name key=value:taint-effect taint-effect : NoSchedule | PreferNoSchedule | NoExecute NoExecute : 新Pod不会部署，已存在的节点也会终止 4. Tolerations - Pods pod-definition.yml spec: tolerations: - key: app operator: Equal value: blue effect: NoSchedule kubectl describe node kubemaster | grep Taint : 查看master node的Taint kubectl taint node node-name key=value:NoSchedule- : 清除taint 5. Node Selectors pod-definition.yml spec: nodeSelector: size: Large ##生效前需要先标记 node kubectl label nodes = : 标记node 6. Node Affinity pod-definition.yml spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: size operator: NotIn | In | Exists ## Exists运算符甚至不需要下面的values values: - Large - Medium Available ： requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecution Planned : requiredDuringSchedulingrequiredDuringExecution DuringScheduling：Pod不存在且是首次创建 DuringScheduling DuringExecution Type1 Required Ignored Type2 Preferred Ignored Type3 Required Required Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/4.设定资源.html":{"url":"k8s/4.设定资源.html","title":"4. 设定资源","keywords":"","body":"pod-definition.yaml : 也可以手动设定所需资源 apiVersion: v1 kind: Pod metadata: name: simple-webapp-color labels: name: simple-webapp-color spec: containers: - name: simple-webapp-color image: simple-webapp-color ports: - containerPort: 8080 resources: requests: ##没有足够的资源创建，则pod会pending memory: \"1Gi\" cpu: 1 limits: memory: \"2Gi\" cpu: 2 单位： CPU：最小0.1，代表100M，M - million。1 CPU代表1 vCPU aws | 1 core in GCP | 1 hyper thread memory：1G - Gigabyte，1M - Megabyte，1K - Kilobyte，1Gi - Gibibyte，1Mi - Mebibyte，1Ki - Kibibyte，带i是精确的用1024换算 默认： Docker默认不限制container的CPU使用，Kubernetes默认设置1 CPU 对于memory也是类似，Kubernetes默认设置512 Mi 超限： Kubernetes默认throttle，CPU不会超出限制 container可以超限使用内存，pod使用超出限制的内存，则会被terminate 使用默认值前需要在Namespace创建LimitRange apiVersion: v1 kind: LimitRange metadata: name: mem-limit-range spec: limits: - default: memory: 512Mi defaultRequest: memory: 256Mi type: Container https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/ apiVersion: v1 kind: LimitRange metadata: name: cpu-limit-range spec: limits: - default: cpu: 1 defaultRequest: cpu: 0.5 type: Container https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/ References: https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource 已存在的pod属性不可编辑，除了以下部分属性： spec.containers[*].image spec.initContainers[*].image spec.activeDeadlineSeconds spec.tolerations 运行edit编辑pod不可修改的属性，会显示 Forbidden: pod updates may not change fields other than ... 的详细信息，并生成临时copy，可以利用copy修改需要的属性，删除原有pod后可根据临时文件生成新的pod。 编辑deployment不受影响，新的配置会自动删除原来的pod生成新的。 kubectl replace --force -f pod-def.yaml Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/5.守护进程、静态Pod、多调度器.html":{"url":"k8s/5.守护进程、静态Pod、多调度器.html","title":"5. 守护进程、静态Pod、多调度器 ","keywords":"","body":"1. Daemon Sets2. Static Pods3. Multiple Schedulers1. Daemon Sets Daemon Sets确保 pod 的一个副本始终存在于集群的所有节点中，常用于 Monitoring Solution、Logs Viewer、Kube-porxy、Weave-net（networking）。 daemon-set-definition.yaml apiVersion: apps/v1 kind: DaemonSet ##唯一区别 metadata: name: elasticsearch namespace: kube-system labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: containers: - name: fluentd-elasticsearch image: k8s.gcr.io/fluentd-elasticsearch:1.20 在 v1.12 之前，pod 可以设置 nodeName 以放置到想要的 node 上，之后使用 scheduler 和 affinity。 因为没有kubectl create daemonset相关的命令，所以创建DaemonSets时可以先用create deployment 命令生成 yaml 模板，kubectl create deployment ds-name -n=namespace-name --image=image-name --dry-run=client -o yaml > app.yaml，修改后 apply。 2. Static Pods kubelet 依赖于 kube-apiserver 来获得关于在其 node 上加载哪些 pod 的指令，这是基于存储在 etcd 数据库中的 kube-scheduler 所做的决定。 kubelet 也可以独立运行，可以创建 pod，可以指定用于存储 pod 信息的目录中读取 pod 定义文件。kubelet 会每隔一段时间确认 pod 定义文件的信息，并保持一致。 replicasets、deployment、service无法独立运行。它们都是整个 Kubernetes 架构的概念组成部分，需要复制和部署控制器等其他控制平面组件。 kubelet 在 pod 级别工作，只能理解 pod，这也是为什么它能够创建 static pod。 指定目录可以是任意地址，指定方式为kubelet.service文件中 --pod-manifest-path=/etc/Kubernetes/manifests --config=kubeconfig.yaml ps : kubeadmin 也是用这种方式实现的 其中kubeconfig.yaml staticPodPath: /etc/Kubernetes/manifests 用docker ps查看 Static Pod 生成结果，如果没有 Kubernetes cluster。 如果有 Kubernetes cluster，kube-apiserver 会知道 Static Pod 的情况。（kube-apiserver 上会有个 Static Pod 的只读镜像，pod 的 name 会附加 node 的名称） 可以使用 Static Pod 将控制平面组件本身作为 pod 部署在 node 上，这样就可以在本地进行部署，不必下载二进制文件配置服务或担心服务崩溃，这也是 kubeadmin 工具设置 Kubernetes 集群的方式。 Static Pods vs DaemonSets Static Pods DaemonSets Created by the Kubelet Created by Kube-API server (DaemonSet Controller) Deploy Control Plane components as Static Pods Deploy Monitoring Agents, Logging Agents on nodes Ignored by the Kube-Scheduler Ignored by the Kube-Scheduler 判断是 Static Pod 的几种方式： pod name 结尾带有 node name kubectl get pod pod-name -n=kube-system -o yaml中查看配置文件，ownerReferences 属性下 kind 为 Node，普通的为 ReplicaSet 等 查看 Static Pod 的配置文件位置： 查找config文件的方式 ps -aux | grep kubelet 查看 --config 项 查看/var/lib/kubelet/config.yaml中的staticPodPath 添加 command 的方式：在 kubectl 命令后加上--command -- sleep 1000，请保证--command放在整条命令之后，所有在--后的都会被视为添加的 command。 创建 Static Pod 的方式就是把 pod 定义文件放到 staticPath 切换 node 的方式ssh node-ip-address 3. Multiple Schedulers kube-scheduler.service ExecStart=/usr/local/bin/kube-scheduler \\\\ --config=/etc/kubernetes/config/kube-scheduler.yaml \\\\ --scheduler-name= default-scheduler /etc/kubernetes/manifests/kube-scheduler.yaml apiVersion: v1 kind: Pod metadata: name: my-custom-scheduler namespace: kube-system spec: containers: - command: ##包含用于启动调度程序的命令和相关选项 - kube-scheduler - --address=127.0.0.1 - --kubeconfig=/etc/kubernetes/scheduler.conf - --leader-elect=true ##没有多个主节点运行scheduler就设置为false - --scheduler-name=my-custom-scheduler ##设置调度程序的自定义名称 - --lock-object-name=my-custom-scheduler ##用于区分自定义调度程序和默认调度程序 image: k8s.gcr.io/kube-scheduler-amd64:v1.11.3 name: kube-scheduler pod-definition.yaml apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - image: nginx name: nginx schedulerName: my-custom-scheduler kubectl get events：查看哪个 scheduler 调用 kubectl logs my-custom-scheduler --name-space=kube-system：查看日志 kubectl create configmap my-scheduler-config --from-file=/root/my-scheduler-config.yaml -n kube-system：创建 configmap Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/6.监控、滚动升级、回滚及参数配置.html":{"url":"k8s/6.监控、滚动升级、回滚及参数配置.html","title":"6. 监控、滚动升级、回滚及参数配置","keywords":"","body":"1. 监控2. 使用Metrics Server3. Logs4. Rolling Updates and Rollbacks5. 命令和参数（Commands and Arguments）6. Kubernetes 中的环境变量7. ConfigMaps1. 监控 Kubernetes 没有提供功能全面的内置监控解决方案，但有许多开源解决方案可用，如 Metrics-Server、Prometheus、Elastic Stack、DATADOG、dynatrace。 Heapster 是 Kubernetes 启用监控和分析功能的原始项目之一，但现已弃用，并形成了一个精简版本，称为 Metrics Server（In-Memory）。 Kubelet 包含一个称为 cAdvisor 或 container advisor 的子组件，负责从 pod 中检索性能指标，发送给 apiserver。 2. 使用Metrics Server 安装 minikube : minikube addons enable metrics-server others : git clone https://github.com/kubernetes-incubator/metrics-server.git 部署：pods、services、roles kubectl create -f deploy/1.8+/ : 在下载后 repo 中执行-f . 查看：kubectl top (node | pod) 3. Logs docker run kodekloud/event-simulator，event-simulator 用来生成随机事件模拟 web 服务器，它本身有 std ouput，但如果在 detach 模式下运行run -d，那么想查看日志可以使用docker logs -f container-id，-f选项帮助查看实时日志跟踪。 在 Kubernetes 中也是一样： kubectl create -f event-simulator.yaml apiVersion: v1 kind: Pod metadata: name: event-simulator-pod spec: containers: - name: event-simulator image: kodekloud/event-simulator kubectl logs -f pod-name container-name：如果 pod 中包含多个 container，则必须要指明 container-name，否则会报错，或用-c指定 container。 当 Pod 有多个容器时打开 shell：kubectl -n elastic-stack exec -it app -- cat /log/app.log或kubectl exec -i -t my-pod --container main-app -- /bin/bash，-iand-tare the same as the long options --stdin and --tty 4. Rolling Updates and Rollbacks kubectl rollout status deployment/myapp-deployment：查看状态 kubectl rollout history deployment/myapp-deployment：查看历史 部署策略： Recreate：一次销毁所有旧的，新建新版本 Rolling Update：滚动更新，一次更新一个 更新 image 的方式： kubectl apply -f deployment-definition.yml kubectl set image deployment/myapp-deployment nginx=nginx:1.9.1：会导致部署定义文件具有不同的配置 回滚：kubectl rollout undo deployment/myapp-deployment，回滚会在原来的replicasets上重新创建 5. 命令和参数（Commands and Arguments） pod-definition.yml 实际执行为 command 后面跟着 args apiVersion: v1 kind: Pod metadata: name: ubuntu-sleeper-pod spec: containers: - name: ubuntu-sleeper image: ubuntu-sleeper command: [\"sleep2.0\"] ##覆写dockerfile中的ENTRYPOINT args: [\"10\"] ##覆写dockerfile中的CMD 也可以写成 command: - \"sleep\" - \"10\" 6. Kubernetes 中的环境变量 docker run -e APP_COLOR=pink simple-webapp-color pod-definition.yaml spec: containers: env: - name: APP_COLOR value: pink valueFrom: ## 2. 单个环境变量导入 configMapKeyRef: ##ConfigMap name: key: secretKeyRef: ##Secrets 7. ConfigMaps spec: containers: envFrom: ## 1. 多个环境变量导入 - configMapRef: name: app-color volumes: ##3. 作为文件导入volume - name: app-config-volume configMap: name: app-config 创建： kubectl create configmap --from-literal== --from-literal=... 或使用文件创建 --from-file=app_config.properties kubectl create -f apiVersion: v1 kind: ConfigMap metadata: name: app-config data: APP_COLOR: blue APP_MODE: prod Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/7.Secrets.html":{"url":"k8s/7.Secrets.html","title":"7. Secrets","keywords":"","body":"1. 创建2. 转换编码3. 查看4. 添加到pod1. 创建 kubectl create secret generic --from-literal== 或 --from-file= kubectl create -f secret-data.yaml secret-data.yaml apiVersion: v1 kind: Secret metadata: name: app-secret data: DB_Host: mysql DB_User: root DB_Password: paswrd 2. 转换编码 编码：echo -n 'mysql' | base64 解码：echo -n 'bXlzcWw=' | base64 --decode 3. 查看 kubectl get secret app-secret -o yaml 4. 添加到pod pod-definition.yaml : secrets 可以作为数据卷挂载或公开为环境变量由 Pod 中的容器使用 apiVersion: v1 kind: Pod metadata: name: simple-webapp-color labels: name: simple-webapp-color spec: containers: - name: simple-webapp-color image: simple-webapp-color ports: - containerPort: 8080 envFrom: - secretRef: name: app-config env: - name: DB_Password valueFrom: secretKeyRef: name: app-secret key: DB_Password volumes: - name: app-secret-volume secret: secretName: app-secret 如果以文件形式创建secret，则对每个secret会生成对应的文件：ls /opt/app-secret-volumes，cat /opt/app-secret-volumes/DB_Password 最佳实践： 未将secret对象定义文件签入源代码存储库 为Secret启用静态加密，以便将它们加密存储在ETCD中 Kubernetes处理secret的方式： 仅当节点上的pod需要时，才会将secret发送到该节点 Kubelet将secret存储到tmpfs中，这样secret就不会写入磁盘存储 一旦依赖于secret的Pod被删除，kubelet也会删除其本地的secret数据副本 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/8.升级和版本.html":{"url":"k8s/8.升级和版本.html","title":"8. 升级和版本","keywords":"","body":"1. Upgrades2. Releases1. Upgrades 默认 pod 超时时间为5分钟：kube-controller-manager --pod-eviction-timeout=5m0s 系统升级时更安全的方式是：kubectl drain node-1，节点会被标记为不可调度，会清除 pod，但当 pod 不属于 replicaSet 时，drain 会失败，需要加上 --force，这个 pod 就会丢失，不会再在其他node 上被创建 升级完成之后：kubectl uncordon node-1 kubectl cordon node-2不会清除pod 使用 kubectl get nodes 可以在 VERSION 列查看版本 v1.11.3 MAJOR MINOR : Features, Functionalities PATCH : Bug Fixes ETCD、CoreDNS 的版本独立，kube-apiserver 的版本一般比其他的组件更高，kubectl 的版本可能会高或者低1个版本，其他 Controller-manager、kube-scheduler、kubelet、kube-proxy 版本保持一致。 Kubernetes 只支持最近的3个版本，当使用的 k8s 版本不再支持时，建议一次只升级一个版本。 使用 kubeadm 升级： kubeadm upgrade plan 查看最近稳定可用的版本 kubeadm upgrade apply 先升级 master node，再升级 work node 2. Releases 升级master node： apt-get upgrade -y kubeadm=1.12.0-00 kubeadm upgrade apply v1.12.0 kubectl get nodes 上显示的是apiserver版本 如果master node上有kubelet，则apt-get upgrade -y kubelet=1.12.0-00，然后systemctl restart kubelet 升级work node： kubectl drain node-1 把节点上的pod转移到其他节点 apt-get upgrade -y kubeadm=1.12.0-00 apt-get upgrade -y kubelet=1.12.0-00 kubeadm upgrade node config --kubelet-version v1.12.0 systemctl restart kubelet kubectl uncordon node-1 查看系统版本：cat /etc/*release* Ubuntu 升级 master node 流程：升级 node 用 upgrade apply 版本 On the controlplane node, run the command run the following commands: apt update : This will update the package lists from the software repository. apt install kubeadm=1.20.0-00 : This will install the kubeadm version 1.20 kubeadm upgrade apply v1.20.0 : This will upgrade kubernetes controlplane. Note that this can take a few minutes. apt install kubelet=1.20.0-00 : This will update the kubelet with the version 1.20. You may need to restart kubelet after it has been upgraded. Run: systemctl daemon-reload, systemctl restart kubelet Ubuntu 升级 work node 流程：升级 node 用 upgrade node If you are on the master node, run ssh node01 to go to node01 apt update : This will update the package lists from the software repository. apt install kubeadm=1.20.0-00 : This will install the kubeadm version 1.20 kubeadm upgrade node : This will upgrade the node01 configuration. 不用写node-name apt install kubelet=1.20.0-00 : This will update the kubelet with the version 1.20. You may need to restart kubelet after it has been upgraded. Run: systemctl daemon-reload, systemctl restart kubelet Type exit or enter CTL + d to go back to the controlplane node. uncordon work node 需要切换到 master node 官方文档：https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/ Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/9.备份、认证及TLS.html":{"url":"k8s/9.备份、认证及TLS.html","title":"9. 备份、认证及TLS","keywords":"","body":"1. 备份2. 还原3. Authentication4. Static Password File5. TLS6. Certificate7. Certificates API1. 备份 kubectl get all --all-namespaces -o yaml > all-deploy-services.yaml 与其备份单个资源，不如备份ETCD： etcd.service --data-dir=/var/lib/etcd etcd也自带快照功能 ETCDCTL_API=3 etcdctl \\ ##根据etcdctl版本 不想重复写就export ETCDCTL_API=3 设置全局参数 snapshot save snapshot.db snapshot status snapshot.db ##查看备份状态 2. 还原 Restore：会初始化新的集群配置，将etcd配置为新成员，以防止新成员加入现有集群 ETCDCTL_API=3 etcdctl \\ service kube-apiserver stop snapshot restore snapshot.db --data-dir /var/lib/etcd-from-backup ##使用新的数据目录，将备份还原到此数据目录 systemctl daemon-reload service etcd restart service kube-apiserver start 可以对备份指定访问端口和密钥信息： ETCDCTL_API=3 etcdctl \\ snapshot save snapshot.db ##如果启用了TLS，以下选项是强制性的 --endpoints=https://127.0.0.1:2379 --cacert=/etc/etcd/ca.crt --cert=/etc/etcd/etcd-server.crt --key=/etc/etcd/etcd-server.key 还原后需要设置新的 etcd-data 的 hostPath： volumes: - hostPath: path: /var/lib/etcd ##修改为etcd-from-backup新目录 type: DirectoryOrCreate name: etcd-data 查看 node 相关的 clusters： kubectl config view kubectl config get-clusters 更换 node 上的 cluster context： kubectl config use-context cluster1 查看ETCD服务器所属的ETCD集群中有多少节点： ETCDCTL_API=3 etcdctl \\ --endpoints=https://127.0.0.1:2379 \\ --cacert=/etc/etcd/pki/ca.pem \\ --cert=/etc/etcd/pki/etcd.pem \\ --key=/etc/etcd/pki/etcd-key.pem \\ member list 跨 node 复制文件：scp cluster1-controlplane:/opt/cluster1.db /opt/cluster1.db 如果是外部的 etcd，需要修改 /etc/systemd/system/etcd.service中的 data-dir，添加新路径的 etcd 权限 chown -R etcd:etcd /var/lib/etcd-data-new，最后重启服务 systemctl daemon-reload, systemctl restart etcd。 3. Authentication 禁用基于密码的身份验证 仅提供基于SSH密钥的身份验证 第一道防线：控制对API服务器本身的访问 用户名+密码 用户名+Token 证书 与LDAP等外部身份验证提供程序集成 服务账户 可以做什么？ RBAC Authorization 基于角色的访问控制 ABAC Authorization 基于属性的访问控制 Node Authorization 基于节点的访问控制 Webhook Mode kubectl create serviceaccount sa1 kubectl get serviceaccount 验证方式kube-apiserver： Static Password File Static Token File Certificates Identity Services，第三方身份验证协议，如LDAP、Kerberos等 4. Static Password File user-details.csv : password,username,userid(,groupname optional) ... user-token-details.csv : token,username,userid(,groupname optional) ... 定义方式： --basic-auth-file=user-details.csv --token-auth-file=user-details.csv apiserver重启才能生效 kubeadm /etc/kubernetes/manifests/kube-apiserver.yaml apiVersion: v1 kind: Pod metadata: creationTimestamp: null name: kube-apiserver namespace: kube-system spec: containers: - command: - kube-apiserver - --authorization-mode=Node,RBAC - --advertise-address=172.17.0.107 - --allow-privileged=true - --enable-admission-plugins=NodeRestriction - --enable-bootstrap-token-auth=true image: k8s.gcr.io/kube-apiserver-amd64:v1.11.3 name: kube-apiserver 访问： curl -v -k https://master-node-ip:6443/api/v1/pods -u \"username:password\" {data...} curl -v -k --header \"Authorization: Bearer xxxxxxxx\" 注意点： 不推荐使用静态储存（在v1.19已弃用） Consider volume mount while providing the auth file in a kubeadm setup Setup Role Based Authorization for the new users 5. TLS 查看 Common Name (CN)：openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text Symmetric Encryption：对称加密，使用相同的密钥来加密和解密数据，必须在发送方和接收方之间交换，因此存在风险 Asymmetric Encryption：非对称加密，Private Key 和 Public Lock ssh-keygen 生成私钥 id_rsa 和公钥 id_rsa.pub 添加公钥：通常是在服务器SSH授权的下划线密钥文件中添加一个包含公钥的条目来完成的 cat ~/.ssh/authorized_keys ssh-rsa AAAAB3Nza... user1 ssh-rsa AAAXCV2b8... user2 指定私钥 ssh -i id_rsa user1@server1 使用openssl生成私钥、公钥： openssl genrsa -out my-bank.key 1024 ## private key ## my-bank.key openssl rsa -in my-bank.key -pubout > mybank.pem ## public key ## my-bank.key mybank.pem 证书包含： 有关谁向该服务器的公钥颁发证书的信息 该服务器地址 ... 生成证书的时候必须带有签名，自签名的证书会被认为非法 Certificate Authority (CA) 负责签署和验证证书，比较著名的有 Symantec、Desert、Comodo、Global Sign 等等 签名的方式： 用之前生成的密钥和网站域名生成Certificate Signing Request (CSR) openssl req -new -key my-bank.key -out my-bank.csr -subj \"/C=US/ST=CA/O=MyOrg, Inc./CN=mydomain.com\" ## 对于hacker Validate Information会失败 ## my-bank.key my-bank.csr 验证通过，Sign and Send Certificate CA合法性的验证：签名用私钥，所有CA的公钥都存在浏览器中 私有CA：一样的运作方式，为组织内所有浏览器安装私有CA的公钥 Kubernetes要求集群至少有一个证书颁发机构CA，也可以设置多个 之前尝试使用命令行登陆证书过期的https失败 openssl x509 -inform der -in \\*.thoughtworks.cn.cer -out certificate.pem 但是缺少私钥，一般会生成公钥和私钥，或者合并为同一份pem文件。 curl --cert certificate.pem --header 'Content-Type: application/json' -d '{\"captcha\": \"111\", \"captchaId\": \"captchaId\", \"password\": \"password\", \"username\": \"user\"}' --request POST https://sample.com 更改hosts方法 sudo vim /etc/hosts 如果api-server不可用，用命令查看频繁退出的container的id crictl ps -a | grep kube-apiserver，并查看日志 crictl logs --tail=2 1fb242055cff8找出原因 - Container Runtime Interface (CRI) 6. Certificate 6.1 证书创建 证书生成工具：easyrsa、openssl、cfssl 生成CA certificate步骤： Generate Keys openssl genrsa -out ca.key 2048 Certificate Signing Request openssl req -new -key ca.key -subj \"/CN=KUBERNETES-CA\" -out ca.csr Sign Certificates : CA创建root certificate是自我签名 openssl x509 -req -in ca.csr -signkey ca.key -out ca.crt 生成client certificate步骤： Generate Keys openssl genrsa -out admin.key 2048 Certificate Signing Request openssl req -new -key admin.key -subj \"/CN=kube-admin\" -out admin.csr Sign Certificates : CA创建root certificate是自我签名 openssl x509 -req -in ca.csr -signkey ca.key -out ca.crt 可以通过在证书中添加用户组详细信息以区分不同的注册用户：openssl req -new -key admin.key -subj \"/CN=kube-admin/O=system:masters\" -out admin.csr 系统组件其名称必须以关键字system作为前缀 kube-api server 有多个别名：kubernetes、kubernetes.default、kubernetes.default.svc、kubernetes.default.svc.cluster.local kube-api 添加别名方式： openssl req -new -key apiserver.key -subj \"/CN=kube-apiserver\" -out apiserver.csr -config openssl.cnf openssl.cnf： [alt_names] DNS.1 = kubernetes DNS.2 = kubernetes.default DNS.3 = kubernetes.default.svc DNS.4 = kubernetes.default.svc.cluster.local IP.1 = 10.96.0.1 IP.2 = 1720.17.0.87 6.2 查看证书细节 x509解码证书以查看详细信息： openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout 如果核心组件（如kubernetes api-server或etcd-server关闭），kubectl命令无法使用，可以用docker命令查看日志 Kubernetes Certificate Health Check Spreadsheet : https://github.com/mmumshad/kubernetes-the-hard-way/tree/master/tools 7. Certificates API 用户创建key： openssl genrsa -out jane.key 2048 用户把key发给admin，admin用这个key创建certificate signing request对象： openssl req -new -key jane.key -subj \"/CN=jane\" -out jane.csr Jane-csr.yaml kubectl create -f Jane-csr.yaml apiVersion: certificates.k8s.io/v1beta1 kind: CertificateSigningRequest metadata: name: jane spec: groups: - system:authenticated usages: - digital signature - key encipherment - server auth request: ## 请求内容用base64 encode ## cat jane.csr | base64 | tr -d \"\\n\" 或 base64 -w 0 禁用换行 创建对象后，admin可以通过 kubectl get csr 查看所有证书请求，通过 kubectl certificate approve jane，拒绝则用 deny，删除则用 kubectl delete csr jane 通过以yaml格式查看证书 kubectl get csr jane -o yaml，用base64解码 echo \"...=\" | base64 --decode 所有与证书相关的操作都由Controller Manage执行：其中包含CSR-APPROVING、CSR-SIGNING等控制器 其中的key和根证书在 /etc/kubernetes/manifests/kube-controller-manager.yaml 中的 spec: containers: - command: - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/10.RBAC.html":{"url":"k8s/10.RBAC.html","title":"10. RBAC","keywords":"","body":"1. KubeConfig2. RBAC3. Service Accounts4. Image Security1. KubeConfig 使用访问API获取pods信息： curl https://my-kube-playground:6443/api/v1/pods \\ --key admin.key --cert admin.crt --cacert ca.crt 用kubectl达成相同的目的： kubectl get pods --server my-kube-playground:6443 --client-key admin.key --client-certificate admin.crt --certificate-authority ca.crt 使用kubeconfig代替每次冗长的输入： kubectl get pods --kubeconfig config $HOME/.kube/config apiVersion: v1 kind: Config current-context: dev-user@google ## 指定默认的上下文 clusters: - name: production cluster: certificate-authority: /etc/kubernetes/pki/ca.crt ## 也可以直接使用证书内容代替 certificate-authority-data: 以cat ca.crt | base64格式写入 server: https://172.17.0.51:6443 contexts: - name: admin@production context: cluster: production user: admin namespace: finance users: - name: admin user: client-certificate: /etc/kubernetes/pki/users/admin.crt client-key: /etc/kubernetes/pki/users/admin.key 使用 kubectl config view 查看当前kubeconfig 可以 kubectl config view --kubeconfig=my-custom-config 指定kubeconfig 使用 kubectl config use-context prod-user@prodection --kubeconfig /root/my-kube-config 指定kubeconfig，更换上下文 设置默认config：mv .kube/config .kube/config.bak 备份，然后复制 cp /root/my-kube-config .kube/config 2. RBAC 集群层面请使用 ClusterRole 和 ClusterRoleBindings developer-role.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: developer rules: - apiGroups: [\"\"] ## 可以用 kubectl api-resources 查看 apiversion resources: [\"pods\"] verbs: [\"list\", \"get\", \"create\", \"update\", \"delete\"] - apiGroups: [\"\"] resources: [\"ConfigMap\"] verbs: [\"create\"] 创建角色：kubectl create -f developer-role.yaml devuser-developer-binding.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: devuser-developer-binding subjects: - kind: User name: dev-user apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: developer apiGroup: rbac.authorization.k8s.io 创建角色绑定：kubectl create -f devuser-developer-binding.yaml 查询： kubectl get roles kubectl get rolebindings kubectl describe role developer kubectl describe rolebinding devuser-developer-binding 验证权限： kubectl auth can-i create deployments kubectl auth can-i delete nodes --as dev-user --namespace test 使用命令行创建、绑定、编辑角色： kubectl create role developer --namespace=default --verb=list,create,delete --resource=pods kubectl create rolebinding dev-user-binding --namespace=default --role=developer --user=dev-user kubectl edit role developer -n blue apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: developer namespace: blue rules: - apiGroups: - apps resourceNames: - dark-blue-app resources: - pods verbs: - get - watch - create - delete - apiGroups: - apps resources: - deployments verbs: - get - watch - create - delete 3. Service Accounts kubectl create serviceaccount dashboard-sa kubectl get serviceaccount kubectl describe serviceaccount dashboard-sa 当创建Service Account时，首先创建 Service Account 对象，然后为服务账户生成令牌 查看secret token：kubectl describe secret dashboard-sa-token-kbbdm 利用 Service Account 创建 token：kubectl create token sa-name 默认采用 default 的 Service Account，可以在deployment指明 Service Account，在 pod spec 下添加 serviceAccountName: sa-name 使用curl访问： curl https://192.168.56.70:6443/api -insecure --header \"Authorization: Bearer \" 每个namespace都会创建 default 的 Service Account：kubectl exec -it my-kubernetes-dashboard ls /var/run/secrets/kubernetes.io/serviceaccount，默认只有运行基本的Kubernetes API 查询的权限 无法编辑pod中的Service Account，只能删除后新建，在deployment中可以。 如果不想自动挂载Service Account，可以设置： spec: automountServiceAccountToken: false 4. Image Security image: docker.io/library/nginx：不指定用户名或账户名，则会假定为library。Registry，User/Account，Image/Repository docker login private-registry.io docker run private-registry.io/apps/internal-app kubectl create secret docker-registry regcred \\ ## 取名为regcred --docker-server= private-registry.io \\ --docker-username= registry-user \\ ## 类型为docker-registry --docker-password= registry-password \\ --docker-email= registry-user@org.com deployment 应用 secret 需要添加以下设置： spec: imagePullSecrets: - name: regcred 查看哪个user在运行pod：kubectl exec pod-name -- whoami 修改 securityContext spec: securityContext: runAsUser: 1010 ## 设置在pod或container level spec: securityContext: capabilities: ## 设置在container level add: [\"SYS_TIME\"] Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/11.网络策略和存储.html":{"url":"k8s/11.网络策略和存储.html","title":"11. 网络策略和存储","keywords":"","body":"1. Network Policy2. 存储3. Container Storage Interface1. Network Policy apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: db-policy spec: podSelector: matchLabels: role: db policyTypes: - Ingress ## 设置入口规则，不会影响出口 - Egress ingress: - from: - podSelector: ## 规则1 matchLabels: name: api-pod namespaceSelector: ## 限制namespace，这里必须满足pod筛选条件 matchLabels: name: prod - ipBlock: ## 2个规则其一通过即可 cidr: 192.168.5.10/32 ports: - protocol: TCP port: 3306 egress: - to: - ipBlock: cidr: ports: - protocol: TCP port: 80 查询方式：kubectl get netpol 或 kubectl get networkpolicy 2. 存储 安装Docker后，默认存储路径： /var/lib/docker |- aufs |- containers |- image |- volumes 对于Dockerfile buid时的分层架构： Dockerfile FROM Ubuntu RUN apt-get update && apt-get -y install python RUN pip install flask flask-mysql COPY . /opt/source-code ENTRYPOINT FLASK_APP=/opt/source-code/app.py flask run docker build Dockerfile -t my-name/my-custom-app Layer 1. Base Ubuntu Layer ## 120MB Layer 2. Changes in apt packages ## 360MB Layer 3. Changes in pip packages ## 6.3MB 前3层可以复用 Layer 4. Source code ## 229B Layer 5. Update Entrypoint ## 0B 以上都是Image Layers（readonly），Container Layer只有当Container存在时存在 Layer 6. Container Layer ## read & write COPY-ON-WRITE：Image Layers的文件虽然只读，但仍然可以修改，在保存修改之前，Docker会自动在读写层中创建该文件的副本，然后在读写层中修改该文件的不同版本。 volumes：保留持久化数据，即使container被破坏 docker volume create data_volume /var/lib/docker |- volumes |- data_volume 设置image的默认存储数据位置：docker run -v data_volume:/var/lib/mysql mysql，即使在执行这条命令前没有运行创建卷 docker volume create，Docker将会自动创建相对应的卷。 创建的数据卷会挂载到container中的 /var/lib/mysql 绑定挂载：如果数据已存在，则需要给出完整的路径，docker run -v /data/mysql:/var/lib/mysql mysql -v是旧式的写法，现在一般推荐使用--mount，更清晰明了：docker run --mount type=bind,source=/data/mysql,target=/var/lib/mysql mysql 3. Container Storage Interface 如同 Container Runtime Interface (CRI)、Container Storage Interface (CSI)可以适配不同的存储驱动，而不用依赖于Kubernetes本身的代码。 RPC (Remote Procedure Call)：远程过程调用 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/12.硬盘和路由.html":{"url":"k8s/12.硬盘和路由.html","title":"12. 硬盘和路由","keywords":"","body":"1. Volumes2. Persistent Volumes3. Storage Class4. Switching5. Routing6. Gateway7. DNS8. Domain Names9. Search Domain10. Record Types11. nslookup、dig12. 将主机配置成DNS服务器1. Volumes !!!注意题目给的 mountPath 后面有没有 /，可能会判定为不同路径。 apiVersion: v1 kind: Pod metadata: name: random-number-generator spec: containers: - image: alpine name: alpine command: [\"/bin/sh\",\"-c\"] args: [\"shuf -i 0-100 -n 1 >> /opt/number.out;\"] volumeMounts: - mountPath: /opt ## Container内的存储路径 name: data-volume volumes: - name: data-volume hostPath: path: /data ## 对应存储在host上的路径 type: Directory ## awsElasticBlockStore: ## 可替换hostPath ## volumeID: ## fsType: ext4 2. Persistent Volumes Persistent Volumes Claim (PVC) pv-definition.yaml apiVersion: v1 kind: PersistentVolume metadata: name: pv-vol1 spec: accessModes: - ReadWriteOnce capacity: storage: 1Gi awsElasticBlockStore: volumeID: fsType: ext4 管理员创建一组PV，用户创建PVC以用于存储。单个PVC绑定单个PV。 可以使用label进行匹配，如果所有其他条件都匹配，并且没有更好的选项，则较小的PVC可能会绑定到较大的PV，且剩下的存储空间无法再被其他PVC利用。没有PV可用，则PVC会保持pending状态。 selector: matchLabels: name: my-pv ## PVC labels: name: my-pv ## PV pvc-definition.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim spec: accessModes: - ReadWriteOnce resources: requests: storage: 500Mi PVC被删除后，PV的状态取决于： persistentVolumeReclaimPolicy: Retain | Delete | Recycle 3. Storage Class 在应用程序需要时自动配置 volumes sc-definition.yaml 不需要再配置 pv，由 Storage Class 自动创建 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: google-storage provisioner: kubernetes.io/gec-pd parameters: ## 取决于磁盘配置 type: pd-standard replication-type: none pvc-definition.yaml spec: storageClassName: google-storage 4. Switching ip link：用于列出和修改host上的接口， ip link只能看链路层的状态，看不到ip地址 ip addr：查看分配给这些接口的IP地址，即使网卡处于down状态，也能显示出网卡状态，但是ifconfig查看就看不到 cat /etc/network/interfaces：查看物理接口 ip addr add 192.168.1.10/24 dev eth0 # 重启失效 ip addr add 192.168.1.11/24 dev eth0 # 如需永久生效，需要在相应的网络接口文件中修改 之后，两个系统之间就可以通过交换机进行通信。路由器连接到2个网络，可以使它们之间可以通信。 一旦链路建立并分配了IP地址，计算机就可以通过交换机相互通信。交换机只能在同一网络内进行通信，这意味着它可以从网络上的主机接收数据包，并将其传送到同一网络内的其他系统。 ip a | grep internal-ip -B 2：查看cluster内node间的网络接口，ip a 和 ip addr 一样 5. Routing 路由器可帮助连接两个网络，可以将其视为另一台具有许多网络端口的服务器，它获取IP分配，每个网络一个。 6. Gateway 如果说网络是一个房间，那么网关就是通向外部世界、其他网络或Internet的一扇门。系统需要知道门在哪里才能通过。 要查看系统上现有的路由配置，运行 route命令，它会显示内核的路由表。 ip route show default ## 查看默认网关 netstat -nplt | grep scheduler ## 查看目前节点上被scheduler监听的接口 ip route add 192.168.2.0/24 via 192.168.1.1 ## 这样B就可以访问网络2上的系统 ip route add 192.168.1.0/24 via 192.168.2.1 ## 这样C就可以访问网络1上的系统 ip route add 172.217.194.0/24 via 192.168.2.1 ## 如果C需要访问Internet上的某个地址，则也需要把新的路由添加到路由表 在互联网上的不同网络上有许多不同的网站，您不必为每个网络的相同路由器IP地址添加路由表条目，而只需简单地说，对于任何您不知道路由的网络，都可以使用此路由器作为默认网关。 ip route add default via 192.168.1.1 # default = 0.0.0.0 在 Gateway 属性列中 0.0.0.0表示不需要网关，因为它在自己的网络中。 当网络中有多个路由器时，一个用于 Internet，一个用于内部专用网络，那么您需要为每个网络创建两个单独的 entries 条目。 如何将Linux主机配置为路由器？ 数据包要到达host C，则C必须向A发回响应，所以两边都得配置。 当2个系统双向都建立好路由时，在Linux中默认情况下，数据包不会从一个接口转发到下一个接口，所以此时仍还ping不通。这是出于安全考虑，例如您将eth0连接到专用网络，而将eth1连接到公共网络，除非您明确允许，否则我们不希望公共网络中的任何人轻松地向专用网络发送消息。 转发的设置在/proc/sys/net/ipv4/ip_forward，默认情况下文件中的值为0，表示没有转发，设置为1，ping可以通过，重启后失效。 永久设置：/etc/sysctl.conf 中 net.ipv4.ip_forward = 1 7. DNS hostname 命令可以查看本机的hostname 记录在本地 /etc/hosts中，ssh 和 curl 命令都会根据此文件查找对应的ip地址，先查看本地记录，本地优先级高，如果有则优先使用： 192.168.1.11 db DNS配置在 /etc/resolv.conf 文件中，将主机指向DNS服务器： nameserver 192.168.1.100 ## 可添加多个 为了防止也在每个主机上配置多个DNS服务器地址，可以在DNS服务器上将任何未知的主机名转发到Internet上的公共DNS服务器 优先级顺序可以在 /etc/nsswitch.conf 中修改： ... hosts: files dns ... 8. Domain Names www.google.com 根域名 . 顶级域名 .com 分配给google的域名 google 子域名 www 9. Search Domain 在 /etc/resolv.conf 中添加 search 条目并指定要附加的搜索域名 search mycompany.com prod.mycompany.com 输入 web 时，就会尝试匹配 web.mycompany.com 、web.prod.mycompany.com 10. Record Types A web-server 192.168.1.1 AAAA web-server 2001:0db8:85a3:0000:0000:8a2e:0370:7334 CNAME food.web-server eat.web-server, hungry.web-server 11. nslookup、dig Ping不总是测试DNS解析的正确工具，还有 nslookup，如 nslookup www.google.com，但 nslookup 不会考虑本地hosts文件中的条目，仅查询DNS服务器。 类似的还有 dig www.google.com，返回更多详细信息 12. 将主机配置成DNS服务器 下载CoreDNS 解压，运行可执行文件coredns 默认侦听端口53 配置Corefile文件 . { hosts /etc/hosts } 其他参考信息： https://github.com/kubernetes/dns/blob/master/docs/specification.md https://coredns.io/plugins/kubernetes/ Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/13.网络空间.html":{"url":"k8s/13.网络空间.html","title":"13. 网络空间","keywords":"","body":"1. Network Namespace2. Create Network NS3. Exec in Network NS4. 建立NS之间的网络接口连接5. Linux Bridge6. 如何配置 bridge 通过以太网接口到达 LAN 网络？7. 外部网络访问内部专用网络的ns端口的2种解决方案：1. Network Namespace Docker 等容器使用 namespace 来实现网络隔离，容器是使用 namespace 与底层主机分离的。如果把 host 当成房子，那么 namespace 就是房子里你分配给每个孩子的房间。 就容器而言，它只看到由它运行的进程，并认为它是独立的。但是，底层 host 可以看到所有进程，包括在容器内运行的进程。 host 有自己的路由表和 ARP 表（IP -> MAC）。创建容器时，我们为其创建一个 namespace，这样，它就无法查看主机上的任何网络相关信息。在其 namespace 内，容器可以有自己的虚拟接口、路由和 ARP 表。 2. Create Network NS ip netns add red ip netns 3. Exec in Network NS ip link ip netns exec red ip link ## 在ns中查看 ip link，在前面加 ip netns exec ip -n red link ## 或者使用这个命令查看LOOPBACK接口，看不到eth0接口 arp ## 在host上执行能看到条目 ip nets exec red arp ## 在新建的container内看不到条目，用route命令也是同样 4. 建立NS之间的网络接口连接 ## 1. 创建veth并连接 ip link add veth-red type veth peer name veth-blue ## 2. 把每个veth附加到ns ip link set veth-red netns red ip link set veth-blue netns blue ## 3. 为每个ns分配IP地址 ip -n red addr add 192.168.15.1 dev veth-red # dev 表示 device ip -n blue addr add 192.168.15.2 dev veth-blue ## 4. 启动每个ns中的相应设备 ip -n red link set veth-red up ip -n blue link set veth-blue up 接口等都建立完成后 ip netns exec red ping 192.168.15.2 才能ping通 arp 命令才会显示mac地址： arp ip netns exec red arp ip netns exec blue arp host上的ARP表不知道我们创建的新ns，也不知道我们在其中创建的接口。 ARP表：地址解析协议（ARP）是在只知道主机的IP地址时查找主机的链路层（MAC）地址的方法。ARP表用于维护每个MAC地址与其对应IP地址之间的相关性。 5. Linux Bridge 当 host 内需要连接的 ns 很多时，解决方案有：Linux bridge、Open vSwitch 等 ip link add v-net-0 type bridge ## 对host来说，它只是另一个接口 添加后 v-net-0 会出现在 ip link 的命令结果中 ip link set dev v-net-0 up 把新的连接到bridge v-net-0 # 1. 删除之前的ns之间的连接，另一端的接口会自动删除 ip -n red link del veth-red # 2. 创建veth并连接 ip link add veth-red type veth peer name veth-red-br ip link add veth-blue type veth peer name veth-blue-br # 3. 把两端veth连接到相应的ns和bridge ip link set veth-red netns red # 把接口veth-red连接到red namespace ip link set veth-red-br master v-net-0 # 把接口veth-red-br连接到bridge，主设备定为v-net-0 # 4. 分配IP地址 ip -n red addr add 192.168.15.1 dev veth-red # 分配地址 ip -n blue addr add 192.168.15.2 dev veth-blue # 分配地址 # 5. 启动设备 ip -n red link set veth-red up ip -n blue link set veth-blue up 此时在host上仍ping不通其他ns，因为它们属于不同的网络，host上的ARP表不知道我们创建的新ns，也不知道我们在其中创建的接口。 而bridge交换机实际是host上的网络接口，如果想在host和ns之间建立连接，我们需要做的就是为bridge分配一个host层面的IP地址， ip addr add 192.168.15.5/24 dev v-net-0，此时host才可以ping通ns 6. 如何配置 bridge 通过以太网接口到达 LAN 网络？ 本地host其实是连接两个网络的Gateway，host此时有两个IP地址，一个在bridge网络上 192.168.15.5，另一个在外部网络上192.168.1.2 内部ns想要访问到host的eth0 ip netns exec blue ip route add 192.168.1.0/24 via 192.168.15.5 此时 ping 192.168.1.3 不会等到无法访问的消息，ip netns exec blue ping 192.168.1.3，但仍然没有收到任何response，原因类似于家庭网络具有我们的内部私有IP地址，而目标网络不知道这些地址，因此他们无法返回获取这些地址。 需要在作为网关的主机上启用NAT（Network Address Translation），以便它可以使用自己的名称和地址将消息发送到LAN： iptables -t nat -A POSTROUTING -s 192.168.15.0/24 -j MASQUERADE 在postrouting链中的网络IP表中添加新规则，以伪装或替换来自源网络192.168.15.0/24的数据包。这样，任何在网络外部接收到这些数据包的人都将认为它们来自主机。 此时，ping已通 ip netns exec blue ping 192.168.1.3，但 ping 外部Internet网络8.8.8.8仍不通（LAN连接到外部Internet），因为 ns 目前可以到达 host 可以到达的任何网络，我们可以简单地说，要访问任何外部网络，请与我们的主机进行通信 ip netns exec blue ip route add default via 192.168.15.5 7. 外部网络访问内部专用网络的ns端口的2种解决方案： 给host添加IP路由条目，就像上面的过程一样 使用IP表添加一个端口转发规则，规定任何到达本地主机上端口80的流量都将被转发到分配给blue ns的IP上的端口80：iptables -t nat -A PREROUTING --dport 80 --to-destination 192.168.15.2:80 -j DNAT Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/14.Networking.html":{"url":"k8s/14.Networking.html","title":"14. Networking","keywords":"","body":"1. Docker Networking2. CNI - Container Networking Interface3. 常用命令4. Cluster Networking5. Pod Networking6. CNI in kubernetes7. CNI weave8. Service Networking9. DNS in kubernetes10. CoreDNS in Kubernetes1. Docker Networking 当您运行容器时，您有不同的网络选项可供选择： container无法到达外部，外部也无法访问container docker run --network none nginx 容器链接到host，host和容器之间没有网络隔离无需接口转发，但两个进程无法同时侦听同一端口 docker run --network host nginx 第三种网络选项是bridge，在这种情况下，会创建一个内部专用网络，Docker主机和容器将连接到该网络。 Docker在内部使用了一种类似于我们在network ns中讲的技术，即运行类型设置为bridge的IP link add 命令，ip link add docker0 type bridge。 当Docker安装在主机上时，默认情况下，会创建一个称为 bridge 的内部专用网络，可由 docker network ls 查看。但在host上由 ip link 查看，显示为 docker0。 根据ip link 查看 docker0接口状态为 DOWN，接口或网络当前已关闭。 还记得我们说过，bridge网络就像是host的接口，但它也是host内部ns或者container的交换机。根据ip addr可以查看docker0被分配的IP地址。 每当创建container时，Docker都会为其创建一个ns，运行 ip netns命令可以列出ns（需要设置）。 docker inspect ns-name可以看到与每个容器关联的ns。 docker或者说 ns 连接到 bridge 上的方式和之前说的一样。如果在docker host上运行 ip link，我们会看到接口的一端连接到本地 bridge master docker0 用 ip -n b3165c10a92b link 连接到container上，可以看到对应的接口，用 ip -n b3165c10a92b addr 查看对应IP地址 接口通常成对匹配，container偶数，bridge接口为奇数 将docker上的8080端口映射到container的80上：docker run -p 8080:80 nginx，实现原理也一样 iptables -t nat -A DOCKER --dport 80 --to-destination 172.17.0.3:80 -j DNAT，查看的命令 iptables -nvL -t nat 2. CNI - Container Networking Interface VETH : virtual Ethernet devices Network Namespaces docker 1. Create Network Namespace 1. Create Network Namespace 2. Create Bridge Network/Interface 2. Create Bridge Network/Interface 3. Create VETH Pairs (Pipe, Virtual Cable) 3. Create VETH Pairs (Pipe, Virtual Cable) 4. Attach VETH to Namespace 4. Attach VETH to Namespace 5. Attach Other VETH to Bridge 5. Attach Other VETH to Bridge 6. Assign IP Address 6. Assign IP Address 7. Bring the interfaces up 7. Bring the interfaces up 8. Enable NAT - IP Masquerade 8. Enable NAT - IP Masquerade 统一的步骤2~8步，可以用bridge命令运行，指定将容器添加到ns： bridge add 2e34dcf34 /var/run/netns/2e34dcf34 bridge add CNI (Container Networking Interface) : container runtime 容器运行时必须创建网络命名空间 标识容器必须连接到的网络 添加容器时调用网络插件（网桥）的容器运行时 删除容器时调用网络插件（网桥）的容器运行时 网络配置的JSON格式 插件方面 必须支持命令行参数ADD/DEL/CHECK 必须支持参数container id、network ns等 必须管理POD的IP地址分配 必须以特定格式返回结果 CNI已经附带了一组支持的插件，如bridge、vlan、ipvlan、macvlan、windows，以及IPAM插件，如DHCP、host-local，还有一些其他第三方组织提供的插件。 但Docker有一套自己的标准，称为CNM（Container Network Model），不适配CNI，所以无法运行 docker run --network=cni-bridge nginx，但这并不意味着Docker无法应用CNI，你可以创建一个没有任何网络配置的Docker容器 docker run --network=none nginx，然后手动调用bridge插件，k8s就是这么做的 bridge add 2e34dcf34 /var/run/netns/2e34dcf34 https://kubernetes.io/docs/setup/independent/install-kubeadm/#check-required-ports 查看所有支持的CNI插件：/opt/cni/bin 查看当前使用的CNI插件：ls /etc/cni/net.d/ 查看kubelet的container runtime：ps -aux | grep kubelet | grep --color container-runtime 3. 常用命令 ifconfig -a：显示所有接口，包括环回接口、集群使用的实际物理接口等 cat /etc/network/interfaces：显示所有物理接口，环回接口、物理接口 ip link：显示此系统上的所有物理链路，ip link show eth0 = ifconfig eth0 ip route show default：查看默认网关，或者 ip r netstat -natulp | grep scheduler：-p programs，-l listening，-t tcp 4. Cluster Networking kubernetes集群由master node和worker node组成。每个节点必须至少有一个连接到网络的接口，每个接口必须配置一个IP地址，host必须设置唯一的主机名以及唯一的mac地址。如果通过现在VM克隆来创建VM，则应特别注意这一点。还有一些端口也需要打开，这些由控制平面中的各种组件使用。 参考文档：https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#check-required-ports 因此，当您在防火墙中为节点设置网络时，或者在GCP、Azure或AWS等云环境中设置ip表规则或网络安全组时，请考虑这些问题。 5. Pod Networking 到目前为止，k8s还没有为此提供内置解决方案，它希望您实施一个网络解决方案来解决这些难题。 但是k8s已经明确列出了对pod networking的要求： 每个POD都应该有一个IP地址 每个POD都应该能够与同一节点中的其他POD通信 每个POD应该能够在没有NAT的情况下与其他节点上的每个其他POD通信 步骤： 在每个节点上创建一个bridge网络 ip link add v-net-0 type bridge 然后 ip link set dev v-net-0 up 设置bridge的IP地址 ip addr add 10.244.1.0/24 dev v-net-0 向默认网关添加IP地址 ip route add 10.244.1.0/24 via 192.168.15.5 但与其在每台服务器上配置路由，不如在路由器上配置路由。如果您的网络中有一个网关，并指定所有主机使用该网关作为默认网关，这样，您就可以轻松地管理路由器上路由表中所有网络的路由。 然后，我们编写了一个脚本，可以为每个容器运行该脚本，那么当我们在 k8s 上创建端口时，我们如何自动运行脚本呢？这就是 CNI 充当中间人的原因。CNI 告诉 k8s，这是您在创建容器后应该立即调用脚本的方式。 根据 CNI 标准，脚本应该有 ADD 和 DEL 部分。 执行步骤： kubelet 在运行时查看之前的配置 --cni-conf-dir=/etc/cni/net.d 并识别脚本名称 然后在目录 --cni-bin-dir=/etc/cni/bin 中寻找脚本 使用命令 ./net-script.sh add 执行脚本 6. CNI in kubernetes ps -aux | grep kubelet：查看设置为CNI的网络插件和一些与CNI相关的其他选项，如CNI bin目录和CNI config目录 ls /opt/cni/bin：bin目录包含所有支持的CNI插件作为可执行文件，如bridge、DHCP、flannel等 ls /etc/cni/net.d：conf文件是kubelet查找需要使用哪个插件的地方 7. CNI weave weave CNI插件部署在集群上，会在每个节点上部署一个代理或服务 一个pod可以连接到多个bridge 安装：kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')&env.IPALLOC_RANGE=10.50.0.0/16\"，可以指定IP范围以防止和host系统IP重叠 8. Service Networking Service承载在整个cluster上，整个cluster的pod都可以访问到这个节点，Service没有绑定到特定节点，但只能从集群内部访问该服务。 NodePort可以不仅让cluster内部的节点访问，它还会再cluster中所有节点的端口上公开application。 查看IPtable转发规则：iptables -L -t nat | grep db-service 或者查看日志：cat /var/log/kube-proxy.log，文件位置可能因安装而异 查看services的IP范围：cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep cluster-ip-range 查看pod的IP范围和使用的proxy类型：kubectl logs weave -n kube-system 9. DNS in kubernetes Hostname Namespace Type Root IP Address web-service apps svc cluster.local 10.107.37.188 10-244-2-5 apps pod cluster.local 10.244.2.5 curl http://10-244-2-5.apps.pod.cluster.local 10. CoreDNS in Kubernetes 建立DNS的方式： 设置每个pod上的 /etc/hosts 设置CoreDNS /etc/resolv.conf，pod名字为用短横线连接的IP 在v1.12版本之前k8s实施的DNS为kube-dns，之后为CoreDNS。 CoreDNS服务器作为POD部署在kubernetes集群的kube-system namespace中，它们被部署为两个pod以实现冗余，作为replicaSet的一部分。 查看CoreDNS的配置文件：kubectl -n kube-system describe deployments.apps coredns | grep -A2 Args | grep Corefile Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/15.资料及经验分享.html":{"url":"k8s/15.资料及经验分享.html","title":"15. 资料及经验分享","keywords":"","body":"1. 学习资料2. 经验贴3. 常用命令4. 刷题5. 考试 Tips6. 深入7. Application Failure8. Control Plane Failure9. Worker Node Failure10. Network Troubleshooting1. 学习资料 Udemy 配合 kodekloud + 官方文档 食用 2. 经验贴 LinuxFoundation官方手册：包含考试要求、报销等 CKA 认证笔记 - CKA 认证经验帖：2022年2月考试经验，真题模糊描述 CKA考试经验：报考和考纲：考试经验整理 CKA、CKAD考试经验Github：知识点 CKA考试指南和攻略：有界面截图 3. 常用命令 kubectl explain replicaset ## List the fields for supported resources kubectl api-resources ## list a complete list of supported resources kubectl run test-nslookup --image=busybox:1.28 --rm -it --restart=Never -- nslookup nginx-resolver-service ## 运行后删除pod kubectl top pods --selector=\"app=demo\" | grep -v NAME | sort -k 2 -nr ## 找到指定service下的pod中，cpu利用率按高到底排序 ## 删除 .spec.claimRef，可让pv从released状态重新变为available 4. 刷题 CKA Exercises CKA 真题 2022年8月 CKA 考试真题整理 2022.9.9更详细 5. 考试 Tips 书签栏搜索插件：Bookmark Sidebar 考试时有 Notepad 可供复制 Ctrl+X,Ctrl+E 可编辑以 \\ 分隔的多行命令 复制后 cat > static.yaml，有时会比跨 node scp static.yaml node01:/root/ 方便的多 6. 深入 Kubernetes 网络通信原理 《Kubernetes In Action》 《Kubernetes Patterns》 极客时间专栏《深入剖析 Kubernetes》 《kubernetes-best-practices》 7. Application Failure 查看Service的状态 使用应用程序或者 curl 检查是否可以在节点端口的IP上访问web服务器 curl http://web-service-ip:node-port 检查服务 kubectl describe svc web-service 的Endpoints 如果没有查询到以上Endpoint，比对一下 Selector 查看Pod的状态 kubectl describe pod web kubectl logs web，-f 全称 --follow，因为应用程序关闭就无法看到日志，只能等的应用程序再次失败，或者使用--previous查看上一个pod的日志 查看依赖Service 检查 db-service状态 检查 db pod 自身 参考文档：https://kubernetes.io/docs/tasks/debug/debug-application/debug-pods/ 8. Control Plane Failure 查看 Node 状态 kubectl get nodes 查看 Pod 状态 kubectl get pods 查看 Control Plane 组件状态 如果 controlplane 组件部署为 pod，使用 kubeadm 工具部署集群的情况下，查看controlplane pod 状态 kubectl -n kube-system get pods 如果 controlplane 组件被部署为 service，则检查 master node 上的 service 的状态：如 service kube-apiserver status，service kube-controller-manager status，service kube-scheduler status，service kubelet status，service kube-proxy status 查看 Service 日志 如果使用 kubeadm 工具部署集群，则使用kubectl -n kube-system logs kube-apiserver-master 如果服务是在主节点上本地配置的，清使用host的日志解决方案查看 service 日志，journalctl -u kube-apiserver 更多参考资料：https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster 9. Worker Node Failure 查看 Node 状态 kubectl get nodes，查看节点详细 kubectl describe node worker-1 检查节点上可能得CPU、内存和磁盘空间 top，df -h 查看 kubelet 状态 service kubelet status，sudo journalctl -u kubelet 检查 kubelet 证书，确保它们未过期，属于正确的组，并且证书由正确的 CA 颁发 openssl x509 -in /var/lib/kubelet/worker-1.crt -text 10. Network Troubleshooting 10.1 CoreDNS 如果 CoreDNS pod 处于 pending 状态，请首先检查 CNI 是否安装 如果 CoreDNS pod 处于 CrashLoopBackOff 或 Error 状态： 如果节点使用旧版本的 Docker 运行 SELinux，可能会遇到 CoreDNS pod 未启动的情况，要解决此问题，可以尝试以下选项 升级到更新版本的 Docker 禁用 SELinux 修改 CoreDNS 部署，将 allowPrivilegeEscalation 设置为 true CoreDNS 发生 CrashLoopBackOff 的另一个原因是 CoreDNS pod 检测到循环 解决方式有： 将以下内容添加到您的 kubelet 配置 yaml：resolvConf: 此标志告诉 kubelet 将备用 resolv.conf 传递给 Pod 。对于使用 systemd-resolved 的系统，/run/systemd/resolve/resolv.conf 通常是“真实” resolv.conf 的位置，尽管这可能因您的发行版而异 禁用主机节点上的本地 DNS 缓存，并将 /etc/resolv.conf 恢复为原始 一个快速的解决方法是编辑您的 Corefile，替换 forward /etc/resolv.conf 与您的上游 DNS 的 IP 地址，例如 forward 8.8.8.8。但这仅解决了 CoreDNS 的问题，kubelet 将继续将无效的 resolv.conf 转发到所有默认的 dnsPolicy Pod，使它们无法解析 DNS 如果 CoreDNS pod 和 kube-dns 服务工作正常，请检查 kube-dns 服务是否有有效的端点。如果服务没有端点，请检查服务并确保它使用正确的选择器和端口 10.2 kube-proxy kube-proxy 负责监视与每个服务关联的服务和端点。当客户端要使用虚拟 IP 连接到服务时，kube-proxy 负责将流量发送到实际的 Pod 检查 kube-system ns 中的 kube-proxy pod 正在运行 检查 kube-proxy 日志 检查 configmap 是否正确定义，运行 kube-proxy 二进制文件的配置文件是否正确 kube-config 在 config map 中定义 检查 kube-proxy 是否在容器内运行 更多参考资料： https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/ https://kubernetes.io/docs/tasks/administer-cluster/dns-debugging-resolution/ Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"k8s/16.KodeKloud Lightning Lab - 1.html":{"url":"k8s/16.KodeKloud Lightning Lab - 1.html","title":"16. KodeKloud Lightning Lab - 1","keywords":"","body":"Question 1 (15')Question 2 (15')Question 3 (8')Question 4 (12')Question 5 (20')Question 6 (10')Question 7 (20')Question 1 (15') Upgrade the current version of kubernetes from 1.23.0 to 1.24.0 exactly using the kubeadm utility. Make sure that the upgrade is carried out one node at a time starting with the controlplane node. To minimize downtime, the deployment gold-nginx should be rescheduled on an alternate node before upgrading each node. Upgrade controlplane node first and drain node node01 before upgrading it. Pods for gold-nginx should run on the controlplane node subsequently. Details Cluster Upgraded? pods 'gold-nginx' running on controlplane? Solution Here is the solution for this task. Please note that the output of these commands have not been added here. On the controlplane node: root@controlplane:~# kubectl drain controlplane --ignore-daemonsets root@controlplane:~# apt update root@controlplane:~# apt-get install kubeadm=1.24.0-00 root@controlplane:~# kubeadm upgrade plan v1.24.0 root@controlplane:~# kubeadm upgrade apply v1.24.0 root@controlplane:~# apt-get install kubelet=1.24.0-00 root@controlplane:~# systemctl daemon-reload root@controlplane:~# systemctl restart kubelet root@controlplane:~# kubectl uncordon controlplane Before draining node01, we need to remove the taint from the controlplane node. # Identify the taint first. root@controlplane:~# kubectl describe node controlplane | grep -i taint # Remove the taint with help of \"kubectl taint\" command. root@controlplane:~# kubectl taint node controlplane node-role.kubernetes.io/control-plane:NoSchedule- # Verify it, the taint has been removed successfully. root@controlplane:~# kubectl describe node controlplane | grep -i taint Now, drain the node01 as follows: - root@controlplane:~# kubectl drain node01 --ignore-daemonsets SSH to the node01 and perform the below steps as follows: root@node01:~# apt update root@node01:~# apt-get install kubeadm=1.24.0-00 root@node01:~# kubeadm upgrade node root@node01:~# apt-get install kubelet=1.24.0-00 root@node01:~# systemctl daemon-reload root@node01:~# systemctl restart kubelet To exit from the specific node, type exit or logout on the terminal. Back on the controlplane node: root@controlplane:~# kubectl uncordon node01 root@controlplane:~# kubectl get pods -o wide | grep gold (make sure this is scheduled on node) Question 2 (15') Print the names of all deployments in the admin2406 namespace in the following format: DEPLOYMENT CONTAINER_IMAGE READY_REPLICAS NAMESPACE . The data should be sorted by the increasing order of the deployment name. Example: DEPLOYMENT CONTAINER_IMAGE READY_REPLICAS NAMESPACE deploy0 nginx:alpine 1 admin2406 Write the result to the file /opt/admin2406_data. Details Task completed? Solution Run the below command to get the correct output: kubectl -n admin2406 get deployment -o custom-columns=DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.template.spec.containers[].image,READY_REPLICAS:.status.readyReplicas,NAMESPACE:.metadata.namespace --sort-by=.metadata.name > /opt/admin2406_data Question 3 (8') A kubeconfig file called admin.kubeconfig has been created in /root/CKA. There is something wrong with the configuration. Troubleshoot and fix it. Details Fix /root/CKA/admin.kubeconfig Solution Make sure the port for the kube-apiserver is correct. So for this change port from 4380 to 6443. Run the below command to know the cluster information: kubectl cluster-info --kubeconfig /root/CKA/admin.kubeconfig Question 4 (12') Create a new deployment called nginx-deploy, with image nginx:1.16 and 1 replica. Next upgrade the deployment to version 1.17 using rolling update. Details Image: nginx:1.16 Task: Upgrade the version of the deployment to 1:17 Solution Make use of the kubectl create command to create the deployment and explore the --record option while upgrading the deployment image. Run the below command to create a deployment nginx-deploy: kubectl create deployment nginx-deploy --image=nginx:1.16 Run the below command to update the new image for nginx-deploy deployment and to record the version: kubectl set image deployment/nginx-deploy nginx=nginx:1.17 --record Question 5 (20') A new deployment called alpha-mysql has been deployed in the alpha namespace. However, the pods are not running. Troubleshoot and fix the issue. The deployment should make use of the persistent volume alpha-pv to be mounted at /var/lib/mysql and should use the environment variable MYSQL_ALLOW_EMPTY_PASSWORD=1 to make use of an empty root password. Important: Do not alter the persistent volume. Details Troubleshoot and fix the issues Solution Use the command kubectl describe and try to fix the issue. Solution manifest file to create a pvc called mysql-alpha-pvc as follows: --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: mysql-alpha-pvc namespace: alpha spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: slow Question 6 (10') Take the backup of ETCD at the location /opt/etcd-backup.db on the controlplane node. Details Troubleshoot and fix the issues Solution Take a help of command etcdctl snapshot save --help options. export ETCDCTL_API=3 etcdctl snapshot save --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --endpoints=127.0.0.1:2379 /opt/etcd-backup.db Question 7 (20') Create a pod called secret-1401 in the admin1401 namespace using the busybox image. The container within the pod should be called secret-admin and should sleep for 4800 seconds. The container should mount a read-only secret volume called secret-volume at the path /etc/secret-volume. The secret being mounted has already been created for you and is called dotfile-secret. Details Pod created correctly? Solution Use the command kubectl run to create a pod definition file. Add secret volume and update container name in it. Alternatively, run the following command: kubectl run secret-1401 -n admin1401 --image=busybox --dry-run=client -o yaml --command -- sleep 4800 > admin.yaml Add the secret volume and mount path to create a pod called secret-1401 in the admin1401 namespace as follows: --- apiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: run: secret-1401 name: secret-1401 namespace: admin1401 spec: volumes: - name: secret-volume # secret volume secret: secretName: dotfile-secret containers: - command: - sleep - \"4800\" image: busybox name: secret-admin # volumes' mount path volumeMounts: - name: secret-volume readOnly: true mountPath: \"/etc/secret-volume\" Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-12 15:46:14 "},"k8s/17.KodeKloud Mock Exam - 2.html":{"url":"k8s/17.KodeKloud Mock Exam - 2.html","title":"17. KodeKloud Mock Exam - 2","keywords":"","body":"Question 1 (10')Question 2 (10')Question 3 (8')Question 4 (12')Question 5 (15')Question 6 (15')Question 7 (15')Question 8Question 1 (10') Take a backup of the etcd cluster and save it to /opt/etcd-backup.db. Details Backup Completed Solution Run the following command to take a backup: export ETCDCTL_API=3 etcdctl snapshot save --endpoints https://[127.0.0.1]:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key /opt/etcd-backup.db Question 2 (10') Create a Pod called redis-storage with image: redis:alpine with a Volume of type emptyDir that lasts for the life of the Pod. Specs on the below. Details Pod named 'redis-storage' created Pod 'redis-storage' uses Volume type of emptyDir Pod 'redis-storage' uses volumeMount with mountPath = /data/redis Solution Use the command kubectl run and create a pod definition file for redis-storage pod and add volume. Alternatively, run the command: kubectl run redis-storage --image=redis:alpine --dry-run=client -oyaml > redis-storage.yaml and add volume emptyDir in it. Solution manifest file to create a pod redis-storage as follows: --- apiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: run: redis-storage name: redis-storage spec: containers: - image: redis:alpine name: redis-storage volumeMounts: - mountPath: /data/redis name: temp-volume volumes: - name: temp-volume emptyDir: {} Question 3 (8') Create a new pod called super-user-pod with image busybox:1.28. Allow the pod to be able to set system_time. The container should sleep for 4800 seconds. Details Pod: super-user-pod Container Image: busybox:1.28 SYS_TIME capabilities for the conatiner? Solution Solution manifest file to create a pod super-user-pod as follows: --- apiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: run: super-user-pod name: super-user-pod spec: containers: - command: - sleep - \"4800\" image: busybox:1.28 name: super-user-pod securityContext: capabilities: add: [\"SYS_TIME\"] dnsPolicy: ClusterFirst restartPolicy: Always Question 4 (12') A pod definition file is created at /root/CKA/use-pv.yaml. Make use of this manifest file and mount the persistent volume called pv-1. Ensure the pod is running and the PV is bound. mountPath: /data persistentVolumeClaim Name: my-pvc Details persistentVolume Claim configured correctly pod using the correct mountPath pod using the persistent volume claim? Solution Add a persistentVolumeClaim definition to pod definition file. Solution manifest file to create a pvc my-pvc as follows: --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: my-pvc spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Mi And then, update the pod definition file as follows: apiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: run: use-pv name: use-pv spec: containers: - image: nginx name: use-pv volumeMounts: - mountPath: \"/data\" name: mypd volumes: - name: mypd persistentVolumeClaim: claimName: my-pvc Finally, create the pod by running: kubectl create -f /root/CKA/use-pv.yaml Question 5 (15') Create a new deployment called nginx-deploy, with image nginx:1.16 and 1 replica. Next upgrade the deployment to version 1.17 using rolling update. Details Deployment : nginx-deploy. Image: nginx:1.16 Image: nginx:1.16 Task: Upgrade the version of the deployment to 1:17 Task: Record the changes for the image upgrade Solution Explore the --record option while creating the deployment while working with the deployment definition file. Then make use of the kubectl apply command to create or update the deployment. To create a deployment definition file nginx-deploy: $ kubectl create deployment nginx-deploy --image=nginx:1.16 --dry-run=client -o yaml > deploy.yaml To create a resource from definition file and to record: $ kubectl apply -f deploy.yaml --record To view the history of deployment nginx-deploy: $ kubectl rollout history deployment nginx-deploy To upgrade the image to next given version: $ kubectl set image deployment/nginx-deploy nginx=nginx:1.17 --record To view the history of deployment nginx-deploy: $ kubectl rollout history deployment nginx-deploy Question 6 (15') Create a new user called john. Grant him access to the cluster. John should have permission to create, list, get, update and delete pods in the development namespace . The private key exists in the location: /root/CKA/john.key and csr at /root/CKA/john.csr. Important Note: As of kubernetes 1.19, the CertificateSigningRequest object expects a signerName. Please refer the documentation to see an example. The documentation tab is available at the top right of terminal. Details CSR: john-developer Status:Approved Role Name: developer, namespace: development, Resource: Pods Access: User 'john' has appropriate permissions Solution Solution manifest file to create a CSR as follows: --- apiVersion: certificates.k8s.io/v1 kind: CertificateSigningRequest metadata: name: john-developer spec: signerName: kubernetes.io/kube-apiserver-client request: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlJQ1ZEQ0NBVHdDQVFBd0R6RU5NQXNHQTFVRUF3d0VhbTlvYmpDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRApnZ0VQQURDQ0FRb0NnZ0VCQUt2Um1tQ0h2ZjBrTHNldlF3aWVKSzcrVVdRck04ZGtkdzkyYUJTdG1uUVNhMGFPCjV3c3cwbVZyNkNjcEJFRmVreHk5NUVydkgyTHhqQTNiSHVsTVVub2ZkUU9rbjYra1NNY2o3TzdWYlBld2k2OEIKa3JoM2prRFNuZGFvV1NPWXBKOFg1WUZ5c2ZvNUpxby82YU92czFGcEc3bm5SMG1JYWpySTlNVVFEdTVncGw4bgpjakY0TG4vQ3NEb3o3QXNadEgwcVpwc0dXYVpURTBKOWNrQmswZWhiV2tMeDJUK3pEYzlmaDVIMjZsSE4zbHM4CktiSlRuSnY3WDFsNndCeTN5WUFUSXRNclpUR28wZ2c1QS9uREZ4SXdHcXNlMTdLZDRaa1k3RDJIZ3R4UytkMEMKMTNBeHNVdzQyWVZ6ZzhkYXJzVGRMZzcxQ2NaanRxdS9YSmlyQmxVQ0F3RUFBYUFBTUEwR0NTcUdTSWIzRFFFQgpDd1VBQTRJQkFRQ1VKTnNMelBKczB2czlGTTVpUzJ0akMyaVYvdXptcmwxTGNUTStsbXpSODNsS09uL0NoMTZlClNLNHplRlFtbGF0c0hCOGZBU2ZhQnRaOUJ2UnVlMUZnbHk1b2VuTk5LaW9FMnc3TUx1a0oyODBWRWFxUjN2SSsKNzRiNnduNkhYclJsYVhaM25VMTFQVTlsT3RBSGxQeDNYVWpCVk5QaGhlUlBmR3p3TTRselZuQW5mNm96bEtxSgpvT3RORStlZ2FYWDdvc3BvZmdWZWVqc25Yd0RjZ05pSFFTbDgzSkljUCtjOVBHMDJtNyt0NmpJU3VoRllTVjZtCmlqblNucHBKZWhFUGxPMkFNcmJzU0VpaFB1N294Wm9iZDFtdWF4bWtVa0NoSzZLeGV0RjVEdWhRMi80NEMvSDIKOWk1bnpMMlRST3RndGRJZjAveUF5N05COHlOY3FPR0QKLS0tLS1FTkQgQ0VSVElGSUNBVEUgUkVRVUVTVC0tLS0tCg== usages: - digital signature - key encipherment - client auth To approve this certificate, run: kubectl certificate approve john-developer Next, create a role developer and rolebinding developer-role-binding, run the command: $ kubectl create role developer --resource=pods --verb=create,list,get,update,delete --namespace=development $ kubectl create rolebinding developer-role-binding --role=developer --user=john --namespace=development To verify the permission from kubectl utility tool: $ kubectl auth can-i update pods --as=john --namespace=development Question 7 (15') Create a nginx pod called nginx-resolver using image nginx, expose it internally with a service called nginx-resolver-service. Test that you are able to look up the service and pod names from within the cluster. Use the image: busybox:1.28 for dns lookup. Record results in /root/CKA/nginx.svc and /root/CKA/nginx.pod Details Pod: nginx-resolver created Service DNS Resolution recorded correctly Pod DNS resolution recorded correctly Solution Use the command kubectl run and create a nginx pod and busybox pod. Resolve it, nginx service and its pod name from busybox pod. To create a pod nginx-resolver and expose it internally: kubectl run nginx-resolver --image=nginx kubectl expose pod nginx-resolver --name=nginx-resolver-service --port=80 --target-port=80 --type=ClusterIP To create a pod test-nslookup. Test that you are able to look up the service and pod names from within the cluster: kubectl run test-nslookup --image=busybox:1.28 --rm -it --restart=Never -- nslookup nginx-resolver-service kubectl run test-nslookup --image=busybox:1.28 --rm -it --restart=Never -- nslookup nginx-resolver-service > /root/CKA/nginx.svc Get the IP of the nginx-resolver pod and replace the dots(.) with hyphon(-) which will be used below. kubectl get pod nginx-resolver -o wide kubectl run test-nslookup --image=busybox:1.28 --rm -it --restart=Never -- nslookup > /root/CKA/nginx.pod Question 8 Create a static pod on node01 called nginx-critical with image nginx and make sure that it is recreated/restarted automatically in case of a failure. Use /etc/kubernetes/manifests as the Static Pod path for example. Details static pod configured under /etc/kubernetes/manifests ? Pod nginx-critical-node01 is up and running Solution To create a static pod called nginx-critical by using below command: kubectl run nginx-critical --image=nginx --dry-run=client -o yaml > static.yaml Copy the contents of this file or use scp command to transfer this file from controlplane to node01 node. root@controlplane:~# scp static.yaml node01:/root/ To know the IP Address of the node01 node: root@controlplane:~# kubectl get nodes -o wide # Perform SSH root@controlplane:~# ssh node01 OR root@controlplane:~# ssh On node01 node: Check if static pod directory is present which is /etc/kubernetes/manifests, if it's not present then create it. root@node01:~# mkdir -p /etc/kubernetes/manifests Add that complete path to the staticPodPath field in the kubelet config.yaml file. root@node01:~# vi /var/lib/kubelet/config.yaml now, move/copy the static.yaml to path /etc/kubernetes/manifests/. root@node01:~# cp /root/static.yaml /etc/kubernetes/manifests/ Go back to the controlplane node and check the status of static pod: root@node01:~# exit logout root@controlplane:~# kubectl get pods Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-12 15:46:49 "},"k8s/18.KodeKloud Mock Exam - 3.html":{"url":"k8s/18.KodeKloud Mock Exam - 3.html","title":"18. KodeKloud Mock Exam - 3","keywords":"","body":"Question 1 (12')Question 2 (12')Question 3 (12')Question 4 (8')Question 5 (14')Question 6 (12')Question 7 (8')Question 8 (8')Question 9 (14')Question 1 (12') Question Create a new service account with the name pvviewer. Grant this Service account access to list all PersistentVolumes in the cluster by creating an appropriate cluster role called pvviewer-role and ClusterRoleBinding called pvviewer-role-binding. Next, create a pod called pvviewer with the image: redis and serviceAccount: pvviewer in the default namespace. Details ServiceAccount: pvviewer ClusterRole: pvviewer-role ClusterRoleBinding: pvviewer-role-binding Pod: pvviewer Pod configured to use ServiceAccount pvviewer ? Solution Pods authenticate to the API Server using ServiceAccounts. If the serviceAccount name is not specified, the default service account for the namespace is used during a pod creation. Reference: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/ Now, create a service account pvviewer: kubectl create serviceaccount pvviewer To create a clusterrole: kubectl create clusterrole pvviewer-role --resource=persistentvolumes --verb=list To create a clusterrolebinding: kubectl create clusterrolebinding pvviewer-role-binding --clusterrole=pvviewer-role --serviceaccount=default:pvviewer Solution manifest file to create a new pod called pvviewer as follows: --- apiVersion: v1 kind: Pod metadata: labels: run: pvviewer name: pvviewer spec: containers: - image: redis name: pvviewer # Add service account name serviceAccountName: pvviewer Question 2 (12') Question List the InternalIP of all nodes of the cluster. Save the result to a file /root/CKA/node_ips. Answer should be in the format: InternalIP of controlplaneInternalIP of node01 (in a single line) Solution Explore the jsonpath loop. kubectl get nodes -o jsonpath='{.items[*].status.addresses[?(@.type==\"InternalIP\")].address}' > /root/CKA/node_ips Question 3 (12') Question Create a pod called multi-pod with two containers. Container 1, name: alpha, image: nginx Container 2: name: beta, image: busybox, command: sleep 4800 Environment Variables: container 1: name: alpha Container 2: name: beta Details Pod Name: multi-pod Container 1: alpha Container 2: beta Container beta commands set correctly? Container 1 Environment Value Set Container 2 Environment Value Set Solution Solution manifest file to create a multi-container pod multi-pod as follows: --- apiVersion: v1 kind: Pod metadata: name: multi-pod spec: containers: - image: nginx name: alpha env: - name: name value: alpha - image: busybox name: beta command: [\"sleep\", \"4800\"] env: - name: name value: beta Question 4 (8') Question Create a Pod called non-root-pod , image: redis:alpine runAsUser: 1000 fsGroup: 2000 Details Pod non-root-pod fsGroup configured Pod non-root-pod runAsUser configured Solution Solution manifest file to create a pod called non-root-pod as follows: --- apiVersion: v1 kind: Pod metadata: name: non-root-pod spec: securityContext: runAsUser: 1000 fsGroup: 2000 containers: - name: non-root-pod image: redis:alpine Verify the user and group IDs by using below command: kubectl exec -it non-root-pod -- id Question 5 (14') Question We have deployed a new pod called np-test-1 and a service called np-test-service. Incoming connections to this service are not working. Troubleshoot and fix it. Create NetworkPolicy, by the name ingress-to-nptest that allows incoming connections to the service over port 80. Important: Don't delete any current objects deployed. Details Important: Don't Alter Existing Objects! NetworkPolicy: Applied to All sources (Incoming traffic from all pods)? NetWorkPolicy: Correct Port? NetWorkPolicy: Applied to correct Pod? Solution Solution manifest file to create a network policy ingress-to-nptest as follows: --- apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: ingress-to-nptest namespace: default spec: podSelector: matchLabels: run: np-test-1 policyTypes: - Ingress ingress: - ports: - protocol: TCP port: 80 Question 6 (12') Question Taint the worker node node01 to be Unschedulable. Once done, create a pod called dev-redis, image redis:alpine, to ensure workloads are not scheduled to this worker node. Finally, create a new pod called prod-redis and image: redis:alpine with toleration to be scheduled on node01. key: env_type, value: production, operator: Equal and effect: NoSchedule Details Key = env_type Value = production Effect = NoSchedule pod 'dev-redis' (no tolerations) is not scheduled on node01? Create a pod 'prod-redis' to run on node01 Solution To add taints on the node01 worker node: kubectl taint node node01 env_type=production:NoSchedule Now, deploy dev-redis pod and to ensure that workloads are not scheduled to this node01 worker node. kubectl run dev-redis --image=redis:alpine To view the node name of recently deployed pod: kubectl get pods -o wide Solution manifest file to deploy new pod called prod-redis with toleration to be scheduled on node01 worker node. --- apiVersion: v1 kind: Pod metadata: name: prod-redis spec: containers: - name: prod-redis image: redis:alpine tolerations: - effect: NoSchedule key: env_type operator: Equal value: production To view only prod-redis pod with less details: kubectl get pods -o wide | grep prod-redis Question 7 (8') Question Create a pod called hr-pod in hr namespace belonging to the production environment and frontend tier . image: redis:alpine Use appropriate labels and create all the required objects if it does not exist in the system already. Details hr-pod labeled with environment production? hr-pod labeled with tier frontend? Solution Create a namespace if it doesn't exist: kubectl create namespace hr and then create a hr-pod with given details: kubectl run hr-pod --image=redis:alpine --namespace=hr --labels=environment=production,tier=frontend Question 8 (8') Question A kubeconfig file called super.kubeconfig has been created under /root/CKA. There is something wrong with the configuration. Troubleshoot and fix it. Details Fix /root/CKA/super.kubeconfig Solution Verify host and port for kube-apiserver are correct. Open the super.kubeconfig in vi editor. Change the 9999 port to 6443 and run the below command to verify: kubectl cluster-info --kubeconfig=/root/CKA/super.kubeconfig Question 9 (14') Question We have created a new deployment called nginx-deploy. scale the deployment to 3 replicas. Has the replica's increased? Troubleshoot the issue and fix it. Details deployment has 3 replicas Solution Use the command kubectl scale to increase the replica count to 3. kubectl scale deploy nginx-deploy --replicas=3 The controller-manager is responsible for scaling up pods of a replicaset. If you inspect the control plane components in the kube-system namespace, you will see that the controller-manager is not running. kubectl get pods -n kube-system The command running inside the controller-manager pod is incorrect. After fix all the values in the file and wait for controller-manager pod to restart. Alternatively, you can run sed command to change all values at once: sed -i 's/kube-contro1ler-manager/kube-controller-manager/g' /etc/kubernetes/manifests/kube-controller-manager.yaml This will fix the issues in controller-manager yaml file. At last, inspect the deployment by using below command: kubectl get deploy Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-12 15:47:24 "},"k8s/19.CKA已通过2022.12.04.html":{"url":"k8s/19.CKA已通过2022.12.04.html","title":"19. CKA 已通过 2022.12.04","keywords":"","body":" 考试版本：1.25.2 考试价格：原价395刀（一直在涨价，Cyber Monday 单门-50%，两门-65%） 注意点： 考试选中文证书无差别，只要 Verify Name 时填对（根据汇率可能会便宜几块钱） 购买后用考试券在1年内参加，如果第一次未通过，免费的 retake 也是按购买时间算的1年内 购买后没有送模拟考试，不会像 aws 送一次模拟考试机会让你熟悉PSI考试界面 使用PSI内远程浏览器，可以多开tab，但不能导入书签，需要自己搜索，所以请熟悉完整命令（有些node上没有alias）和yaml格式 考前请仔细阅读考试手册（预约考试页面有链接），特别是熟悉考试界面（右上角有notepad），牢记复制粘贴的按键 为了防止把cluster搞挂，etcd备份与恢复和集群版本升级请在最后做 学习课程推荐：Udemy上的 Certified Kubernetes Administrator (CKA) with Practice Tests，配套有免费的KodeKloud练习平台，实时更新 备考技巧：https://www.cnblogs.com/Bota5ky/p/16747803.html Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"kafka/":{"url":"kafka/","title":"Kafka 学习笔记","keywords":"","body":"Kafka 相关学习笔记Kafka 相关学习笔记 根据 Udemy 上的课程 Apache Kafka Series - Learn Apache Kafka for Beginners v3 学习。 START HERE: Learn Apache Kafka 3.0 Ecosystem, Core Concepts, Real World Java Producers/Consumers & Big Data Architecture Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"kafka/1.介绍和简单部署.html":{"url":"kafka/1.介绍和简单部署.html","title":"1. 介绍和简单部署","keywords":"","body":"1. Why Apache Kafka2. Apache Kafka：使用场景3. 案例4. 本地伪分布式环境搭建1. Why Apache Kafka 由Linkedln创建，现在作为开源项目主要由Confluent、IBM、Cloudera维护 分布式、具有弹性体系结构，并且具有容错能力 水平可扩展性 可扩展到几百个broker 可扩展到每秒百万条信息吞吐量 高性能（低于10ms的延迟）几乎实时 超过2000家公司使用kafka，财富排行100强中有80%的公司使用kafka：airbnb、NETFLIX、Linkedin、UBER、Walmart... 2. Apache Kafka：使用场景 信息系统 活动跟踪系统 从不同位置收集指标数据 收集应用程序日志 流处理（以Kafka Streams API为例） 解耦系统依赖和微服务 集成Spark、Flink、Storm、Hadoop等大数据技术 微服务pub/sub 3. 案例 Netflix使用Apache Kafka在你看电视节目的时候实时应用推荐 Uber使用kafka实时收集用户打车和出行数据，并计算和预测需求，还实时计算你的定价 LinkedIn使用kafka来防止垃圾邮件，收集用户交互，以便实时提供更好的连接建议 4. 本地伪分布式环境搭建 4.1 下载及安装 kafka_2.11-1.0.0.tar 2.11表示scala的版本 解压：tar -xzvf kafka_2.11-1.0.0.tar 4.2 配置 cp config/server.properties etc/server-0.properties cp config/server.properties etc/server-1.properties cp config/server.properties etc/server-2.properties vi 操作更改配置文件 broker.id=0 #修改broker id #listeners=PLAINTEXT://:9092 #取消注释 log.dirs=/tmp/kafka-logs-0 #区分log listeners：指定broker启动时本机的监听名称、端口，给服务器端使用 默认名称（协议） PLAINTEXT://:9092 PLAINTEXT PLAINTEXT://192.168.1.10:9092 SSL PLAINTEXT://hostname:9092 SASL_PLAINTEXT PLAINTEXT://0.0.0.0:9092 SASL_SSL advertised.listeners：对外发布的访问IP和端口，注册到zookeeper中，给客户端（client）使用 如果 advertised.listeners 没有配置，默认采用 listeners 的配置 外部网络需要访问时，advertised.listeners 需要配置成公网IP ## 实践 listeners=INTERNAL://:9092,EXTERNAL://0.0.0.0:9093 advertised.listeners=INTERNAL://kafka-0:9092,EXTERNAL://公网IP:9093 listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT inter.broker.listener.name=INTERNAL 4.3 启动 启动zookeeper ./bin/zookeeper-server-start.sh ./etc/zookeeper.properties 不同terminal窗口启动kafka实例 ./bin/kafka-server-start.sh ./etc/server-0.properties 主题创建 ./bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic topic_name --partitions 3 --replication-factor 2 查看主题 > ./bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic topic_name Topic: topic_name Partition: 0 Leader: 1 Replicas: 1,2 Isr: 1,2 Topic: topic_name Partition: 1 Leader: 2 Replicas: 2,0 Isr: 2,0 Topic: topic_name Partition: 2 Leader: 0 Replicas: 0,1 Isr: 0,1 Replicas: 1,2表示有2个副本，在broker id: 1和broker id: 2维护，Isr表示同步正常的 创建消费者 0.10版本之后，消费者的偏移量保存在kafka主题，不再在zookeeper上保存 ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093,localhost:9094 --topic topic_name 从头消费可以加--from-beginning 创建Producer ./bin/kafka-consle-producer.sh --broker-list localhost:9092,localhost:9093,localhost:9094 --topic topic_name Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"kafka/2.基本概念.html":{"url":"kafka/2.基本概念.html","title":"2. 基本概念","keywords":"","body":"1. Kafka Topics2. Partitions and offsets3. Leader, Follower, and In-Sync Replica (ISR) List4. Producers5. send()异步发送6. 同步发送7. 批量发送8. acks9. Producers: Message keys10. Kafka 消息剖析11. Kafka 消息 key 哈希算法12. Consumers13.生产者：精确一次14. 消费者：精确一次15. 事务16. Consumer Groups17. Consumer Offsets18. 消费者交付语义19. Kafka Brokers20. Kafka 代理机制21. 主题复制因子22. 分区领导者的概念23. 生产者、消费者和领导者之间的默认行为24. afka 消费者副本获取（Kafka v2.4+）25. 生产者的确认机制 acks26. Zookeeper27. 你应该使用 Zookeeper 吗？28. 关于 Kafka KRaft29. Kafka KRaft Architecture 1. Kafka Topics Topics: 一种特殊的数据流 就像数据库中的表，但没有所有的约束 可以有任意多的 Topics 一个 Topic 由它的 name 定义 任意格式的消息格式 Topic 中的消息序列称为 data stream 你无法像数据库一样查询 Topics 2. Partitions and offsets Topics 被划分为 Partitions 每个分区中的消息会被排序 每个分区中的消息会有一个递增的 id，即 offset Kafka topics是不可变的，一旦数据写入到分区就不可修改 数据只保留有限时间（默认是一周，可配置） 即使前面的数据被删除，offset 也不会被复用 消息的顺序只在一个分区内得到保证 当数据（Record消息记录，包含key和value）被发送到kafka主题时，但key为空时，会以轮询的方式写入不同的分区，key不为空时，相同key的消息会被写入到同一个分区 3. Leader, Follower, and In-Sync Replica (ISR) List ISR 集合包含了当前可用的、与 Leader 分区保持同步的副本（Replica） ISR 集合的信息保存在每个 Broker 的日志目录中的元数据文件中，文件名为 isr-[partition-id]。该元数据文件包含了每个分区的 ISR 集合及其相关的信息，比如 Leader 副本、副本列表、最后一次同步的位置等。 如果某个副本不能正常同步数据或者落后的比较多，那么kafka会从ISR中将这个节点移除，直到它追赶上来之后再重新加入 4. Producers 生产者向主题分区写入数据 生产者事先知道写入到哪个分区，哪个kafka代理拥有它 5. send()异步发送 缓冲区会为主题的每个分区创建一个大小用来存放消息，生产者首先将消息放入到对应分区的缓冲区中，当他放入消息后立刻返回，不等消息是否发送给服务端，也不管它是否成功发送消息，后台IO线程负责将消息发送给broker。 6. 同步发送 Future result = producer.send(new ProducerRecord(\"topic_name\", \"\" + (i%5), Integer.toString(i))); try{ RecordMetadata recordMetadata = result.get(); //阻塞 } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } 7. 批量发送 linger.ms 每一批消息最大大小 batch.size 延迟时间 满足任意一项即可 8. acks acks=0 生产者不会等待服务器端的任何请求，当消息被放到缓冲区的时候，我们就认为他成功发送了，可能会造成数据丢失 acks=1 消息已经被服务器端的leader存入到本地了，leader未同步到follower就宕机会导致数据丢失 acks=all 至多一次 acks=0或1 至少一次 acks=-1或all, retries>0 9. Producers: Message keys 生产者可以发送带有key (string, number, binary, etc...) 的消息 如果key=null，数据将循环发送到各分区 如果key!=null，那么数据将一直发送到相同分区（哪个分区由生产者决定） 如果你需要根据指定字段对消息进行排序，那么就需要发送key 10. Kafka 消息剖析 key、value（可以为空） 压缩格式：none，gzip，snappy，lz4，zstd Headers：可选的键值对列表 消息要发送到的分区及其偏移量 时间戳（由系统或者用户设置） 11. Kafka 消息 key 哈希算法 targetPartition = Math.abs(Utils.murmur2(keyBytes))%(numPartitions-1) 12. Consumers 消费者根据 name 从某个 topic 读取数据，是 pull model，不是kafka server把数据推送给消费者 消费者自动知道从哪个broker读取数据 如果broker失效了，消费者知道如何恢复 在每个分区中，数据根据 offset 从低到高被读取 13.生产者：精确一次 enable.idempotence=true ##retries=Integer.MAX_VALUE acts=all 14. 消费者：精确一次 通过offset来防止重复消费不是一个好的办法 通常在消息中加入唯一ID (例如流水ID，订单D)，在处理业务时，通过判断 ID来防止重复处理 15. 事务 在kafka中，消息会尽可能地发送到服务端，如果提交成功了，消息后面会有成功提交的标志，如果未成功提交，那么它的状态是未提交的。 Isolation_level 隔离级别，默认为 read_uncommitted 脏读，如果只读取成功提交的数据，可以设置为 read_committed 16. Consumer Groups 在一个应用中的所有消费者作为消费者组读取数据 组内的每个消费者从独立的分区读取 如果消费者多于分区，那么一些消费者会处于非活动状态（作为备用的消费者） 分区是最小的并行单位 一个消费者可以消费多个分区 一个分区可以被多个消费者组里的消费者消费 但是，一个分区不能同时被同一个消费者组里的多个消费者消费 16.1 发布 - 订阅模式 每条消息需要被每个消费者都进行消费：每个消费者都属于不同的消费者组 16.2 点对点（一对一） 一条消息只要有被消费就可以：所有消费者都属于同一个消费者组 17. Consumer Offsets kafka 保存消费者组的 offsets 提交的 offsets 在 kafka topic 中被称为 __consumer_offsets 当组内的一个消费者处理完从 kafka 收到的数据后，它会阶段性地提交 offsets （kafka 代理会写入到__consumer_offsets，而不是消费者组自身） 如果一个消费者崩溃，重启后能根据提交的消费者偏移量重新开始读取数据 18. 消费者交付语义 Java 消费者默认会自动提交偏移量（至少一次） 手动提交有3种语义 至少一次（推荐） 消息被处理后提交偏移量 如果处理失败，消息会再被读取 这意味着，我们可以对消息进行重复处理，因此，我们需要确保我们的处理是幂等的（指再次处理不会影响我们的系统） 最多一次 消息收到就提交偏移量 如果处理失败，消息就会丢失（当然也不会再次被读取） 正好一次 对于 kafka => kafka workflows：使用 Transactional API 对于 kafka => 外部系统 workflows：使用幂等消费者 19. Kafka Brokers 一个kafka集群由多个 brokers（servers）组成 每个代理由ID（整数）标识 每个代理只包含特定的主题分区 连接到任何kafka代理（也称为引导代理后），客户端、生产者或使用者将连接到整个kafka集群 最好是从3个代理开始，但在有些大型集群中会有超过100个代理 代理的编号可以选择从任意数开始 20. Kafka 代理机制 每个 kafka 代理也被称为“引导服务器” 每个代理知道所有的代理、主题和分区（元数据） 21. 主题复制因子 主题应有一个复制因子>1（通常在2与3之间） 因此，万一有一个代理挂了，其他代理仍可以提供服务 22. 分区领导者的概念 在任何时刻，一个分区只会有一个代理作为领导者 生产者只会把数据发送给作为分区领导者的代理 其他的代理会从分区领导者复制数据 因此，每个分区拥有一个领导者和多个ISR（in-sync replica 同步副本） 23. 生产者、消费者和领导者之间的默认行为 kafka 生产者只会向分区的领导者代理写入数据 kafka 消费者默认会从分区的领导者读取数据 24. afka 消费者副本获取（Kafka v2.4+） 自从 Kafka 2.4，可以配置让消费者从最近的副本进行读取，这可以降低延迟，如果是在云上，则可以降低网络成本 25. 生产者的确认机制 acks 生产者可以选择是否接受写入数据的确认消息： acks=0：生产者不会等待确认，如果代理崩溃，可能会导致数据丢失 acks=1：生产者会等待领导者的确认，可能会导致有限的数据丢失 acks=all：要求领导者和所有副本的确认，不会有数据丢失 26. Zookeeper Zookeeper管理代理，保留一份代理的名单 Zookeeper帮助完成分区的领导者选举 当kafka有更改时，Zookeeper会发送通知，比如新的主题、代理崩溃、代理启动、删除主题等等 Kafka 2.x 版本运行必需要有 Zookeeper Kafka 3.x 可以使用 Raft (KIP-500) 作为代替 Kafka 4.x 没有 Zookeeper Zookeeper 以单数个数运行，1、3、5、7...通常不会超过7个 Zookeeper 拥有一个领导者作为写入，其他的作为追随者进行读取 v0.10 版本之后，Zookeeper不再存储消费者的偏移量 27. 你应该使用 Zookeeper 吗？ 和 Kafka 代理？ 是的，除非4.0版本发布并可用于生产环境 和 Kafka 客户端？ 随着时间的推移，Kafka客户端和CLI已经被迁移，以利用代理作为唯一的连接端点，而不是Zookeeper 自从 0.10 版本之后，消费者将偏移量储存在 Kafka 中，不再连接到 Zookeeper 从 2.2 版本之后，CLI命令 kafka-topics.sh 用 Kafka 代理而不是 Zookeeper来进行主题管理，Zookeeper CLI命令已被废弃 所有使用 Zookeeper 的API和命令会被迁移，这样新版本的集群可以不再绑定 Zookeeper，这些操作对于客户端是不可见的 Zookeeper 的安全性比 Kafka 低，这意味着如果你应该用 Zookeeper 只接受来自代理的连接，拒绝客户端的连接 28. 关于 Kafka KRaft 在2020年，Apache Kafka项目做开始着手移除 Zookeeper 依赖（KIP-500） 当Kafka集群拥有超过10万个分区时，Zookeeper 有扩展问题 删除 Zookeeper 之后，Apache Kafka 可以 扩展到百万级分区，变得更容易维护和设置 提升稳定性，更易监控、支持和管理 为整个系统提供单一的安全模型 启动 Kafka 也会容易很多 更快的关闭和恢复时间 Kafka 3.x 实现了 Raft 协议，以替代 Zookeeper（Not production ready） 29. Kafka KRaft Architecture Kafka Raft Readme Kafka performance improvement Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-14 16:09:43 "},"kafka/3.Kafka Topics & CLI.html":{"url":"kafka/3.Kafka Topics & CLI.html","title":"3. Kafka Topics & CLI","keywords":"","body":"1. Kafka CLI: kafka-topics.sh2. Kafka CLI: kafka-console-producer.sh3. Kafka CLI: kafka-console-consumer.sh4. CLI Consumer in Groups with kafka-console-consumer.sh5. Consumer Group Management CLI kafka-consumer-groups.sh6. Consumer Groups -Reset Offsets kafka-consumer-groups.sh1. Kafka CLI: kafka-topics.sh # Replace \"kafka-topics.sh\" # by \"kafka-topics\" or \"kafka-topics.bat\" based on your system # (or bin/kafka-topics.sh or bin\\windows\\kafka-topics.bat if you didn't setup PATH / Environment variables) kafka-topics.sh kafka-topics.sh --bootstrap-server localhost:9092 --list kafka-topics.sh --bootstrap-server localhost:9092 --topic first_topic --create kafka-topics.sh --bootstrap-server localhost:9092 --topic first_topic --create --partitions 3 kafka-topics.sh --bootstrap-server localhost:9092 --topic first_topic --create --partitions 3 --replication-factor 2 # Create a topic (working) kafka-topics.sh --bootstrap-server localhost:9092 --topic first_topic --create --partitions 3 --replication-factor 1 # List topics kafka-topics.sh --bootstrap-server localhost:9092 --list # Describe a topic kafka-topics.sh --bootstrap-server localhost:9092 --topic first_topic --describe # Delete a topic kafka-topics.sh --bootstrap-server localhost:9092 --topic first_topic --delete # (only works if delete.topic.enable=true) 2. Kafka CLI: kafka-console-producer.sh # Replace \"kafka-console-producer.sh\" # by \"kafka-console-producer\" or \"kafka-console-producer.bat\" based on your system # (or bin/kafka-console-producer.sh or bin\\windows\\kafka-console-producer.bat if you didn't setup PATH / Environment variables) kafka-console-producer.sh # producing kafka-console-producer.sh --bootstrap-server localhost:9092 --topic first_topic > Hello World >My name is Conduktor >I love Kafka >^C ( some message that is acked > just for fun > fun learning! # producing to a non existing topic # 会自动帮你创建一个新的主题，默认partition=1 kafka-console-producer.sh --bootstrap-server localhost:9092 --topic new_topic > hello world! # our new topic only has 1 partition kafka-topics.sh --bootstrap-server localhost:9092 --list kafka-topics.sh --bootstrap-server localhost:9092 --topic new_topic --describe # edit config/server.properties or config/kraft/server.properties # num.partitions=3 # produce against a non existing topic again kafka-console-producer.sh --bootstrap-server localhost:9092 --topic new_topic_2 hello again! # this time our topic has 3 partitions kafka-topics.sh --bootstrap-server localhost:9092 --list kafka-topics.sh --bootstrap-server localhost:9092 --topic new_topic_2 --describe # overall, please create topics before producing to them! # produce with keys kafka-console-producer --bootstrap-server localhost:9092 --topic first_topic --property parse.key=true --property key.separator=: >example key:example value >name:Stephane 3. Kafka CLI: kafka-console-consumer.sh # Replace \"kafka-console-consumer.sh\" # by \"kafka-console-consumer\" or \"kafka-console-consumer.bat\" based on your system # (or bin/kafka-console-consumer.sh or bin\\windows\\kafka-console-consumer.bat if you didn't setup PATH / Environment variables) kafka-console-consumer.sh # consuming kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first_topic # other terminal kafka-console-producer.sh --bootstrap-server localhost:9092 --topic first_topic # consuming from beginning # 默认不是从头开始读，是因为消息可能很多，比如累积了一周的消息 kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first_topic --from-beginning # display key, values and timestamp in consumer kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --formatter kafka.tools.DefaultMessageFormatter --property print.timestamp=true --property print.key=true --property print.value=true --from-beginning 4. CLI Consumer in Groups with kafka-console-consumer.sh # Replace \"kafka-console-consumer.sh\" # by \"kafka-console-consumer\" or \"kafka-console-consumer.bat\" based on your system # (or bin/kafka-console-consumer.sh or bin\\windows\\kafka-console-consumer.bat if you didn't setup PATH / Environment variables) # start one consumer kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first_topic --group my-first-application # start one producer and start producing kafka-console-producer.sh --bootstrap-server localhost:9092 --topic first_topic # start another consumer part of the same group. See messages being spread kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first_topic --group my-first-application # start another consumer part of a different group from beginning kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first_topic --group my-second-application --from-beginning 5. Consumer Group Management CLI kafka-consumer-groups.sh # Replace \"kafka-consumer-groups.sh\" # by \"kafka-consumer-groups\" or \"kafka-consumer-groups.bat\" based on your system # (or bin/kafka-consumer-groups.sh or bin\\windows\\kafka-consumer-groups.bat if you didn't setup PATH / Environment variables) # documentation for the command kafka-consumer-groups.sh # list consumer groups kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list # describe one specific group kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-second-application # describe another group kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-first-application # start a consumer # 启动consumer时，若不指定group，则会创建一个临时的group，在consumer关闭后删除，并且不会提交offset kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first_topic --group my-first-application # describe the group now kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-first-application # describe a console consumer group (change the end number) kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group console-consumer-10592 # start a console consumer kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first_topic --group my-first-application # describe the group again kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-first-application 6. Consumer Groups -Reset Offsets kafka-consumer-groups.sh # Replace \"kafka-consumer-groups\" # by \"kafka-consumer-groups.sh\" or \"kafka-consumer-groups.bat\" based on your system # (or bin/kafka-consumer-groups.sh or bin\\windows\\kafka-consumer-groups.bat if you didn't setup PATH / Environment variables) # look at the documentation again kafka-consumer-groups # reset the offsets to the beginning of each partition # 停止运行consumer才可以reset kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-first-application --reset-offsets --to-earliest # execute flag is needed kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-first-application --reset-offsets --to-earliest --execute # topic flag is also needed kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-first-application --reset-offsets --to-earliest --execute --topic first_topic # consume from where the offsets have been reset kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first_topic --group my-first-application # describe the group again kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-first-application # documentation for more options kafka-consumer-groups.sh # shift offsets by 2 (forward) as another strategy kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-first-application --reset-offsets --shift-by 2 --execute --topic first_topic # shift offsets by 2 (backward) as another strategy kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-first-application --reset-offsets --shift-by -2 --execute --topic first_topic # consume again kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first_topic --group my-first-application Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"kafka/4.Java Integration.html":{"url":"kafka/4.Java Integration.html","title":"4. Java Integration","keywords":"","body":"1. Java Producer2. Java Producer Callbacks3. Java Consumer4. Kafka Consumer - Graceful shutdown5. 自动提交-至多一次6. 手动提交-至少一次7. 手动指定消费分区和消费位置1. Java Producer public class ProducerDemo { private static final Logger log = LoggerFactory.getLogger(ProducerDemo.class.getSimpleName()); public static void main(String[] args) { log.info(\"I am a Kafka Producer\"); // create Producer Properties Properties properties = new Properties(); properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"127.0.0.1:9092\"); properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); // create the Producer KafkaProducer producer = new KafkaProducer<>(properties); // create a producer record ProducerRecord producerRecord = new ProducerRecord<>(\"demo_java\", \"hello world\"); // send the data - asynchronous producer.send(producerRecord); // flush data - synchronous producer.flush(); // flush and close producer producer.close(); } } 2. Java Producer Callbacks producer.send(producerRecord, new Callback() { @Override public void onCompletion(RecordMetadata metadata, Exception e) { // executes every time a record is successfully sent or an exception is thrown if (e == null){ // the record was successfully sent log.info(\"Received new metadata. \\n\" + \"Topic: \" + metadata.topic() + \"\\n\" + \"Partition: \" + metadata.partition() + \"\\n\" + \"Offset: \" + metadata.offset() + \"\\n\" + \"Timestamp: \" + metadata.timestamp()); } else { log.error(\"Error while producing\", e); } } }); 粘性分区：如果发送速度足够快，几条消息可能作为同一批发送到同一分区 partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner DefaultPartitioner 初始化时默认采用 StickyPartitionCache 3. Java Consumer String boostrapServers = \"127.0.0.1:9092\"; String groupId = \"my-second-application\"; String topic = \"demo_java\"; // create consumer configs Properties properties = new Properties(); properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, boostrapServers); properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId); properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\"); // create consumer KafkaConsumer consumer = new KafkaConsumer<>(properties); // subscribe consumer to our topic(s) consumer.subscribe(Arrays.asList(topic)); // poll for new data while(true) { log.info(\"Polling\"); ConsumerRecords records = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord record : records) { log.info(\"Key: \" + record.key() + \", Value: \" + record.value()); log.info(\"Partition: \" + record.partition() + \", Offset: \" + record.offset()); } } 4. Kafka Consumer - Graceful shutdown // create consumer KafkaConsumer consumer = new KafkaConsumer<>(properties); // get a reference to the current thread final Thread mainThread = Thread.currentThread(); // adding the shutdown hook Runtime.getRuntime().addShutdownHook(new Thread() { public void run() { log.info(\"Detected a shutdown, let's exit by calling consumer.wakeup()...\"); consumer.wakeup(); // 会让下面的poll() throw exception // join the main thread to allow the execution of the code in the main thread try { mainThread.join(); } catch (InterruptedException e) { e.printStackTrace(); } } }); try { // subscribe consumer to our topic(s) consumer.subscribe(Arrays.asList(topic)); // poll for new data while(true) { ConsumerRecords records = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord record : records) { log.info(\"Key: \" + record.key() + \", Value: \" + record.value()); log.info(\"Partition: \" + record.partition() + \", Offset: \" + record.offset()); } } } catch (WakeupException e) { log.info(\"Wake up exception!\"); // we ignore this as this is an expected exception when closing a consumer } catch (Exception e){ log.error(\"Unexpected exception\"); } finally { consumer.close(); // this will also commit the offsets if need be log.info(\"The consumer is now gracefully closed\"); } 5. 自动提交-至多一次 props.put(\"enable.auto.commit\", \"true\"); props.put(\"auto.commit.interval.ms\", \"1000\"); consumer.poll(100); 6. 手动提交-至少一次 props.put(\"enable.auto.commit\", \"false\"); consumer.commitSync(); 7. 手动指定消费分区和消费位置 指定消费分区 String topic =\"foo\"; TopicPartition partition0 = new TopicPartition(topic, 0); TopicPartition partition1 =new TopicPartition(topic,1); consumer.assign(Arrays.asList(partition0,partition1)); 指定消费位置 seek(TopicPartition, long) Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"redis/":{"url":"redis/","title":"Redis 学习笔记","keywords":"","body":"Redis 相关学习笔记Redis 相关学习笔记 根据 Udemy 上的课程 Redis: The Complete Developer's Guide 学习。 Master Redis v7.0 with hands-on exercises. Includes Modules, Scripting, Concurrency, and Streams! Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"redis/1.基础命令.html":{"url":"redis/1.基础命令.html","title":"1. 基础命令","keywords":"","body":"1. 设置远程 redis demo2. 在macOs上查看Redis配置文件3. Redis 使用单线程的原因主要有以下几点：4. String5.List6.Hash7.Set8.Sorted Set9.Bitmap10.Hyperloglog11.JSON12.Index13. 如何降低内存穿透风险？14. geospatial 地理位置15. Hyperloglog16. Bitmap1. 设置远程 redis demo demo工具网站：https://app.redislabs.com 远程登录 redis-cli -u redis://:@redis-16985.c14.us-east-1-2.ec2.cloud.redislabs.com:16985 性能测试：redis-benchmark 2. 在macOs上查看Redis配置文件 cat /usr/local/etc/redis.conf 默认16个数据库，可以使用SELECT 切换数据库 DBSIZE # 查看数据库当前使用的大小 KEYS * # 查看所有的key FLUSHDB # 清空当前库 FLUSHALL # 清空全部库 MOVE # 移动到指定数据库 EXPIRE TTL # 查看剩余时间 -1表示不会过期 -2表示已过期 TYPE # 查看key类型 3. Redis 使用单线程的原因主要有以下几点： 减少锁竞争：Redis 的核心操作是基于内存的，使用单线程可以避免多线程环境下的锁竞争问题，提高性能。由于单线程模型避免了线程切换和上下文切换的开销，可以更高效地利用 CPU。 避免复杂性：多线程编程涉及到线程同步、数据一致性等复杂问题。使用单线程可以避免这些复杂性，使代码更加简单、可靠，减少潜在的错误。 避免资源竞争：Redis 的主要瓶颈是 CPU 和内存带宽，而不是计算能力。使用单线程可以充分利用 CPU 的计算能力，避免了多线程之间因为资源竞争而导致的性能下降。 高效的网络模型：Redis 使用非阻塞的 I/O 多路复用模型，单线程可以处理大量的并发连接。这种模型在处理高并发读写请求时非常高效，避免了线程间切换的开销。 需要注意的是，尽管 Redis 主线程是单线程的，但它通过使用异步 I/O 和多路复用技术实现了非阻塞的网络通信和高并发处理能力。此外，Redis 也提供了一些并发操作的指令，如使用多个 Redis 实例进行数据分片来提高整体性能。 4. String Store plain string or number SET GET APPEND # 如果不存在，相当于SET EXISTS INCR DECR INCRBY DECRBY GETRANGE # 包含start和end，end为-1在倒数第1的位置 SETRANGE # 从offset开始替换成value，替换的范围为value的长度 SETEX # 设置key-value和过期时间，不存在则创建 SETNX # 成功返回1，否则0（在分布式锁中常常会使用） MSET MGET MSETNX # 有一个存在则全部失败，原子性操作 GETSET # 先get再set，不存在返回nil，同样会设置新值 5.List List of strings，实际上是个链表 LLEN LINSERT LPUSH # 不存在则创建 RPUSH # 在尾部添加值 LPOP RPOP LINDEX # 找到第index个key的位置，从0开始，末尾从-1开始，越界报错 LRANGE LREM # 最多移除count个数的value，精确匹配 LTRIM # 截取list部分元素 RPOPLPUSH LSET # 没有key或者超出原有key的index范围都报错 LINSERT BEFORE|AFTER 6.Hash Collection of key-value pairs HGET HSET [field value ...] HMGET HGETALL HMSET HDEL HLEN HEXISTS HKEYS HVALS 7.Set Set of strings (each string is unique) SADD SREM SCARD # 获取元素总个数 cardinality 基数 SDIFF [key ...] # 差集 SINTER [key ...] # 交集 SUNION [key ...] # 合集 SISMEMBER SMEMBERS # 显示所有元素 SPOP # 随机移除元素 SRANDMEMBER # 随机count个数的获取元素 SMOVE 8.Sorted Set Set of strings in a particular order ZADD key [NX | XX] [GT | LT] [CH] [INCR] score member [score member...] ZDIFF ZCOUNT ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] # -inf +inf ZREVRANGEBYSCORE 逆序 9.Bitmap Kind of like a collection of booleans BITOP BITCOUNT BITPOS 10.Hyperloglog Kind of like a collection of booleans PFADD PFCOUNT PFMERGE 11.JSON Nested JSON structure JSON.SET JSON.GET JSON.DEL 12.Index Internal data used for searching FT.SEARCH FT.CREATE FT.PROFILE Documentation for commands: https://redis.io/commands 13. 如何降低内存穿透风险？ 布隆过滤器（英語：Bloom Filter）是1970年由布隆提出的。 它实际上是一个很长的二进制向量和一系列随机映射函数。 布隆过滤器可以用于检索一个元素是否在一个集合中。 它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。 14. geospatial 地理位置 底层由Zset实现 GEOADD key [NX | XX] [CH] longitude latitude member [longitude latitude member ...] 地球两极无法直接添加 经度纬度 GEODIST # 单位m，km，mi，ft GEOHASH GEOPOS GEORADIUS # 可以限制数量 GEORADIUSBYMEMBER 15. Hyperloglog 基数，不重复的元素个数，可以接受误差 PFADD key [element [element ...]] PFMERGE PFCOUNT 16. Bitmap 位存储 SETBIT key offset value # 最大32位 BITCOUNT # 统计1的位数个数 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"redis/2.事务及Java集成.html":{"url":"redis/2.事务及Java集成.html","title":"2. 事务及 Java 集成","keywords":"","body":"1. 什么是Redis事务2. Redis事务相关命令和使用3. 如何理解Redis与事务的ACID？4. CAS操作实现乐观锁5. Redis事务执行步骤6. Jedis7. SpringBoot8. Redis.conf 详解1. 什么是Redis事务 Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。 总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。 2. Redis事务相关命令和使用 MULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。 EXEC：执行事务中的所有操作命令。 DISCARD：取消事务，放弃执行事务块中的所有命令。 WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。 UNWATCH：取消WATCH对所有key的监视。 3. 如何理解Redis与事务的ACID？ 原子性atomicity Redis事务在编译错误时回滚，运行时错误跳过。很多文章由此说Redis事务违背原子性的；而官方文档认为是遵从原子性的。 Redis官方文档给的理解是，Redis的事务是原子性的：所有的命令，要么全部执行，要么全部不执行。而不是完全成功。 一致性consistency redis事务可以保证命令失败的情况下得以回滚，数据能恢复到没有执行之前的样子，是保证一致性的，除非redis进程意外终结。 隔离性Isolation redis事务是严格遵守隔离性的，原因是redis是单进程单线程模式(v6.0之前），可以保证命令执行过程中不会被其他客户端命令打断。 但是，Redis不像其它结构化数据库有隔离级别这种设计。 持久性Durability redis事务是不保证持久性的，这是因为redis持久化策略中不管是RDB还是AOF都是异步执行的，不保证持久性是出于对性能的考虑。 4. CAS操作实现乐观锁 check-and-set (CAS)：被 WATCH 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回nil-reply来表示事务已经失败。 WATCH mykey val = GET mykey val = val + 1 MULTI SET mykey $val EXEC 5. Redis事务执行步骤 通过上文命令执行，很显然Redis事务执行是三个阶段： 开启：以MULTI开始一个事务 入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面 执行：由EXEC命令触发事务 当一个客户端切换到事务状态之后， 服务器会根据这个客户端发来的不同命令执行不同的操作： 如果客户端发送的命令为 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令的其中一个， 那么服务器立即执行这个命令。 与此相反， 如果客户端发送的命令是 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令以外的其他命令， 那么服务器并不立即执行这个命令， 而是将这个命令放入一个事务队列里面， 然后向客户端返回 QUEUED 回复。 6. Jedis Jedis是Redis官方提供的Java客户端，用于在 Java 应用程序中连接、操作 Redis，它提供了与 Redis 通信的 API，简化了 Java 开发者与 Redis 的交互流程。 Jedis Github Readme：https://github.com/redis/jedis#getting-started 7. SpringBoot 在 SpringBoot2.x 之后，原来使用的 jedis 被替换成了 lettcuce，原因： Jedis：采用直连，多个线程操作不安全，需要使用 Jedis pool 来避免，会有线程阻塞的情况（BIO模式） Lettuce：采用 netty，实例可以在多个线程共享，不存在线程不安全的情况，可以减少线程数量（NIO模式） Lettuce Doc：https://lettuce.io/core/release/reference/#_for_gradle_users 8. Redis.conf 详解 查找 redis.conf 位置 redis-cli config get dir find / -name redis.conf Linux系统可以 systemctl status redis-server unit 单位对大小写不敏感 bind 127.0.0.1 绑定IP protected-mode yes 保护模式，docker启动需要关闭 port 6379 端口设置 daemonize yes 以守护进程的方式运行 pidfile /var/run/redis_6379.pid 如果以后台方式运行，需要指定pid进程文件 loglevel notice logfile \"\" 日志的文件位置名 database 16 默认的数据库数量 always-show-logo yes 是否总是显示logo 快照：持久化，在规定的时间内，执行了多少次操作，则会持久化到文件.rdb,.aof redis是内存数据库，如果没有持久化，那么断电即丢失！ save 900 1 #如果900秒，如果至少有一个key进行了修改，我们即进行持久化操作 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes 如果持久化出错，是否还需要继续工作 rdbcompression yes 是否压缩rdb持久化文件，需要消耗cpu资源 rdbchecksum yes 保存时是否校验rdb文件 dir ./ 持久化rdb文件保存的目录 config get requirepass # 获取requirepass项配置 config set requirepass \"123456\" # 设置requirepass项配置 auth 123456 # 登录才能查看及修改以上配置内容 maxclients 10000 默认可连接的最大客户端数目 maxmemory redis配置最大内存 LRU least recently used LFU least frequently used maxmemory-policy noeviction 内存到达上限之后的处理策略： volatile-lru：只对设置了过期时间的key进行LRU算法进行删除 allkeys-lru：对所有key执行LRU算法进行删除 volatile-lfu：只对设置了过期时间的key进行LFU算法进行删除 allkeys-lfu：对所有key执行LFU算法进行删除 volatile-random：随机删除设置有过期时间的key allkeys-random：随机删除 volatile-ttl：删除即将过期的 noeviction：永不过期，返回错误 appendonly no 默认不开启aof模式，默认是使用rdb方式持久化的，大部分情况下，rdb完全够用 appendfilename \"appendonly.aof\" 持久化的文件名字 appendfsync everysec 每秒执行一次同步，always 每次修改都写入，速度较慢，no 让操作系统决定同步，速度最快 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"redis/3.RDB&AOF持久化.html":{"url":"redis/3.RDB&AOF持久化.html","title":"3. RDB & AOF 持久化","keywords":"","body":"1. RDB (Redis DataBase)2. AOF (Append Only File)3. 扩展1. RDB (Redis DataBase) 在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里。 Redis会单独创建（fork）一个进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的。这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能法失。我们默认的就是RDB，一般情况下不需要修改这个配置！ rdb保存的文件是dump.rdb（在conf中dbfilename修改文件名） 在主从复制中，rdb就是备用，在从机上面。 1.1 触发生成rdb文件的机制： save的规则满足 执行FLUSHALL 退出redis 1.2 如何恢复rdb文件 ？ 只需要将rdb文件放在我们redis启动目录就可以，redis启动的时候会自动检查dump.rdb 恢复其中的数据！ 查看需要存在的位置 > config get dir 1)\"dir\" 2)\"/usr/1ocal/bin\" # 如果在这个目录下存在 dump.rdb 文件，启动就会自动恢复其中的数据 1.3 优点 1). 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。 2). 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。 3). 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。 4). 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。 1.4 缺点 1). 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。 2). 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。 2. AOF (Append Only File) 以日志的形式来记录每个写操作，将Redis执行过的所有指令记录下来（读操作不记录），只许加文件但不可以改与文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 aof保存的是appendonly.aof文件，默认不开启。 同时开启 redis-check-aof --fix # 修复aof文件 重写机制： no-appendfsync-on-rewrite no # 由操作系统决定重写时机 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb 2.1 优点 1). 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。 2). 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。 3). 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 4). AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。 2.2 缺点 1). 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 2). 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。 二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent 的意思了。 3. 扩展 RDB 持久化方式能够在指定的时间间隔内对你的数据进行快照存储 AOF 持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以Redis 协议追加保存每次写的操作到文件末尾，Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大 只做缓存，如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化 同时开启两种持久化方式 在这种情况下，当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整 RDB 的数据不实时，同时使用两者时服务器重启也只会找AOF文件，那要不要只使用AOF呢？作者建议不要，因为RDB更适合用于备份数据库（AOF在不断变化不好备份），快速重启，而且不会有AOF可能潜在的Bug，留着作为一个万一的手段 性能建议 因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留 save 900 1这条规则。 如果Enable AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了，代价一是带来了持续的I0，二是AOF rewrite 的最后将 rewrite 过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite 的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上，默认超过原大小100%大小重写可以改到适当的数值。 如果不Enable AOF，仅靠 Master-Slave Repllcation 实现高可用性也可以，能省掉一大第10，也减少了rewrite时带来的系统波动。代价是如果Master/Slave 同时断电，会丢失十几分钟的数据，启动脚本也要比较两个 Master/Slave 中的 RDB文件，载入较新的那个，微博就是这种架构。 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"redis/4.订阅发布及主从复制.html":{"url":"redis/4.订阅发布及主从复制.html","title":"4. 订阅发布及主从复制","keywords":"","body":"1. Commands2. 原理3. 主从复制的作用4. 配置5. 复制原理6. 哨兵模式7. 通过Redis实现一把安全可靠的分布式锁8. 缓存一致性协议1. Commands SUBSCRIBE channel [channel ...] PUBLISH channel message UNSUBSCRIBE [channel [channel ...]] PSUBSCRIBE pattern [pattern ...] 正则订阅 PUBSUB subcommand [argument [argument ...]] 查看订阅与发布系统状态 PUNSUBSCRIBE [pattern [pattern ...]] 退订所有给定模式的频道 2. 原理 Redis 是使用 C 实现的，通过分析 Redis 源码里的pubsub.c文件，了解发布和订阅机制的底层实现，籍此加深对 Redis 的理解。 Redis 通过 PUBLISH、SUBSCRIBE 和 PSUBSCRIBE 等命令实现发布和订阅功能。 通过 SUBSCRIBE 命令订阅某频道后，redis-server 里维护了一个字典，字典的键就是一个个channel，而字典的值则是一个链表，链表中保存了所有订阅这个 channel 的客户端。SUBSCRIBE 命令的关键，就是将客户端添加到给定 channel 的订阅链表中。 通过 PUBLISH 命令向订阅者发送消息，redis-server 会使用给定的频道作为键，在它所维护的 channel 字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。 Pub/Sub 从字面上理解就是发布（Publish）与订阅（Subscribe），在Redis中，你可以设定对某一个kev值进行消息发布及消息阅，当一个key值上进行了消息发布后，所有订阅它的客户端都会收到相应的消息。这一功能最明显的用法就是用作实时消息系统，比如普通的即时聊天，群聊等功能。 3. 主从复制的作用 数据冗余 故障恢复 负载均衡 高可用 原因： 单点故障 单台服务器内存有限，一般来说，单台最大不应该超过20G 4. 配置 master服务器不用特殊配置 info replication # 查看集群主从信息 需要配置的项： port 6379 daemonize yes # 打开后台运行 pidfile /var/run/reds_6379.pid logfile \"6379.log\" dbfilename dump6379.rdb 从机配置 从机ReadOnly无法写入，链式主从复制，中间的节点依旧属于Slave。 SLAVEOF host port # 使用命令进行配置 SLAVEOF no one # 从slave更新为master节点 replicaof # 使用配置项进行永久配置 5. 复制原理 slave启动成功连接到 master 后会发送一个sync同步命令 master 接到命令，启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave，并完成一次完全同步。 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。 增量复制:：master 继续将新的所有收集到的修改命令依次传给slave，完成同步但是只要是重新连接master，一次完全同步（全量复制）将被自动执行。 6. 哨兵模式 哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令等待Redis服务器响应从而监控运行的多个Redis实例。 多哨兵模式： 假设主服务器宕机，哨兵1先检测到这个结巢，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover[故障转移]操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线。 conf配置： sentinel monitor # 告诉Sentinel监听指定主节点，并且只有在至少哨兵达成一致的情况下才会判断它 O_DOWN 状态 redis-sentinel kconfig/sentinel.conf # 启动sentinel 故障下线又恢复的master节点会变成slave。 全部配置项： # Example sentinel.conf # *** IMPORTANT *** # 绑定IP地址 # bind 127.0.0.1 192.168.1.1 # 保护模式（是否禁止外部链接，除绑定的ip地址外） # protected-mode no # port # 此Sentinel实例运行的端口 port 26379 # 默认情况下，Redis Sentinel不作为守护程序运行。 如果需要，可以设置为 yes。 daemonize no # 启用守护进程运行后，Redis将在/var/run/redis-sentinel.pid中写入一个pid文件 pidfile /var/run/redis-sentinel.pid # 指定日志文件名。 如果值为空，将强制Sentinel日志标准输出。守护进程下，如果使用标准输出进行日志记录，则日志将发送到/dev/null logfile \"\" # sentinel announce-ip # sentinel announce-port # # 上述两个配置指令在环境中非常有用，因为NAT可以通过非本地地址从外部访问Sentinel。 # # 当提供announce-ip时，Sentinel将在通信中声明指定的IP地址，而不是像通常那样自动检测本地地址。 # # 类似地，当提供announce-port 有效且非零时，Sentinel将宣布指定的TCP端口。 # # 这两个选项不需要一起使用，如果只提供announce-ip，Sentinel将宣告指定的IP和“port”选项指定的服务器端口。 # 如果仅提供announce-port，Sentinel将通告自动检测到的本地IP和指定端口。 # # Example: # # sentinel announce-ip 1.2.3.4 # dir # 每个长时间运行的进程都应该有一个明确定义的工作目录。对于Redis Sentinel来说，/tmp就是自己的工作目录。 dir /tmp # sentinel monitor # # 告诉Sentinel监听指定主节点，并且只有在至少哨兵达成一致的情况下才会判断它 O_DOWN 状态。 # # # 副本是自动发现的，因此您无需指定副本。 # Sentinel本身将重写此配置文件，使用其他配置选项添加副本。另请注意，当副本升级为主副本时，将重写配置文件。 # # 注意：主节点（master）名称不能包含特殊字符或空格。 # 有效字符可以是 A-z 0-9 和这三个字符 \".-_\". sentinel monitor mymaster 127.0.0.1 6379 2 # 如果redis配置了密码，那这里必须配置认证，否则不能自动切换 # Example: # # sentinel auth-pass mymaster MySUPER--secret-0123passw0rd # sentinel down-after-milliseconds # # 主节点或副本在指定时间内没有回复PING，便认为该节点为主观下线 S_DOWN 状态。 # # 默认是30秒 sentinel down-after-milliseconds mymaster 30000 # sentinel parallel-syncs # # 在故障转移期间，多少个副本节点进行数据同步 sentinel parallel-syncs mymaster 1 # sentinel failover-timeout # # 指定故障转移超时（以毫秒为单位）。 它以多种方式使用： # # - 在先前的故障转移之后重新启动故障转移所需的时间已由给定的Sentinel针对同一主服务器尝试，是故障转移超时的两倍。 # # - 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。 # # - 取消已在进行但未生成任何配置更改的故障转移所需的时间 # # - 当进行failover时，配置所有slaves指向新的master所需的最大时间。 # 即使过了这个超时，slaves依然会被正确配置为指向master。 # # 默认3分钟 sentinel failover-timeout mymaster 180000 # 脚本执行 # # sentinel notification-script和sentinel reconfig-script用于配置调用的脚本，以通知系统管理员或在故障转移后重新配置客户端。 # 脚本使用以下规则执行以进行错误处理： # # 如果脚本以“1”退出，则稍后重试执行（最多重试次数为当前设置的10次）。 # # 如果脚本以“2”（或更高的值）退出，则不会重试执行。 # # 如果脚本因为收到信号而终止，则行为与退出代码1相同。 # # 脚本的最长运行时间为60秒。 达到此限制后，脚本将以SIGKILL终止，并重试执行。 # 通知脚本 # # sentinel notification-script # # 为警告级别生成的任何Sentinel事件调用指定的通知脚本（例如-sdown，-odown等）。 # 此脚本应通过电子邮件，SMS或任何其他消息传递系统通知系统管理员 监控的Redis系统出了问题。 # # 使用两个参数调用脚本：第一个是事件类型，第二个是事件描述。 # # 该脚本必须存在且可执行，以便在提供此选项时启动sentinel。 # # 举例: # # sentinel notification-script mymaster /var/redis/notify.sh # 客户重新配置脚本 # # sentinel client-reconfig-script # # 当主服务器因故障转移而变更时，可以调用脚本执行特定于应用程序的任务，以通知客户端，配置已更改且主服务器地址已经变更。 # # 以下参数将传递给脚本： # # # # 目前始终是故障转移 \"failover\" # 是 \"leader\" 或 \"observer\" # # 参数 from-ip, from-port, to-ip, to-port 用于传递主服务器的旧地址和所选副本的新地址。 # # 举例: # # sentinel client-reconfig-script mymaster /var/redis/reconfig.sh # 安全 # 避免脚本重置，默认值yes # 默认情况下，SENTINEL SET将无法在运行时更改notification-script和client-reconfig-script。 # 这避免了一个简单的安全问题，客户端可以将脚本设置为任何内容并触发故障转移以便执行程序。 sentinel deny-scripts-reconfig yes # REDIS命令重命名 # # # 在这种情况下，可以告诉Sentinel使用不同的命令名称而不是正常的命令名称。 # 例如，如果主“mymaster”和相关副本的“CONFIG”全部重命名为“GUESSME”，我可以使用： # # SENTINEL rename-command mymaster CONFIG GUESSME # # 设置此类配置后，每次Sentinel使用CONFIG时，它将使用GUESSME。 请注意，实际上不需要尊重命令案例，因此在上面的示例中写“config guessme”是相同的。 # # SENTINEL SET也可用于在运行时执行此配置。 # # 为了将命令设置回其原始名称（撤消重命名），可以将命令重命名为它自身： # # SENTINEL rename-command mymaster CONFIG CONFIGss 7. 通过Redis实现一把安全可靠的分布式锁 SET 'resource_name' 'my_random_value' NX PX 30000 resource_name：锁的key my_random_value：键值应该为随机数，便于唯一指定地释放，也可以防止超时后误释放别人的锁 NX：表示只有当key不存在的时候才能设置成功 PX：表示该键值信息会在指定时间之后自动删除 但是很明显，单个Redis实例存在单点故障问题，即一旦Redis发生故障，就会导致整个分布式服务不可用 这个时候你可能会想为该Redis添加Slave节点，以便实现故障转移，但是这里有一个陷阱，虽然添加从节点后，该实例会成为Master，其会进行主从复制，但是这个过程是异步的，也就是说主节点的锁信息还未能同步到从节点便发生故障后，重新选举出来的主节点不一定有锁信息，就会导致其他服务重新获得锁，出现多个服务获得同一把锁的情况 采用Redis的集群部署方案，即有多个Master节点，采用RedLock算法 RedLock算法：向N个Redis Master循环发送锁请求信息，使用单实例命令，并设置超时时间 SET 'LOCK' '1001' NX EX 3000 获取成功的条件： 半数以上节点返回Success N次加锁请求时间小于超时时间 若超时失败，则会向所有Master节点发送释放锁的命令，并随机延迟时间后再去请求获得锁 参考文档：https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html 8. 缓存一致性协议 内存使用DRAM的动态随机存储器，缓存使用SRAM的静态随机存储器 MESI: Modified, Exclusive, Shared, Invalid Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"java/":{"url":"java/","title":"Java 学习笔记","keywords":"","body":"Java 八股整理Java 八股整理 包括一些基础知识、集合类实现的细节、JVM垃圾回收、锁、多线程、设计模式、多线程等。 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"java/1.基础.html":{"url":"java/1.基础.html","title":"1. 基础","keywords":"","body":"1. JDK, JRE, JVM2. Math.Round()3. Byte范围4. Integer 缓存池5. UTF-8 和 Unicode 的关系6. fail-fast 和 fail-safe7. 反射的基本原理，反射创建类实例的三种方式是什么8. 类加载机制9. 双亲委派模型10. 异常11. String12. 为什么重写 equals 方法必须重写 hashcode 方法13. String s1 = new String(\"abc\") 在内存中创建了几个对象14. 设计原则1. JDK, JRE, JVM JDK(Java Development Kit) 开发工具 基本类库 javac 编译 javap 反编译 javadoc 运行环境 JRE(Java Runtime Environment) JVM(Java Virtual Mechinal) 不同操作系统的机器指令是有可能不一样的，所以就导致不同操作系统上的JVM是不一样的。凡是编译后是Java字节码的都可以在JVM上运行，如Apache Groovy，Scala and Kotlin等等。 JVM工作所需要的类库 2. Math.Round() 向右取整 3. Byte范围 Java 中用补码来表示⼆进制数，补码的最高位是符号位，最高位用0表示正数，最高位1表示负数，正数的补码就是其本身，由于最高位是符号位，所以正数表示的就是0111 1111，也就是127。最⼤负数就是1111 1111，这其中会涉及到两个0，⼀个+0，⼀个-0，+0归为正数，也就是0，-0归为负数，也就是-128，所以 byte 的范围就是 -128 - 127。 4. Integer 缓存池 它的默认值⽤于缓存 -128 - 127 之间的数字，如果有 -128 - 127 之间的数字的话，使⽤ new Integer 不⽤创建对象，会直接从缓存池中取，此操作会减少堆中对象的分配，有利于提⾼程序的运⾏效率。 例如创建⼀个 Integer a = 24，其实是调⽤ Integer 的 valueOf 5. UTF-8 和 Unicode 的关系 由于每个国家都有⾃⼰独有的字符编码，所以Unicode 的发展旨在创建⼀个新的标准，⽤来映射当今使用的大多数语⾔中的字符，这些字符有⼀些不是必要的，但是对于创建⽂本来说却是不可或缺的。 Unicode 统⼀了所有字符的编码，是⼀个 Character Set，也就是字符集，字符集只是给所有的字符⼀个唯⼀编号，但是却没有规定如何存储，不同的字符其存储空间不⼀样，有的需要⼀个字节就能存储，有的则需要2、 3、 4个字节。 UTF-8 只是众多能够对⽂本字符进行解码的⼀种⽅式，它是⼀种变长的方式。 UTF-8 代表 8 位⼀组表示 Unicode 字符的格式，使⽤ 1 - 4 个字节来表示字符。 U+ 0000 ~ U+ 007F: 0XXXXXXX U+ 0080 ~ U+ 07FF: 110XXXXX 10XXXXXX U+ 0800 ~ U+ FFFF: 1110XXXX 10XXXXXX 10XXXXXX U+10000 ~ U+1FFFF: 11110XXX 10XXXXXX 10XXXXXX 10XXXXXX 可以看到， UTF-8 通过开头的标志位位数实现了变⻓。对于单字节字符，只占⽤⼀个字节，实现了向下兼容 ASCII，并且能和 UTF-32 ⼀样，包含 Unicode 中的所有字符，⼜能有效减少存储传输过程中占⽤的空间。 char 在 java 中是2个字节。 java 采用 unicode，2个字节（16位）来表示一个字符。所以 char = '中' 合法。 6. fail-fast 和 fail-safe fail-fast是 Java 中的⼀种快速失败机制， java.util 包下所有的集合都是快速失败的，快速失败会抛出 ConcurrentModificationException异常， fail-fast 你可以把它理解为⼀种快速检测机制，它只能⽤来检测错误，不会对错误进⾏恢复， fail-fast 不⼀定只在多线程环境下存在， ArrayList 也会抛出这个异常，主要原因是由于 modCount 不等于 expectedModCount。 fail-safe是 Java 中的⼀种安全失败机制，它表示的是在遍历时不是直接在原集合上进⾏访问，而是先复制原有集合内容，在拷⻉的集合上进⾏遍历。 由于迭代时是对原集合的拷⻉进⾏遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发ConcurrentModificationException。java.util.concurrent包下的容器都是安全失败的，可以在多线程条件下使⽤，并发修改。 7. 反射的基本原理，反射创建类实例的三种方式是什么 反射机制就是使 Java 程序在运⾏时具有 自省(introspect) 的能力，通过反射我们可以直接操作类和对象，比如获取某个类的定义，获取类的属性和方法，构造方法等。 创建类实例的三种⽅式是： 对象实例.getClass() 通过 Class.forName() 创建 对象实例.newInstance() ⽅法创建 8. 类加载机制 类的生命周期：（class 文件 -> Java虚拟机内存 -> 卸载） 加载 验证 准备 解析 初始化 使用 卸载 类的加载过程： 加载：查找并加载类的二进制数据（Class文件） 方法区：类的类信息 堆：Class 文件对应的类实例 验证：确保加载的类信息是正确的 准备：为类的静态变量进行初始化，分配空间并赋予初始值 解析：是将符号应用转换为直接引用 初始化：JVM对类进行初始化，对静态变量赋予正确值 静态代码块 类加载器： BootStrapClasserLoader C语言实现，加载 JDK/JRE/lib 下类路径 java.* 开头的类 ExtClassLoader 扩展类加载器 加载 JDK/JRE/lib/ext 下类路径 javax.* 开头的类 AppClassLoader 加载自己定义的类，类路径下面。用户自定义类加载器 可以用流、文件、数据库、网络形式加载 9. 双亲委派模型 当一个类加载器收到了类加载的请求的时候，他不会直接去加载指定的类，而是把这个请求委托给自己的父加载器去加载。只有父加载器无法加载这个类的时候，才会由当前这个加载器来负责类的加载。（这样就保证了我们不能篡改 java.己有的类） 10. 异常 参考文献：看完这篇 Exception 和 Error，和面试官扯皮就没问题了 Java中的所有异常都来自顶级父类 Throwable（实现 Serializable 接口）。 Throwable下有两个子类Exception和Error。 Eror表示非常严重的措误，比 StakOverFlowError 和 0ut0fMemoryError，通常这些误出现时，仅仅想靠程序自己是解决不了的，可能是虚拟机、磁盘、操作系统层面出现的问题了，所以通常也不建议在代码中去捕获这些Eror，因为捕获的意义不大，因为程序可能已经根本运行不了了。 Exception表示异常，表示程序出现 Exception时，是可以靠程序自己来解决的，比 NullPointerException、 IllealAcessException等，我们可以捕获这些异常来做特殊处理。Exception的子类通常又可以分为RuntimeException和非RuntimeException两类。 RuntimeException 表示运行期异常（又称 uncheckedException），表示这个异常是在代码运行过程中抛出的，这些异常是非检查异常，程序中可以选泽浦获处理，也可以不处理，这些导一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生，比如 NullPointerException、IndexOutOfBoundsException 等 非RuntimeException表示非运行期异常，也就是我们常说检查异常，是必须进行处的异常，如果不处理，程序就不能检查异常通过，如 IOExeption、SQLException 等以及用户自定义的 Exception 异常 11. String String 代表的是 Java 中的字符串 ， String 类比较特殊，它整个类都是被 final 修饰的，也就是说，String 不能被任何类继承，任何 修改 String 字符串的⽅法都是创建了⼀个新的字符串（保证了线程安全性）。 不可变对象不是真的不可变，可以通过 反射 来对其内部的属性和值进⾏修改，不过⼀般我们不这样做。 方法 String.intern()：在 JDK1.7 及以后调⽤ intern ⽅法是判断运⾏时常量池中是否有指定的字符串，如果没有的话，就把字符串添加到常量池（JDK8之后，字符串常量池在堆中）中，并返回常量池中的对象。 String a = new String(\"ab\"); String b = new String(\"ab\"); String c = \"ab\"; String d = \"a\"; String e = new String(\"b\"); String f = d + e; // + 号相当于是执行 new StringBuilder.append(), 但每次都会new StringBuilder()，所以多次拼接建议自建 StringBuilder String g = \"a\" + \"b\"; // 编译器会优化，会直接被优化为bbbccc，也就是直接创建了一个 bbbccc 对象 System.out.println(a.intern() == b); //false System.out.println(a.intern() == b.intern()); //true System.out.println(a.intern() == c); //true System.out.println(a.intern() == f); //false //equals()方法作对比都是true 具体分析：一篇与众不同的 String、StringBuilder 和 StringBuffer 详解 StringBuilder 不加锁 StringBuffer 线程安全 12. 为什么重写 equals 方法必须重写 hashcode 方法 如果在 Java 运⾏期间对同⼀个对象调用 hashCode 方法后，无论调用多少次，都应该返回相同的 hashCode，但是在不同的 Java 程序中，执行 hashCode 方法返回的值可能不⼀致； 如果两个对象的 equals 相等，那么 hashCode 必须相同； 如果两个对象 equals 不相等，那么 hashCode 也有可能相同，所以需要重写 hashCode 方法，这样也能够提高不同对象的访问速度； hashCode 通常是将地址转换为整数来实现的。 13. String s1 = new String(\"abc\") 在内存中创建了几个对象 ⼀个或者两个，String s1 是声明了⼀个 String 类型的 s1 变量，它不是对象。使⽤ new 关键字会在堆中创建⼀个对象，另外⼀个对象是 abc ，它会在常量池中创建，所以⼀共创建了两个对象；如果 abc 在常量池中已经存在的话，那么就会创建⼀个对象。 14. 设计原则 14.1 SOLID原则是面向对象设计和编程中的一组基本原则，其中SOLID分别是以下五个原则的首字母缩写： 单一职责原则(Single Responsibility Principle，SRP)。一个类或者模块只应该有一个单一的责任。这个原则告诉我们，一个类应该只负责一项功能，不要试图把太多的职责塞到一个类里面。 开闭原则(Open Closed Principle，OCP)。软件应该对扩展开放，对修改关闭。这个原则告诉我们，我们应该尽量通过扩展来实现新的功能，而不是去修改已经存在的代码。 里氏替换原则(Liskov Substitution Principle，LSP)。子类可以被看作是父类的一种类型，即父类能出现的地方子类也能够出现。这个原则告诉我们，在使用继承时，子类不能改变父类原有的行为，否则会导致程序出现意想不到的问题。 接口隔离原则(Interface Segregation Principle，ISP)。客户端不应该依赖于它不需要的接口。这个原则告诉我们，在设计接口时，应该尽量将接口拆分成更小粒度的接口，避免接口的臃肿和复杂度的增加。 依赖倒置原则(Dependency Inversion Principle，DIP)。高层模块不应该依赖低层模块，二者都应该依赖其抽象。这个原则告诉我们，在设计类和模块之间的关系时，应该通过抽象来实现低耦合、高内聚的设计。 14.2 开闭原则 开闭原则是指软件设计中的一个基本原则，它强调\"软件实体（类、模块、函数等）应该对扩展开放，对修改关闭\"。换言之，开闭原则要求我们在设计软件时，应该尽量避免直接修改已有的代码，而是通过添加新的代码来扩展功能，从而使系统更加稳定和灵活。 这个原则的核心思想就是面向对象设计的继承和多态特性，即通过继承来扩展原有的功能，而不是直接修改原有的代码。同时，通过多态可以将具体的实现与抽象的接口分离开来，从而降低了代码的耦合度，提高了代码的可维护性和可扩展性。 总之，遵循开闭原则可以使软件系统具有更好的可维护性、可扩展性和可复用性，从而降低软件开发的成本和风险。 14.3 里氏替换原则 里氏替换原则是面向对象设计中的重要原则之一，它指出：任何一个基类可以出现的地方，子类一定可以出现。也就是说，子类可以完全替代父类并且不会影响程序的正确性。 这个原则的意义在于保证代码的可维护性、可扩展性和可复用性。如果不遵循里氏替换原则，可能会导致程序的耦合度过高，增加了后期维护的难度，并且给系统带来了潜在风险。 具体而言，里氏替换原则需要满足以下条件： 子类必须完全实现父类的抽象方法。 子类可以有自己的方法，但不能覆盖父类的非抽象方法。 子类的前置条件必须弱于父类；子类的后置条件必须强于父类。 子类不能抛出比父类更多或更宽泛的异常。 总之，里氏替换原则是一种优秀的编程习惯，它可以帮助我们编写出高质量、可维护的代码，提高程序的灵活性和可复用性。 14.4 接口隔离原则 接口隔离原则（Interface Segregation Principle，ISP）是面向对象设计中的一项原则，指的是客户端不应该依赖于它不需要的接口。简而言之，一个接口应该只包含客户端需要的方法，而不应该强迫客户端实现它们不需要的方法。 这个原则的目标是减少系统的耦合性，提高系统的可维护性、可扩展性和可重用性。如果一个接口包含了过多的方法，那么实现这个接口的类就会出现“胖接口”的问题，这样会导致代码的臃肿和复杂度的增加，影响程序的可读性、可维护性和可测试性。 因此，按照接口隔离原则，我们应该将一个大接口拆分成多个小接口，每个小接口提供一组相关的方法，客户端只需要实现自己需要的接口即可。这样可以降低实现的难度，减少出错的可能性，同时也方便后期对系统的维护和修改。 14.5 依赖倒置原则 依赖倒置原则（Dependence Inversion Principle，DIP）是指设计代码结构时，高层模块不应该依赖低层模块，二者都应该依赖其抽象。抽象不应该依赖细节，细节应该依赖抽象。这个原则是面向对象设计中很重要的一条原则之一，它有助于降低代码的耦合性和提高代码的灵活性、可读性和可扩展性。 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"java/2.集合.html":{"url":"java/2.集合.html","title":"2. 集合","keywords":"","body":"1. HashMap 和 HashTable 的区别2. HashMap & HashSet3. ConcurrentHashMap4. Vector 和 ArrayList 的区别5. 线程安全的集合6. Arrays.asList 获得的 List 应该注意什么1. HashMap 和 HashTable 的区别 HashMap HashTable 线程不安全 线程安全 继承 AbstractMap 继承 Dictionary 允许空的 key 和 value 值 不允许空的 key 和 value 值 初始长度为16或2的幂次方 初始⻓度是11或给定大小 每次扩充变为原来的两倍 每次扩充容量变为之前的 2n+1 entry大于等于8时变为红黑树 / 2. HashMap & HashSet 2.1 HashMap HashMap 的长度为什么是 2 的幂次方： 对哈希值h进行计算索引的操作等价于h&(n-1)，效果和h%n是一样的，但&操作性能更优。通过将长度设为2的幂次方，可以保证n-1的二进制表示全为1，这样对哈希值进行位与运算相当于对哈希值的低位取模，从而均匀地将键值对分布到数组的不同位置上。 长度为2的幂次方还能够方便地进行数组的扩容和重哈希操作。在扩容时，新数组的长度通常是原长度的两倍，而且新数组的索引位置与旧数组的索引位置之间存在特定的关系，使得元素可以快速地重新映射到新数组中。 扩容机制：发生冲突的话则以链表的形式存储，jdk1.8之后引入了红黑树，链表的长度超过8之后会使用红黑树，小于6之后则又转换回来。 HashMap 线程安全的实现：ConcurrentHashMap（分段锁，效率最高），HashTable（只有一把锁，期间不能put和get），Collections.synchronizedMap 线程不安全原因：在扩容时，新增数据采用头插法，会造成链表翻转形成闭环，jdk1.8之后就不再采用头插法了，而是直接插入链表尾部，因此不会形成环形链表形成死循环，但是在多线程的情况下仍然是不安全的，在put数据时如果出现两个线程同时操作，可能会发生数据覆盖，引发线程不安全，总之，用ConcurrentHashMap没错了。 2.2 HashSet HashSet 继承于 AbstractSet 接口，实现了 Set、 Cloneable,、 java.io.Serializable 接口。 HashSet 不允许集合中出现重复的值。HashSet 底层其实就是 HashMap，所有对 HashSet 的操作其实就是对HashMap 的操作。所以 HashSet 也不保证集合的顺序，也不是线程安全的容器。 3. ConcurrentHashMap 3.1 JDK 1.7: ReentrantLock+Segment+HashEntry HashEntry数组 + Segment数组 + Unsafe 「大量方法运用」 JDK1.7中数据结构是由一个Segment数组和多个HashEntry数组组成的，每一个Segment元素中存储的是HashEntry数组+链表，而且每个Segment均继承自可重入锁ReentrantLock，也就带有了锁的功能，当线程执行put的时候，只锁住对应的那个Segment 对象，对其他的 Segment 的 get put 互不干扰，这样子就提升了效率，做到了线程安全。 额外补充：我们对 ConcurrentHashMap 最关心的地方莫过于如何解决 HashMap 在 put 时候扩容引起的不安全问题？ 在 JDK1.7 中 ConcurrentHashMap 在 put 方法中进行了两次 hash 计算去定位数据的存储位置，尽可能的减小哈希冲突的可能行，然后再根据 hash 值以 Unsafe 调用方式，直接获取相应的 Segment，最终将数据添加到容器中是由 segment对象的 put 方法来完成。由于 Segment 对象本身就是一把锁，所以在新增数据的时候，相应的 Segment对象块是被锁住的，其他线程并不能操作这个 Segment 对象，这样就保证了数据的安全性，在扩容时也是这样的，在 JDK1.7 中的 ConcurrentHashMap扩容只是针对 Segment 对象中的 HashEntry 数组进行扩容，还是因为 Segment 对象是一把锁，所以在 rehash 的过程中，其他线程无法对 segment 的 hash 表做操作，这就解决了 HashMap 中 put 数据引起的闭环问题。 3.2 JDK 1.8: Synchronized+CAS+Node+红黑树 JDK1.8屏蔽了JDK1.7中的Segment概念呢，而是直接使用「Node数组+链表+红黑树」的数据结构来实现，并发控制采用 「Synchronized + CAS机制」来确保安全性，为了兼容旧版本保留了Segment的定义，虽然没有任何结构上的作用。 总之JDK1.8中优化了两个部分： 放弃了 HashEntry 结构而是采用了跟 HashMap 结构非常相似的 Node数组 + 链表（链表长度大于8时转成红黑树）的形式 Synchronize替代了ReentrantLock，我们一直固有的思想可能觉得，Synchronize是重量级锁，效率比较低，但为什么要替换掉ReentrantLock呢？ 随着JDK版本的迭代，本着对Synchronize不放弃的态度，内置的Synchronize变的越来越“轻”了，某些场合比使用API更加灵活。 加锁力度的不同，在JDK1.7中加锁的力度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点），也就是1.8中加锁力度更低了，在粗粒度加锁中 ReentrantLock 可能通过 Condition 来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了，所以使用内置的 Synchronize 并不比ReentrantLock效果差。 4. Vector 和 ArrayList 的区别 ArrayList Vector 线程不安全 线程安全 1.5倍扩容 2x扩容 / 链表实现 5. 线程安全的集合 var list = new Vector<>(); // deprecated 使用synchronized修饰add var list = Collections.synchronizedList(new ArrayList<>()); var list = new CopyOnWriteArrayList<>(); // 写入时复制 使用lock在add中，效率较高 6. Arrays.asList 获得的 List 应该注意什么 Arrays.asList 转换完成后的 List 不能再进⾏结构化的修改，什么是结构化的修改？就是不能再进 ⾏任何 List 元素的增加或者减少的操作。 Arrays.asList 不⽀持基础类型的转换 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"java/3.JVM.html":{"url":"java/3.JVM.html","title":"3. JVM","keywords":"","body":"1. 运行时数据区域2. 垃圾回收3. HotSpot垃圾分代回收算法4. Serial5. ParNew6. Parallel Scavenge7. G1/CMS并发标记原理1. 运行时数据区域 虚拟机栈 : Java 虚拟机栈是线程私有的数据区，Java 虚拟机栈的生命周期与线程相同，虚拟机栈也是局部变量的存储位置。方法在执行过程中，会在虚拟机栈种创建一个 栈帧(stack frame) 本地方法栈: 本地方法栈也是线程私有的数据区，本地方法栈存储的区域主要是 Java 中使用 native 关键字修饰的方法所存储的区域 程序计数器：程序计数器也是线程私有的数据区，这部分区域用于存储线程的指令地址，用于判断线程的分支、循环、跳转、异常、线程切换和恢复等功能，这些都通过程序计数器来完成。 方法区：方法区是各个线程共享的内存区域，它用于存储虚拟机加载的 类信息、常量、静态变量、即时编译器编译后的代码等数据 堆：堆是线程共享的数据区，堆是 JVM 中最大的一块存储区域，所有的对象实例都会分配在堆上 运行时常量池：运行时常量池又被称为 Runtime Constant Pool，这块区域是方法区的一部分，它的名字非常有意思，它并不要求常量一定只有在编译期才能产生，也就是并非编译期间将常量放在常量池中，运行期间也可以将新的常量放入常量池中，String 的 intern 方法就是一个典型的例子 2. 垃圾回收 可作为gc roots的对象： 虚拟机栈中引用的对象 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI引用的对象 JDK1.2之后对引用进行了扩充： 强引用：不会被回收 软引用：内存要溢出的时候会回收 弱引用：只要发生垃圾回收，就会被回收 虚引用：在回收时会收到一个通知 3. HotSpot垃圾分代回收算法 默认情况下新生代占1/3，老年代占2/3 绝大多数对象在新生代中被创建，这里的垃圾回收非常频繁且速度很快 新生代通常采用复制算法，由于存活对象少，复制成本很低 新生代分为 Eden、Surivivor from、Surivivor to区，占比8比1比1 Eden填满后触发一次新生代的垃圾回收，称为minor gc，存活对象复制到任一Surivivor区，然后将Eden区清空即可完成这次gc，Surivivor from区的存活对象会复制到另一个Surivivor to区，这里需要保证to区为空 存活超过复制次数阈值（默认15）会被复制到老年代 Surivivor空间不够容纳存活对象时，也会直接进入老年代 大数组或者特别大的字符串 老年代通常使用标记整理算法进行回收，将存活对象向一端进行移动，称为major gc 4. Serial JDK1.3版本之前唯一的串行垃圾回收器，Stop The World 5. ParNew 多线程垃圾回收，只负责新生代的垃圾回收，可以配合Serial Old和Concurrent Mark Swap处理老年代 6. Parallel Scavenge 也是新生代的收集器，可控制吞吐量，gc自适应，配合Parallel old处理老年代 7. G1/CMS并发标记原理 三色标记 白色：没有被访问过 -> 垃圾对象 黑色：包括其引用都被访问过 灰色：被访问过，但还存在一些引用没有被访问 对象消失问题：扫描过程中插入了一条或多条从黑色对象到白色对象的新引用，并且同时去掉了灰色对象到该白色对象的直接引用或者间接引用。 解决方法，破坏上述两个条件之一即可： 增量更新：记录引用关系，并发扫描结束后根据记录重新扫描一次 -> CMS 原始快照（SATB）：记录 -> G1 JVM_垃圾收集之三色标记算法详解 CMS缺点 占用CPU资源，不超过25% 浮动垃圾 内存碎片 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"java/4.锁.html":{"url":"java/4.锁.html","title":"4. 锁","keywords":"","body":"1. Synchronized 和 ReentrantLock 的区别2. 传统的 synchronized 锁3. synchronized 锁的升级过程4. Lock锁5. 非公平锁6. ReentrantLock 公平锁和非公平锁的实现7. Synchronized 和 Lock 的区别8. 传统的生产者消费者问题，防止虚假唤醒9. Lock版的生产者消费者问题10. 八锁现象11. Java死锁如何避免？1. Synchronized 和 ReentrantLock 的区别 Synchronized ReentrantLock Java中的一个关键字 JDK提供的一个类 自动加锁与释放锁 需要手动加锁与释放锁 JVM层面的锁 API层面的锁 非公平锁 公平锁或非公平锁 锁的是对象，锁信息保存在对象头中 int类型的state标识来标识锁的状态 底层有锁升级过程 没有锁升级过程 2. 传统的 synchronized 锁 synchronized 通过为方法或代码块添加互斥锁，来保证线程安全性。 持有相同锁的多个线程，同一时间只有一个线程能够拿到锁并执行锁定的代码块或方法。 public synchronized void run(){ // do something } synchronized (this){// do something} synchronized (A.class){// do something} 3. synchronized 锁的升级过程 无锁状态（No lock）：初始状态下，共享资源没有被任何线程锁定，可以被任意线程访问。 偏向锁状态（Biased lock）：当第一个线程访问同步代码块时，JVM会将对象头中的标记位设置为偏向锁。这表示该对象偏向于第一个获取锁的线程。在这个阶段，锁是非竞争的，其他线程可以直接进入临界区。这个阶段旨在优化只有一个线程访问同步代码块的情况。 轻量级锁状态（Lightweight lock）：如果多个线程尝试获取偏向锁失败，JVM会将锁升级为轻量级锁。在轻量级锁状态下，JVM会将对象头中的一部分空间用于存储锁记录（Lock Record）的指针。每个线程在进入临界区之前，会通过CAS（Compare and Swap）操作尝试将锁记录指针替换为自己的线程ID。如果替换成功，表示获取到锁；否则，表示锁被其他线程占用，需要进行锁膨胀。 重量级锁状态（Heavyweight lock）：如果轻量级锁获取失败，JVM会进行锁膨胀，将锁升级为重量级锁。在重量级锁状态下，JVM会使用操作系统的互斥量来实现锁。这样，如果一个线程持有重量级锁，其他线程需要等待，直到持有锁的线程释放。 需要注意的是，锁的升级过程是逐步发生的。当线程竞争激烈或临界区执行时间较长时，锁可能会直接升级到重量级锁，跳过偏向锁和轻量级锁的阶段。 锁的升级过程是JVM自动完成的，开发者无需显式操作。JVM会根据线程竞争情况和锁的使用方式来选择最适合的锁级别，以平衡并发性能和线程安全性。 4. Lock锁 接口Lock的实现类： ReentractLock ReentractReadWriteLock.ReadLock ReentractReadWriteLock.WriteLock public void run(){ lock.lock(); try{ // do something } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } 5. 非公平锁 非公平锁（Unfair Lock）是一种线程同步机制，与公平锁（Fair Lock）相对应。在多线程环境中，公平锁会按照线程的申请顺序来获取锁资源，即先到先得的原则。而非公平锁则不考虑线程的申请顺序，允许新来的线程插队获取锁资源，从而可能导致已经在等待的线程长期等待。 非公平锁的设计主要是为了提高系统的整体吞吐量和性能。由于公平锁要求按照申请顺序获取锁资源，如果一个线程获取锁资源的时间较长，那么其他已经准备好并且在等待的线程就必须一直等待。这样会导致线程频繁地从用户态和内核态之间切换，增加了上下文切换的开销，降低了系统的吞吐量。 相比之下，非公平锁允许新来的线程插队获取锁资源，避免了等待时间过长的情况，减少了线程的等待时间和上下文切换的开销，从而提高了系统的整体性能和吞吐量。然而，由于非公平锁的设计特点，可能会导致某些线程一直无法获取到锁资源，造成不公平现象。 选择使用公平锁还是非公平锁需要根据具体的场景和需求来决定。如果对线程的公平性要求较高，并且能够容忍一定的性能损失，可以选择公平锁。如果追求系统的整体性能和吞吐量，并且能够接受一些线程的不公平性，可以选择非公平锁。 6. ReentrantLock 公平锁和非公平锁的实现 首先不管是公平锁和非公平锁，它们的底层实现都会使用AQS来进行排队，它们的区别在于线程在使用lock()方法加锁时： 如果是公平锁，会先检查AQS（AbstractQueuedSynchronizer队列同步器）队列中是否存在线程在排队，如果有线程在排队，则当前线程也进行排队 如果是非公平锁，则不会去检查是否有线程在排队，而是直接竞争锁 另外，不管是公平锁还是非公平锁，一旦没竞争到锁，都会进行排队，当锁释放时，都是唤醒排在最前面的线程，所以非公平锁只是体现在了线程加锁阶段，而没有体现在线程被唤醒阶段，ReentrantLock是可重入锁，不管是公平锁还是非公平锁都是可重入的。 7. Synchronized 和 Lock 的区别 https://xie.infoq.cn/article/4e370ded27e4419d2a94a44b3 8. 传统的生产者消费者问题，防止虚假唤醒 线程也可以唤醒，而不会被通知，中断或超时，即所谓的虚促唤醒 。 虽然这在实践中很少会发生，但应用程序必须通过测试应该使线程被唤醒的条件来防范，并目如果条件不满足则继续等待。 换句话说，等待应该总是出现在循环中，就像这样: synchronized (obj) { while () obi.wait(timeout); ...// Perform action appropriate to condition } 如果当前线程interrupted任何线程之前或在等待时，那么InterruptedException被抛出。 如上所述，在该对象的锁定状态已恢复之前，不会抛出此异常。 9. Lock版的生产者消费者问题 Condition可以实现精准通知唤醒 class BoundedBuffer { final Lock lock = new ReentrantLock(); final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); final Object[] items = new Object[100]; int putptr, takeptr, count; public void put(E x) throws InterruptedException{ lock.lock(); try { while (count == items.length) notFull.await(); items[putptr] = x; if (++putptr == items.length) putptr = 0; ++count; notEmpty.signal(); } finally { lock.unlock(); } } public E take() throws InterruptedException { lock.lock(); try { while (count == 0) notEmpty.await(); E x = (E) items[takeptr]; if (++takeptr == items.length) takeptr = 0; --count; notFull.signal(); return x; } finally { lock.unlock(); } } } 10. 八锁现象 JUC学习之8锁现象 syncMethod 方法使用 synchronized 关键字修饰，锁定对象为当前实例（this），nonSyncMethod 方法没有使用同步关键字，不会进行锁定 static 修饰的方法属于Class模版，只有一个 11. Java死锁如何避免？ 造成死锁的几个原因: 一个资源每次只能被一个线程使用 一个线程在阻塞等待某个资源时，不释放已占有资源 一个线程已经获得的资源，在未使用完之前，不能被强行剥夺 若干线程形成头尾相接的循环等待资源关系 这是造成死锁必须要达到的4个条件，如果要避免死锁，只需要不满足其中某一个条件即可。而其中前3个条件是作为锁要符合的条件，所以要避免死就需要打破第4个条件，不出现循环等待锁的关系。 在开发过程中: 要注意加锁顺序，保证每个线程按同样的顺序进行加锁 要注意加锁时限，可以针对所设置一个超时时间 要注意死锁检查，这是一种预防机制，确保在第一时间发现死锁并进行解决 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"java/5.多线程.html":{"url":"java/5.多线程.html","title":"5. 多线程","keywords":"","body":"1. Java默认有2个线程：main + GC2. 多线程实现方式3. 实现 Runnable 接口相比继承 Thread 类有如下优势：4. 实现 Runnable 接口和实现 Callable 接口的区别:5. 线程的六种状态6. sleep 和 wait 的区别7. 停止线程8. 线程的优先级越高越先执行吗？9. CAS (Compare And Swap)10. volatile11. CountDownLatch 减计数器12. CyclicBamer 加计数器13. Semaphore 信号量14. BlockingQueue 四组API15. ThreadLocal1. Java默认有2个线程：main + GC 并发：CPU单核，交替执行 并行：CPU多核，多个线程可以同时执行（提高使用效率：线程池） Runtime.getRuntime().availableProcessors() //当前CPU可用核数 2. 多线程实现方式 2.1 继承 Thread 类，重写 run 方法 这样代码的写法简单，符合大家的习惯，但是直接继承 Thread 类有一个很大的缺点，因为“java 类的继承是单一的，extends 后面只能指定一个父类”，所有如果当前类继承 Thread 类之后就不可以继承其他类。如果我们的类已经从一个类继承（如 Swing 继承自 Panle 类、JFram 类等），则无法再继承 Thread 类，这时如果我们又不想建立一个新的类，应该怎么办呢？ class MyThread extends Thread { private int ticket = 5; @Override public void run() { for (int i = 0; i 0) { System.out.println(\"车票第\" + ticket-- + \"张\"); } } } } public void Test() { new MyThread().start(); new MyThread().start(); new MyThread().start(); } 2.2 实现 Runnable 接口，重写 run 方法，实现 Runnable 接口的实现类的实例对象作为 Thread 构造函数的 target 如果要实现多继承就得要用implements，Java 提供了接口java.lang.Runnable来解决上边的问题。 Runnable是可以共享数据的，多个 Thread 可以同时加载一个Runnable，当各自 Thread 获得 CPU时间片的时候开始运行Runnable，Runnable里面的资源是被共享的，所以使用Runnable更加的灵活。 class MyRunnable implements Runnable { private int ticket = 5; @Override public void run() { for (int i = 0; i 0) { System.out.println(\"车票第\" + ticket-- + \"张\"); } } } } public void Test() { Runnable myRunnable = new MyRunnable(); // 将myRunnable作为Thread target创建新的线程 new Thread(myRunnable).start(); new Thread(myRunnable).start(); } 在第二种方法（Runnable）中，ticket 输出的顺序并不是54321，这是因为线程执行的时机难以预测，ticket--并不是原子操作。 在第一种方法中，我们 new 了3个 Thread 对象，即三个线程分别执行三个对象中的代码，因此便是三个线程去独立地完成卖票的任务；而在第二种方法中，我们同样也 new 了3个 Thread 对象，但只有一个Runnable对象，3个 Thread 对象共享这个Runnable对象中的代码，因此，便会出现3个线程共同完成卖票任务的结果。如果我们 new 出3个Runnable对象，作为参数分别传入3个 Thread 对象中，那么3个线程便会独立执行各自Runnable对象中的代码，即3个线程各自卖5张票。 在第二种方法中，由于3个 Thread 对象共同执行一个Runnable对象中的代码，因此可能会造成线程的不安全，比如可能 ticket 会输出-1（如果我们System.out....语句前加上线程休眠操作，该情况将很有可能出现），这种情况的出现是由于，一个线程在判断 ticket 为1>0后，还没有来得及减1，另一个线程已经将 ticket 减1，变为了0，那么接下来之前的线程再将 ticket 减1，便得到了-1。这就需要加入同步操作（即互斥锁），确保同一时刻只有一个线程在执行每次for循环中的操作。而在第一种方法中，并不需要加入同步操作，因为每个线程执行自己 Thread 对象中的代码，不存在多个线程共同执行同一个方法的情况。 2.3 通过 Callable 和 FutureTask 创建线程 Runnable是执行工作的独立任务，但是它不返回任何值。如果你希望任务在完成的能返回一个值，那么可以实现Callable接口而不是Runnable接口。在 Java SE5 中引入的Callable是一种具有类型参数的泛型，它的参数类型表示的是从方法call()(不是run())中返回的值。 FutureTask具有仅执行1次run()方法的特性(即使有多次调用也只执行1次)，避免了重复查询的可能。 class MyThread implements Callable { public Integer call() throws Exception { System.out.println(\"当前线程名——\" + Thread.currentThread().getName()); int i = 0; for (; i futureTask = new FutureTask<>(myThread); new Thread(futureTask, \"线程名：有返回值的线程2\").start(); try { System.out.println(\"子线程的返回值：\" + futureTask.get()); } catch (Exception e) { e.printStackTrace(); } } 2.4 通过线程池创建线程 ExecutorService executorService = Executors.newFixedThreadPool(5); MyRunnable myRunable = new MyRunnable(); executorService.execute(myRunable); executorService.shutdown(); ExecutorService、Callable、Future三个接口实际上都是属于Executor框架。返回结果的线程是在 JDK1.5 中引入的新特征，有了这种特征就不需要再为了得到返回值而大费周折了。 有返回值的任务必须实现Callable接口。类似的，无返回值的任务必须实现Runnable接口。 执行Callable任务后，可以获取一个Future的对象，在该对象上调用get就可以获取到Callable任务返回的Object了。 注意：get方法是阻塞的，即：线程无返回结果，get方法会一直等待。 再结合线程池接口ExecutorService就可以实现传说中有返回结果的多线程了。 下面提供了一个完整的有返回结果的多线程测试例子，在 JDK1.5 下验证过没问题可以直接使用。 3. 实现 Runnable 接口相比继承 Thread 类有如下优势： 可以避免由于 Java 的单继承特性而带来的局限； 增强程序的健壮性，代码能够被多个线程共享，代码与数据是独立的； 适合多个相同程序代码的线程区处理同一资源的情况。 4. 实现 Runnable 接口和实现 Callable 接口的区别: Runnable是自从 Java1.1 就有了，而Callable是1.5之后才加上去的 Callable规定的方法是call(),Runnable规定的方法是run() Callable的任务执行后可返回值，而Runnable的任务是不能返回值（是 void） call方法可以抛出异常，run方法不可以 运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。 加入线程池运行，Runnable使用ExecutorService的execute方法，Callable使用submit方法。 5. 线程的六种状态 NEW：初始化状态，未调用start方法 RUNNABLE：运行态 Ready：等待CPU发时间片 Running：执行态 BLOCKED：阻塞态，锁 WAITING：等待态，拿到锁之后，发现当前执行条件不太满足，需要暂时停止执行，以便让出CPU资源供其他线程执行，wait()，继续执行需要notify() TIMED_WAITING：超时等待 TERMINATED：结束态 6. sleep 和 wait 的区别 sleep 暂停当前线程执行，但不释放锁 Thread.sleep() 可以在任何场景使用 只能等待sleep结束 wait 暂停当前线程执行，并释放锁 属于对象 不能写在synchronized同步块之外 notify()唤醒 7. 停止线程 但是stop()方法是不建议使用，并且是有可能在未来版本中删除掉的： @Deprecated(since=\"1.2\", forRemoval=true) public final void stop() { 因为stop()方法太粗暴了，一旦调用了stop()，就会直接停掉线程，这样就可能造成严重的问题，比如任务执行到哪一步了？该释放的锁释放了没有？都存在疑问。 这里强调一点，stop()会释放线程占用的synchronized锁，而不会自动释放ReentrantLock锁 建议通过中断来停止线程 if (Thread.currentThread().isInterrupted()) { //... } try { Thread.sleep(1000); } catch (InterruptedException e) { //如果没有对中断做处理，中断信号会被重置为false，在循环内判断isInterrupted就会失效 } 8. 线程的优先级越高越先执行吗？ Java线程 轻量级进程 -> 系统内核线程，即操作系统原生的线程 优先级：1-10，win系统只有7级 系统会改变优先级，win存在优先级推进器的功能 9. CAS (Compare And Swap) 内存位置，预期值，新值 原子操作，CPU硬件指令集提供，硬件保证一个语义看起来需要多次操作才能完成的行为，通过一条处理器指令CAS就能完成 JDK1.5之后提供了CAS操作 Unsafe类 10. volatile volatile关键字主要是使变量在多个线程间可见 线程的私有堆栈：Java 内存模型告诉我们，各个线程会将共享变量从主内存中拷贝到工作内容，然后执行引擎会基于工作内存中的数据进行操作处理。这个时机对普通变量是没有规定的，而针对volatile修饰的变量给 Java 虚拟机特殊的约定，线程对volatile变量的修改会立刻被其他线程所感知，即不会出现数据脏读的现象，从而保证数据的”可见性“。 只保证可见性，并不保证原子性 11. CountDownLatch 减计数器 https://www.cnblogs.com/cxuanBlog/p/14166322.html 12. CyclicBamer 加计数器 https://www.jianshu.com/p/4ef4bbf01811 13. Semaphore 信号量 https://www.jianshu.com/p/38630b7dbe73 14. BlockingQueue 四组API 方式 抛出异常 有返回值，不抛出异常 阻塞等待 超时等待 添加 add offer put offer 移除 remove poll take poll 判断队列首 element peek / / 15. ThreadLocal ThreadLocal是 Java 中所提供的线程本地存储机制，可以利用该机制将数据缓存在某个线程内部，该线程可以在任意时刻、任意方法中获取缓存的数据。 ThreadLocal底层是通过ThreadLocalMap来实现的，每个Thread对象（注意不是ThreadLocal对象）中都存在一个ThreadLocalMap，Map 的 key 为ThreadLocal对象，Map 的 value 为需要缓存的值。 如果在线程池中使用ThreadLocal会造成内存泄漏，因为当ThreadLocal对象使用完之后，应该要把设置的 key、value，也就是Entry对象进行回收，但线程池中的线程不会回收，而线程对象是通过强引用指向ThreadLocalMap，ThreadLocalMap也是通过强引用指向Entry对象线程不被回收，Entry对象也就不会被回收，从而出现内存泄漏，解决办法是，在使用了ThreadLocal对象之后，手动调用ThreadLocal的remove方法，手动清除Entry对象。 threadLocal.remove(); ThreadLocal经典的应用场景就是连接管理（一个线程持有一个连接，该连接对象可以在不同的方法之间进行传递，线程之间不共享同一个连接）。 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"java/6.单例模式.html":{"url":"java/6.单例模式.html","title":"6. 单例模式","keywords":"","body":"1. 懒汉式2. 饿汉式1. 懒汉式 懒汉式单例模式在第一次调用的时候进行实例化。 1.1 适用于单线程环境（不推荐） 此方式在单线程的时候工作正常，但在多线程的情况下就有问题了。如果两个线程同时运行到判断instance是否为null的if语句，并且instance的确没有被创建时，那么两个线程都会创建一个实例，此时类型Singleton就不再满足单例模式的要求了。 public class Singleton { private static Singleton instance = null; private Singleton() {} public static Singleton getInstance() { if (null == instance) { instance = new Singleton(); } return instance; } } 1.2 适用于多线程环境，但效率不高（不推荐） 为了保证在多线程环境下我们还是只能得到该类的一个实例，只需要在getInstance()方法加上同步关键字sychronized，就可以了。但每次调用getInstance()方法时都被synchronized关键字锁住了，会引起线程阻塞，影响程序的性能。 public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } 1.3 双重检验锁 为了在多线程环境下，不影响程序的性能，不让线程每次调用getInstance()方法时都加锁，而只是在实例未被创建时再加锁，在加锁处理里面还需要判断一次实例是否已存在。 public static Singleton getInstance() { // 先判断实例是否存在，若不存在再对类对象进行加锁处理 if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; } 1.4 静态内部类方式（推荐） 加载一个类时，其内部类不会同时被加载。一个类被加载，当且仅当其某个静态成员（静态域、构造器、静态方法等）被调用时发生。 由于在调用 StaticSingleton.getInstance() 的时候，才会对单例进行初始化，而且通过反射，是不能从外部类获取内部类的属性的；由于静态内部类的特性，只有在其被第一次引用的时候才会被加载，所以可以保证其线程安全性。 总结： 优势：兼顾了懒汉模式的内存优化（使用时才初始化）以及饿汉模式的安全性（不会被反射入侵） 劣势：需要两个类去做到这一点，虽然不会创建静态内部类的对象，但是其 Class 对象还是会被创建，而且是属于永久带的对象 public class StaticSingleton { private StaticSingleton() {} // 获取实例 public static StaticSingleton getInstance() { return StaticSingletonHolder.instance; } // 一个私有的静态内部类，用于初始化一个静态final实例 private static class StaticSingletonHolder { private static final StaticSingleton instance = new StaticSingleton(); } public void methodA() {} public void methodB() {} public static void main(String[] args) { StaticSingleton.getInstance().methodA(); StaticSingleton.getInstance().methodB(); } } 2. 饿汉式 饿汉式单例类：在类初始化时，已经自行实例化。 2.1 饿汉式 public class Singleton { private static final Singleton instance = new Singleton(); private Singleton() {} public static Singleton getInstance() { return instance; } } 2.2 枚举方式（推荐） 创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。保证只有一个实例（即使使用反射机制也无法多次实例化一个枚举量）。 public class Singleton { public static void main(String[] args) { Single single = Single.SINGLE; single.print(); } enum Single { SINGLE; private Single() {} public void print() { System.out.println(\"hello world\"); } } } Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"java/7.线程池.html":{"url":"java/7.线程池.html","title":"7. 线程池","keywords":"","body":"1. CTL (control)2. 线程池的5种状态3. 线程池状态的转换情况4. 线程池中提交一个任务的流程5. 三大方法6. 七大参数7. 四种策略8. Spring ApplicationContext 和 BeanFactory 的区别1. CTL (control) 在 Java 中，线程池（Thread Pool）是一种用于管理和复用线程的机制。在 Java 的线程池实现中，ctl是一个表示线程池状态和线程数量的变量。 具体来说，ctl是一个32位的整数，其中高3位表示线程池的状态，低29位表示线程池中的线程数量。这样的设计可以同时表示线程池的状态和线程数量，提供了一种紧凑的表示方式。 通过对ctl的操作，可以实现对线程池状态和线程数量的管理，包括增加或减少线程数量、判断线程池是否在运行等功能。这样的设计可以更好地控制线程池的行为和资源利用，提高多线程编程的效率和可靠性。 2. 线程池的5种状态 状态 行为 RUNNING 会接收新任务并且会处理队列中的任务 SHUTDOWN 不会接收新任务并且会处理队列中的任务，任务处理完后会中断所有线程 STOP 不会接收新任务并且不会处理队列中的任务，并且会直接中断 TIDYING 所有线程所有线程都停止了之后，线程池的状态就会转为TIDYING，一旦达到此状态，就会调用线程池的terminated() TERMINATED terminated()执行完之后就会转变为TERMINATED 3. 线程池状态的转换情况 转变前 转变后 转变条件 RUNNING SHUTDOWN 手动调用shutdown()触发，或者线程池对象GC时会调用finalize()从而调用shutdown() RUNNING STOP 手动调用shutdownNow()触发 SHUTDOWN STOP 手动先调用shutdown()紧着调用shutdownNow()触发 SHUTDOWN TIDYING 线程池所有线程都停止后自动触发 STOP TIDYING 线程池所有线程都停止后自动触发 TIDYING TERMINATED 线程池自动调用terminated()后触发 4. 线程池中提交一个任务的流程 在使用execute方法提交一个Runnable对象时 会先判断当前线程池中的线程数是否小于corePoolSize 如果小于，则创建新线程并执行Runnable 如果大于等于，则尝试将Runnable加入到workQueue中 如果workQueue没满，则将Runnable正常入队，等待执行 如果workQueue满了，则会入队失败，那么会尝试继续增加线程 如果当前线程池中的线程数是否小于 maximumPoolSize 如果小于，则创建新线程并执行任务 如果大于等于，则执行拒绝策略，拒绝此Runnable 5. 三大方法 Executors.newSingleThreadExecutor(); // 单个线程 Executors.newFixedThreadPool(5); // 固定的线程池大小 Executors.newCachedThreadPool(); // 可伸缩的 以上底层都是由 ThreadPoolExecutor 实现 阿里开发手册：线程池不允许使用 Executors 去创建， 而是通过 ThreadPoolExecutor 的方式， 这样的处理方式让写的同学更加明确线程池的运行规则， 规避资源耗尽的风险。 Executors 返回的线程池对象的弊端如下： FixedThreadPool 和 SingleThreadPool：允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 CachedThreadPool：允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 ScheduledThreadPool：允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 6. 七大参数 public ThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, // TimeUnit.SECONDS BlockingQueue workQueue, // new LinkedBlockingDeque<>(3) ThreadFactory threadFactory, // Executors.defaultThreadFactory() RejectedExecutionHandler handler // new ThreadPoolExecutor.AbortPolicy() ) 7. 四种策略 AbortPolicy 如果线程池拒绝了任务，直接报错 CallerRunsPolicy 线程池让调用者去执行 public static class CallerRunsPolicy implements RejectedExecutionHandler { public CallerRunsPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { r.run(); // 可以看见源码逻辑为，先判断线程池还未关闭，然后直接r.run运行了任务。 } } } DiscardPolicy 如果线程池拒绝了任务，直接丢弃 DiscardOldestPolicy 如果线程池拒绝了任务，直接将线程池中最旧的，未运行的任务丢弃，将新任务入队 8. Spring ApplicationContext 和 BeanFactory 的区别 BeanFactory是Spring中非常核心的组件，表示Bean工厂可以生成Bean，维护Bean，而 ApplicationContext 继承了 BeanFactory，所以 ApplicationContext 拥有 BeanFactory 所有的特点，也是一个 Bean工厂，但是 ApplicationContext 除开继承了 BeanFactoy 之外，还继承了诸如 EnvironmentCapable（获取环境变量、properties等）、MesageSoure（国际化）、ApplicationEventPublisher 等接口，从而 ApplicationContext 还有获取系统环境变量、国际化、事件发布等功能，这是 BeanFactory 所不具备的。 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"数据库.html":{"url":"数据库.html","title":"数据库","keywords":"","body":"1. Innodb 是如何实现事务的2. 零时刻导致 Flyway 执行失败3. SQL Server (Compact Edition)4. 不同数据库之间的类型映射关系5. ChangeDB1. Innodb 是如何实现事务的 Innodb 通过 Buffer Pool，LogBuffer，Redo Log，Undo Log 来实现事务，以一个 update 语句为例: Innodb 在收到一个update语句后，会先根据条件找到数据所在的页，并将该页缓存在 Buffer Pool 中 执行 update 语句，修改 Buffer Pool 中的数据，也就是内存中的数据 针对 update 语句生成一个 RedoLog 对象，并存入 LogBuffer 中 针对 update 语句生成 undolog 日志，用于事务回滚 如果事务提交，那么则把 Redolog 对象进行持久化，后续还有其他机制将 Buffer Pool 中所修改的数据页持久化到磁盘中 如果事务回滚，则利用 undolog 日志进行回滚 2. 零时刻导致 Flyway 执行失败 运行时，历史脚本中的 Flyway 失败，因为带有时间戳的脚本没有默认值。检查本地 MySQL 环境的 sql_mode，删除NO_ZERO_DATE和NO_ZERO_IN_DATE。 SELECT @@GLOBAL.sql_mode; --- SET时移除NO_ZERO_DATE和NO_ZERO_IN_DATE SET GLOBAL sql_mode = \"ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\"; 3. SQL Server (Compact Edition) 3.1 SQL CE 中 sp_rename 仅支持表的修改 sp_rename 'oldTableName','newTableName'; 在 SqlServer 2005 Management Studio 中，您必须使用新名称创建一个新列，然后使用旧列中的值更新它，然后删除旧列。如果列是索引的一部分，那么最后一个操作是困难的。 3.2 SQL CE 查询表信息 SELECT table_name_, column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE table_name_='stu'; 3.3 SQL CE 和其他 SQL 的区别 SQL CE 3.5 和其他 SQL 的区别 SQL CE 3.5 SP2和其他 SQL 的区别 SQL CE 4.0和其他 SQL 的区别 3.4 SQL CE 使用 EFCore 连接并持久化对象： https://entityframework-extensions.net/efcore-sql-server-compact-provider 3.5 确定Firebird SQL版本 SELECT rdb$get_context('SYSTEM', 'ENGINE_VERSION') as version from rdb$database; 4. 不同数据库之间的类型映射关系 常用关键字翻译 T-sql postgres cast(value AS datetime)convert(datetime, value) cast(value AS timestamp(3)) datepart(day, value) extract(day FROM value) dateadd(day, value1, value2) value2 + value1 * INTERVAL '1 day' dateadd(d,-1,dateadd(mm, datediff(m,0,column_name)+1,0))当月的最后一天 date_trunc('month', column_name) + INTERVAL '1 month- 1 day' len(value) char_length(value) + || IDENTITY (1,1) GENERATED BY DEFAULT AS IDENTITY ROWVERSION bytea CREATE TABLE table_name (column_name varbinary(46) NOT NULL DEFAULT ((0))) CREATE TABLE table_name (column_name bytea NOT NULL DEFAULT E'\\x00000000') DECLARE @tablename TABLE(column_name1 nvarchar(500), column_name2 nvarchar(500)) CREATE TEMPORARY TABLE tablename (column_name1 nvarchar(500), column_name2 nvarchar(500))WITH tablename AS (SELECT …) NOCHECK CONSTRAINT allWITH CHECK CHECK CONSTRAINT all DISABLE TRIGGER ALLENABLE TRIGGER ALL 常用类型映射 SQL Server Postgres smallint smallint, int2 int integer, int, int4 bigint bigint, int8 tinyint 不支持 float(n) 1 , real float(n) 1 , real, float4 float(n) 25 double precision, float(n) 25 , float8 numeric, decimal numeric, decimal money, smallmoney moneyIn SQL Server, money is (19,4) and smallmoney is (10,4) in , but in Postgres money is (19,2) varbinary(n) bytea with checkPostgres uses 'check' to simulate n varbinary(max), image bytea binary(n) 不支持 date date datetime timestamp(3) without time zone datetime2(n) timestamp(n) without time zoneIn SQL Server 0 , but in Postgres 0 datetimeoffset(n) timestamp(n) with time zone, timestamptzIn SQL Server 0 , but in Postgres 0 bit bit, bit(1), boolean, bool char(n) character(n), char(n) nchar(n) character(n), char(n)For UCS-2 encoding, the storage size is two times n bytes varchar(n) character varying(n), varchar(n) nvarchar(n) character varying(n), varchar(n)For UCS-2 encoding, the storage size is two times n bytes text text ntext text Postgres pg_stat_statements Create Extension pg_stat_statements; Select * from pg_available_extensions where name = 'pg_stat_statements'; 5. ChangeDB 5.1 安装ChangeDB yscorecore/changedb (github.com) dotnet SDK 6.0 dotnet tool restore dotnet tool install changedb.consoleapp -g dotnet tool list -g 5.2 运行命令 changedb migration {source-database-type} \"{source-connection-string}\" {target-database-type} \"{target-connection-string}\" sqlserver -> postgres changedb migration sqlserver \"Data Source=(LocalDB)\\MSSQLLocalDB;Initial Catalog=;Integrated Security=SSPI;\" postgres \"Server=127.0.0.1;Port=5432;Database=;User Id=;Password=;\" sqlce -> sqlserver ChangeDb migration --max-fetch-bytes 10000 sqlce \"Data Source=C:\\xxxxxx.myox;Max Database Size=2048; Persist Security Info=False;\" sqlserver \"Data Source=(LocalDB)\\MSSQLLocalDB;Initial Catalog=;Integrated Security=SSPI;\" sqlce -> postgres ChangeDb migration --max-fetch-bytes 10000 sqlce \"Data Source=C:\\xxxxxx.myox;Max Database Size=2048; Persist Security Info=False;\" postgres \"Server=localhost;port=5432;Database={DBName};User Id=postgres;Password={PASSWORD}\" 5.3 复制数据库备份 CREATE DATABASE db_backup WITH TEMPLATE \"db\" Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-19 11:07:44 "},"网络模型、协议及报文.html":{"url":"网络模型、协议及报文.html","title":"网络","keywords":"","body":"1. TCP/IP 网络模型有哪几层？2. OSI（Open System Interconnection Reference Model 开放式系统互联通信参考模型）3. ARP（Address Resolution Protocol 地址解析协议）4. ICMP（Internet Control Message Protocol Internet控制报文协议）5. TCP报文6. options 字段7. 三次握手8. 查看 TCP 连接状态9. http报文10. IP报文11. 假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？12. MAC 报文13. 出口 —— 网卡14. 交换机和路由器建议直接看小林coding 1. TCP/IP 网络模型有哪几层？ 应用层（message消息或报文）：工作在操作系统中的用户态，传输层及以下则工作在内核态 传输层（segment段）：为应用层提供网络支持，如 TCP（Transmission Control Protocol 传输控制协议）、UDP（用户数据报协议 User Datagram Protocol） 网络层（packet包）：网络层最常使用的是 IP 协议（Internet Protocol），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片，得到一个即将发送到网络的 IP 报文 网络接口层（frame帧）：网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上 IP 地址分成两种意义： 一个是网络号，负责标识该 IP 地址是属于哪个「子网」的； 一个是主机号，负责标识同一「子网」下的不同主机； IP地址 & 子网掩码 = 网络号 IP地址 & 子网掩码取反 = 主机号 CIDR（Classless Inter-Domain Routing 无类别域间路由）是一种对IP地址进行分配和路由选择的标准方法。 2. OSI（Open System Interconnection Reference Model 开放式系统互联通信参考模型） 物理层（Physical Layer）：负责传输原始的比特流，处理物理介质、电压等物理连接细节。 数据链路层（Data Link Layer）：在直接连接的节点之间传输数据，处理帧（Frame）的发送和接收，提供可靠的数据传输。 网络层（Network Layer）：负责在不同网络之间进行路径选择和数据包转发，处理数据包的路由和寻址。 传输层（Transport Layer）：提供端到端的可靠数据传输，负责分段、流控制、差错检测和恢复等功能。 会话层（Session Layer）：建立、管理和终止应用程序之间的会话，负责进行对话控制和同步。 表示层（Presentation Layer）：处理数据的表示格式，负责数据的加密、压缩、解压缩以及数据格式的转换等。 应用层（Application Layer）：提供直接面向用户的应用服务，包括各种应用程序和协议，如电子邮件、文件传输、远程登录等。 3. ARP（Address Resolution Protocol 地址解析协议） ARP 是用于在局域网（LAN）中将IP地址解析为对应的物理MAC地址的协议。 在计算机网络中，数据包在传输过程中需要知道目标设备的物理地址（MAC地址），而通常应用程序使用的是目标设备的IP地址。ARP 协议（如果目标设备的 IP 地址和 MAC 地址映射在 ARP 缓存中不存在）通过在局域网内广播请求，询问某个IP地址对应的MAC地址，从而实现 IP 地址到 MAC 地址的解析。 在 Linux 系统中，我们可以使用 arp -a 命令来查看 ARP 缓存的内容。 > arp -a ? (192.168.3.20) at f0:76:1c:58:f4:bc [ether] on eth2 # IP地址 MAC地址 网口名称 4. ICMP（Internet Control Message Protocol Internet控制报文协议） ICMP 是一种网络协议，用于在IP网络中传输控制和错误消息。 ICMP 协议的主要功能包括以下几个方面： 错误报告：当在网络通信中出现错误时，ICMP 可以生成和传输错误报文给源设备，以通知发送者发生的问题。例如，当目标主机不可达、数据报超时、端口不可达等情况发生时，ICMP 可以生成相应的错误报文。 回显请求和回显回答：ICMP 提供了回显请求（Ping）和回显回答的功能。通过发送一个回显请求消息到目标设备，可以测试目标设备是否可达和计算往返时间（RTT）。目标设备收到回显请求后，会发送一个回显回答消息作为响应。 传输状况报告：ICMP 可以传输有关网络状况的信息。例如，当路由器转发数据报时，可以使用 ICMP 来发送传输状况报告，如 TTL（生存时间）过期报文等。 网络重定向：当路由器发现数据包正在沿着非最佳路径传输时，它可以使用 ICMP 报文发送网络重定向消息，告知发送者采用更佳的路径。 ICMP 协议通常工作在网络层（第3层），它直接封装在 IP 数据报中传输。它在网络通信中起到控制和诊断的作用，帮助网络管理员监控和排除网络问题，并提供了一些基本的网络工具和命令，如 Ping 和 Traceroute。 5. TCP报文 源端口和目的端口：各16bits，端口是传输层与应用层的服务接口 序号seq：32bits，TCP 连接中传送的数据流中的每一个字节都编上一个序号，序号字段的值则指的是本报文段所发送的数据的第一个字节的序号 确认号ack：32bits，是期望收到对方的下一个报文段的数据的第一个字节的序号 数据偏移：4bits，表示首部长度包含可选部分，最小单位为32bits 保留：6bits，保留为今后使用，但目前应置为 0 URG：当 URG=1 时，表示紧急数据，相当于高优先级的数据，尽快传送 ACK：当 ACK=1 时确认号字段才有效，当 ACK=0 时无效 PSH(PuSH)：当 PSH = 1 时，就尽快地交付接收应用进程，而不再等到整个缓存都填满了后再向上交付 RST (ReSeT)：当 RST=1 时，由于主机崩溃或其他等原因必须释放然后再重新建立连接 SYN：当 SYN = 1 时，表示这是一个连接请求或连接接受报文 FIN：但 FIN=1 时，表示发送方的数据已发送完毕，要求释放连接 窗口大小：16bits，窗口字段用来控制对方发送的数据量，单位为字节。TCP 连接的一端根据设置的缓存空间大小确定自己的接收窗口大小，然后通知对方以确定对方的发送窗口的上限。 检验和：16bits，校验首部前12字节 + 数据部分 紧急指针：16bits，指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面） 选项options：长度可变。TCP首部可以有多达40字节的可选信息，用于把附加信息传递给终点，或用来对齐其它选项。 这部分最多包含40字节，因为TCP头部最长是60字节（其中还包含前面讨论的20字节的固定部分） 填充：使整个首部长度是 4 字节的整数倍 6. options 字段 TCP报文中的选项（Options）字段具有以下结构： 选项类型（Option Kind）：1字节，表示选项的类型。常见的选项类型包括： 0：表示选项字段的结束标记（End of Option List）。 1：表示无操作（No-Operation），用于填充字节和对齐选项字段。 2：表示最大报文段长度（Maximum Segment Size，MSS）。 3：表示窗口扩大因子（Window Scale）。 4：表示选择确认（Selective Acknowledgment，SACK）。 其他选项类型还包括时间戳（Timestamp）、窗口探测（Window Probe）等。 选项长度（Option Length）：1字节，表示选项字段的长度，包括选项类型字段和选项数据字段的总长度。 选项数据（Option Data）：可变长度，根据选项类型的不同而具体确定。选项数据字段包含了选项的具体内容和参数。 TCP报文的选项字段可以包含多个选项，按顺序排列。每个选项的结构由选项类型、选项长度和选项数据组成。选项字段的长度是根据选项数据的实际长度计算得出的。 在TCP报文头中，选项字段紧跟在固定长度的报文头字段后面。如果选项字段的长度不是4字节的倍数，将会使用填充字节进行对齐，确保选项字段的起始位置是4字节对齐的。 选项字段的使用是根据需要和协商来确定的。发送方和接收方需要共同支持并理解使用的选项类型和相应的选项数据格式，以确保正确的解析和处理。选项字段的存在为TCP协议提供了一定的灵活性和功能扩展性，允许在TCP报文中传递额外的信息和实现协议的扩展功能。 7. 三次握手 目的是保证双方都有发送和接收的能力 ISN：初始化序列号（Initial Sequence Number） 8. 查看 TCP 连接状态 netstat -napt #-n（或 --numeric）：以数字形式显示 IP 地址和端口号，而不进行反向解析。 #-a（或 --all）：显示所有的连接，包括监听和非监听状态的连接。 #-p（或 --program）：显示与连接相关的程序名称和 PID。 #-t（或 --tcp）：仅显示 TCP 协议相关的连接信息。 9. http报文 TCP 报文中的数据部分就是存放 HTTP 头部 + 数据 （1）请求方法 URI 协议 / 版本 GET /index.html HTTP/1.1 http 1.1协议支持以下几种请求方法： GET：用于从服务器获取指定资源（幂等） POST：用于向服务器提交数据 HEAD：与 GET 方法类似，但只请求获取资源的元数据，而不包含实际的资源内容。主要用于获取资源的元信息，如资源的大小、最后修改时间等 PUT：将请求中包含的实体存储在服务器上的指定位置。PUT 方法用于上传、替换或创建指定位置的资源 DELETE：请求服务器删除指定的资源 OPTIONS：用于请求服务器返回对指定资源支持的通信选项。主要用于获取服务器支持的请求方法、报文头部支持的字段等信息 TRACE：用于对服务器进行环回测试。服务器收到 TRACE 请求后，应该将请求报文的内容作为响应主体返回给客户端，用于检测中间的代理服务器或网关对请求的修改。 CONNECT：用于建立与目标服务器的隧道连接，通常用于进行安全的HTTPS通信。 （2）请求头 (Request Header) 请求头包含许多有关的客户端环境和请求正文的有用信息。例如，请求头可以声明浏览器所用的语言，请求正文的长度等。 Accept:image/gif.image/jpeg.*/* Accept-Language:zh-cn Connection:Keep-Alive Host:localhost User-Agent:Mozila/4.0(compatible:MSIE5.01:Windows NT5.0) Accept-Encoding:gzip,deflate. (3) 请求正文 请求头和请求正文之间是一个空行，这个行非常重要，它表示请求头已经结束，接下来的是请求正文。请求正文中可以包含客户提交的查询字符串信息。 10. IP报文 版本（Version）：4 bits，IP协议的版本号，常用4、6 首部长度（Header Length）：4 bits，不包含Data部分，单位4 bytes，最大 60 bytes 服务类型（Type of Service）：8 bits，用于指定IP报文的优先级、延迟和吞吐量要求等服务质量(QoS)相关信息 总长度（Total Length）：16 bits，指定整个IP报文的总长度（包括IP首部和数据部分），单位 bytes，最大值为65535 标识（Identification）：16 bits，用于标识IP报文的唯一标识符。在分片传输中，这个字段在所有片段中保持不变 标志（Flags）：3 bits，用于指示是否进行分片以及如何处理分片 第一个比特位为保留位 第二个比特位为不分片DF （Don't Fragment）标志位，用于指示该报文是否允许分片 第三个比特位为更多分片MF（More Fragments）标志位，用于指示是否还有更多分片 片偏移（Fragment Offset）：13 bits，用于指示该分片相对于原始IP报文开始位置的偏移量，以8字节为单位 生存时间（Time to Live）：8 bits，表示报文在网络中可以经过的最大跳数（即经过的路由器数量） 协议（Protocol）：8 bits，指定IP报文中携带的上层协议类型，例如TCP(6)、UDP(17)、ICMP(1)等。 首部校验和（Header Checksum）：16 bits，用于检验IP首部的完整性，以便在接收端进行错误检测 源IP地址（Source IP Address）：32 bits，指定报文的发送者的IP地址 目标IP地址（Destination IP Address）：32 bits，指定报文的接收者的IP地址 选项（Options）：可选字段，用于在IP报文中传递一些额外的控制和参数信息，如记录路由路径、时间戳等 数据（Data）：IP报文的数据部分，根据协议类型的不同而具有不同的格式和含义 11. 假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？ 当存在多个网卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断应该使用哪个一块网卡来发送包。 这个时候就需要根据路由表规则，来判断哪一个网卡作为源地址 IP。 在 Linux 操作系统，我们可以使用 route -n 命令查看当前系统的路由表。 > route -n Kernel IP routing table Destination Gateway Genmask Flags Metric RefUse Iface 192.168.3.0 0.0.0.0 255.255.255.0 U 0 0 eth0 192.168.10.0 0.0.0.0 255.255.255.0 U 0 0 eth1 0.0.0.0 192.168.3.1 0.0.0.0 UG 0 0 eth0 举个例子，根据上面的路由表，我们假设 Web 服务器的目标地址是 192.168.10.200。 首先先和第一条目的子网掩码（Genmask Generalized netmask）进行 与运算，得到结果为 192.168.10.0，但是第一个条目的 Destination 是 192.168.3.0，两者不一致所以匹配失败。 再与第二条目的子网掩码进行 与运算，得到的结果为 192.168.10.0，与第二条目的 Destination 192.168.10.0 匹配成功，所以将使用 eth1 网卡的 IP 地址作为 IP 包头的源地址。 那么假设 Web 服务器的目标地址是 10.100.20.100，那么依然依照上面的路由表规则判断，判断后的结果是和第三条目匹配。 第三条目比较特殊，它目标地址和子网掩码都是 0.0.0.0，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，Gateway 即是路由器的 IP 地址。 12. MAC 报文 MAC（Media Access Control）报文是在数据链路层上使用的一种格式，用于在本地网络中的主机之间进行通信。下面是MAC报文的基本格式： 目的MAC地址（6字节） 源MAC地址（6字节） 类型/长度字段（2字节） 数据（46-1500字节） 帧校验序列（4字节） 目的MAC地址（Destination MAC Address）：指示报文的目标设备的物理地址，通常是一个唯一的标识符，采用十六进制表示法（如00:11:22:33:44:55） 源MAC地址（Source MAC Address）：指示报文的发送设备的物理地址，也是一个唯一的标识符 类型/长度字段（Type/Length Field）：用于指示数据字段中包含的协议类型或者报文长度。 如果该字段的值大于等于0x600（1536），则表示指示的是协议类型，一般在 TCP/IP 通信里，MAC 包头的协议类型只使用：0800 ： IP 协议，0806 ： ARP 协议 如果该字段的值小于0x600，则表示指示的是报文的长度 数据（Data）：MAC报文携带的有效数据部分，长度通常为46至1500字节。这部分数据是由上层协议（如IP协议）产生的数据。 帧校验序列（Frame Check Sequence，FCS）：用于校验报文是否在传输过程中发生错误。它是通过对报文中的数据部分进行计算所得到的一种校验值，长度为4个字节。 需要注意的是，上述格式是Ethernet（以太网）中MAC报文的基本格式，还有其他类型的局域网技术和数据链路协议也使用不同的报文格式，但是以太网是目前应用最广泛的局域网技术之一。 13. 出口 —— 网卡 网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。 负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。 网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。 起始帧分界符是一个用来表示包起始位置的标记 末尾的 FCS（帧校验序列）用来检查包传输过程是否有损坏 最后网卡会将包转为电信号，通过网线发送出去。 14. 交换机和路由器 交换机 路由器 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-13 10:05:20 "},"markdown.html":{"url":"markdown.html","title":"Markdown","keywords":"","body":"markdown 注意事项markdown 注意事项 markdown 链接左右括号可能解析不正确，建议使用 %28 代替 url 中的 (，使用 %29 代替 ) 在表格中输入|，建议使用&#124;代替 Copyright ©Bota5ky all right reserved，powered by GitbookLast Updated: 2023-07-19 11:11:33 "}}